# 计算机组成原理与体系结构

**推荐书籍：**

- 计算机体系结构（第二版） 清华大学出版社

- John L. Hennessy, David A. Patternson; Computer Architecture: A Quantitative Approach; sixth Edition. 

- David A. Patternson, John L. Hennessy ; Computer Organization and Design- The Hardware/Software Interface; RISC-V Edition.
- CSAPP



## 考试

- 第七章

  - 开关

- 第六章

  - **向量优化**，向量处理方式，哪种方式适合

- 第五章（填空、计算）

  - 理解相关性，怎样处理相关性（控制相关，结构相关，数据相关）
  - 针对计算流水性能分析，流水线的时空图的基本计算指标 加速比 吞吐率 效率等
  - 看清楚题目，是不是一个多功能的，动态静态多功能看清楚
  - 做一个简单算法，哪个先算哪个后算
    - 相同功能的要尽可能一起算
    - 尽可能减少RAW去除

- 第四章

  - 输入输出的三种基本方式
    - 程序控制
    - 中断（中断处理重点：中断优先级）
  - iop处理问题 通道 最大流量跟什么有关（工作周期互为倒数）
  - 使用通道的基本条件，实际流量不能超过通道最大流量，
  - 判断哪些通道与设备是否能连接

- 第三章 I/O
  - 几个层次
    - 每个层次的目标，扩容or提速
  - 如何地址变换提速
  - 如何 cache 性能优化
    - 减低失效率，减少时效冲突，减少命中时间
    - 替换算法 页块  
      - 堆栈型替换算法怎么用
- 第二章 指令系统
  - 指令基本构成
  - 寻址方式 确定选择使用什么方式
    - 选择方法：频度分析
    - 间接寻址、变址寻址 -> 扩充寻址空间；立即寻址
  - 指令格式优化  分别对操作码操作数进行优化
  - 标记 下一条指令在哪 PC
  - CRSC RISC，了解RISC经常使用的技术
- 第一章
  - 计算：计算性能处理衡量cpu：CPI，计算过程中间有小的转弯
  - 阿姆达尔定理（部分改进对整体的影响），
    - 单部件优化的改善
    - 多部件的优化
  - 设计原理
    - 局部性原理（时间 空间局部性）

## 第一章 计算机系统概论

### 计算机发展历史

计算机是由软件+硬件组成的

#### 计算机分类方式:star::star::star:

- 按处**理机性能**和**价格**分类

- 按大小分类：<font color= red>**巨型、大型、中型、小型、微型机**</font>

- 按用途分：个人设备、科学计算、事务处理、实时控制、工作站、服务器等。
  - 集群/仓储级计算机（Clusters / Warehouse Scale Computers）
    - 每个数据中心包含10+万个处理器核，专门的应用程序，加上虚拟机的云托管
    - 现在越来越多地使用gpu、fpga和定制硬件来加速工作负载
    - 强调可用性和性价比(availability、price-performance、energy)
  - 嵌入式计算机/物联网（Embedded Computers / Internet of Things）
    - 有线/无线网络基础设施，打印机
    - 消费类产品( TV/Music/Games/Automotive/Camera/MP3)和物联网
    - 强调价格、能耗及面向特定应用的性能
  
- 按数据类型分：定点计算机、浮点计算机

  - 向量计算机：
    - 向量运算涉及在一组数据上进行同样的操作，例如矩阵乘法、图像处理等。
    - 常用于高性能计算（HPC）领域，例如超级计算机。

  - 堆栈计算机：

    - 操作数和结果通过堆栈来管理，而不是使用寄存器。

    - 简化了编译器设计，但在现代计算机中不常见。

- 按处理机个数种类划分：单处理机，并行处理机、多处理机、分布处理机，关联处理机，超标量处理机，超流水线处理机，VLIW处理机，SMP(对称多处理机)、MPP(大规模并行处理机)、机群(Cluster)系统等

- 按“并行级”和“流水线”分类：**Handler表示法**

  - 根据可并行和流水处理的程度，将硬件分成三个层次：

    - 程序控制部件（PCU）的个数$k$；
    - 算术逻辑部件（ALU）或处理部件（PE）的个数$d$；
    - 每个算逻部件包含基本逻辑线路（ECL）的套数$w$。
  - 每一个计算机系统都可以用上述三个参数表示其结构特征$t（系统型号）=（k，d，w）$
  - 为了更细致的反映结构特殊性，表示式可写成：$t（系统型号）=（k×k’，d×d’，w×w’）$
    - k’表示宏流水线中程序控制部件的个数；
    - d’表示指令流水线中算术逻辑部件的个数；
    - w’表示操作流水线中基本逻辑线路的套数。



##### 基于流（Flynn分类法）:star:

1. 模型中的重要概念

   指令流（Instruction Stream）：机器执行的指令序列；

   数据流（Data stream）：由指令处理的数据序列；

   多倍性（Multiplicity）：在系统最窄的部件上，处于同一执行阶段的指令和数据的最大可能个数。

2. 模型中的基本模块

   MM（Memory Module）：内存模块。

   PU（Process Unit）：处理单元

   CU（Control Unit）：控制单元

3. 按照**指令流和数据流的多倍性（原理）**，Flynn将 CA 分成4种：

   1. **单指令流单数据流(SISD)**：一个CU从MM读取一个指令，并操控PU对MM操作
   2. **单指令流多数据流(SIMD)**：同一指令由多个使用不同数据流的处理器执行。开发数据级并行
   3. **多指令流单数据流(MISD)**:  目前为止，还没有这种类型的商用多处理器，但包含这种类型之后，这种简单的分类方式变得更完整。
   4. **多指令流多数据流(MIMD)**: 每个处理器都提取自己的指令，对自己的数据进行操作，它针对的是任务级并行。

> 分类缺点：
>
> 1. 分类太粗
>
>    - 在SIMD中包括有多种处理机
>
>    - 对流水线处理机的划分不明确，
>
>    - 标量流水线为SISD，向量流水线为SIMD
>
>
> 2. 根本问题是把两个不同等级的功能并列对待     
>    - 数据流受指令流控制，造成MISD不存在
>
>
> 3. 没有区分非冯计算机的分类

##### 库克分类法：按指令流和执行流分类:star:

- 单指令流单执行流 (Single Instruction Single Executionstream, SISE) ，典型的单处理机

- 单指令流多执行流 (Single Instruction Multiple Executionstream, SIME)，多功能部件处理机、相联、向量、流水线、超流水线、超标量

- 多指令流单执行流 (Multiple Instruction Single Execution stream, MISE) 多道程序系统 

- 多指令流多执行流 (Multiple Instruction Multiple Execution stream, MIME) 典型的多处理机


##### 冯氏分类法:star:

- 以**最大并行度**作为系统结构分类的标准，最大并行度的数值越大越好


- 所谓最大并行度 $P_m$ 是指一个系统在单位时间内能够处理的最多的二进制位数，显然这是一个完全由计算机硬件结构决定的参数。


- 字串位串（WSBS）：$n = 1，m = 1$。这是最早期全串行运算的计算机。

- 字并位串（WPBS）：*n* > 1，*m* = 1。这是传统的并行单处理机。

- 字串位并（WSBP）：*n* = 1，*m* > 1。每处理机只一位，但有许多个处理机字并行运用

- 字并位并（WPBP）：*n* > 1，*m* > 1。

  W – Word；B – Bit；S – Serial；P – Parallel；位宽代表一个位片中能同时处理的字数，字宽代表一个字中的bit数

- 平均并行度

  - 如果在一个时钟周期 $\Delta t_i$ 内实际处理的二进制位数为 $P_i$，那么在 $T$ 个时钟周期内的平均并行度$P_a$ 为
    $$
    P_a=\left(\sum_{i=1}^T P_i\right) / T
    $$

  - 把平均并行度与最大并行度之比称为平均利用率，用μ表示为：
    $$
    \mu=P_a/P_m=\frac{\sum^T_{i=1}P_i}{T \bullet P_m}
    $$



### 计算机系统的层次结构

- 应用语言机器 面向用户

- 高级语言机器 面向用户

- 汇编语言机器 面向用户

- 操作系统机器 面向上层机器

- 传统机器 面向上层机器

- 微指令机器 面向上层机器

#### 冯诺伊曼计算机 :star:

- 由 **运算器、存储器、控制器、输入设备、输出设备** 五大设备组成
- 指令和数据用**二进制**以同等地位**存放于存储器**中，按地址访问
- 指令由**操作码和地址码**组成，操作码指明操作的内容，地址码表示操作数在存储器中的位置
- 指令在存储器内顺序存放
- 机器以**运算器**为核心

#### 计算机的功能部件

![在这里插入图片描述](assets/2021011714554763.png)

1. 输入设备：将外部信息以计算机能读懂的方式输入，如键盘，鼠标

2. 输出设备：将计算机处理的信息以人所能接受的方式输出，如显示屏，打印机


##### 存储器的组成

- 主存储器（内存储器）
  - 由地址寄存器(MAR)，数据寄存器(MDR)，存储体，时序控制逻辑组成
  - 地址寄存器存放访存地址，经过地址译码后找到所选的存储单元
  - 时序控制逻辑用于产生存储器操作所需的各种时序信号
  - CPU能直接访问主存
- 辅助存储器（外存储器）
  - 协助主存储器记忆更多的信息，辅助存储器的信息需要导入到主存储器中，才可以被CPU访问


![在这里插入图片描述](assets/20210117142540792.png)

##### 运算器的组成

![在这里插入图片描述](assets/20210117142756847.png)

##### 控制器组成

![在这里插入图片描述](assets/20210117143001482.png)

#### 计算机软件的分类

系统软件和应用软件

- 系统软件包括 操作系统，数据库管理系统，语言处理系统，网络软件系统等。
- 应用软件包括各种科学计算类程序，工程设计类程序，数据统计与处理程序。

三个级别的语言

- **机器语言**（二进制代码语言），需要编程人员记忆每条指令的二进制编码。机器语言是计算机唯一可以直接识别和执行的语言。
- **汇编语言**。汇编语言用英文单词或其缩写代替二进制的指令代码，更容易为人们记忆和理解。使用汇编语言编辑的程序，必须经过一个称为汇编程序的系统软件的翻译，将其转换为计算机的机器语言后，才能在计算机的硬件系统上执行。
- **高级语言**。高级语言是为方便程序设计人员写出解决问题的处理方案和解题过程的程序。通常高级语言需要经过编译程序编译成汇编语言程序，然后经过汇编操作得到机器语言程序，或直接由高级语言程序翻译成机器语言程序。

#### 解释和编译:star::star:

**编译（Compile）**是把整个源程序代码翻译成另外一种代码，翻译后的代码等待被执行或者被优化等等，发生在运行之前，产物是**另一种代码**。

**解释（Interpret）**是把源程序代码一行一行的读懂，然后一行一行的执行，发生在运行时，产物是**运行结果**。



### 计算机性能标准

#### 衡量计算机性能的主要标准

![在这里插入图片描述](https://img-blog.csdnimg.cn/20210117153043725.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hhb2ppZV9kdWFu,size_16,color_FFFFFF,t_70)

工作能力指标：

- 处理能力——单位时间内能处理的信息量（吞吐率）
- 响应能力——响应时间、周转时间、排队时间
- 利用率——$T$ 时间内，某部分被使用时间 $t$ 与 $T$ 的比值
- 数据通路带宽——数据总线一次所能传送信息的位数

例如，数据总线的传输速率为266 MHz，总线的宽度为32位（4字节），那么该数据总线的带宽就达到2.1GB/s（266MHz×4B）。

<img src="assets/image-20231108180121393.png" alt="image-20231108180121393" style="zoom: 67%;" />

<img src="assets/image-20231108180130060.png" alt="image-20231108180130060" style="zoom: 67%;" />



#### 系统处理能力:star:

> CPI：执行一条指令所需的时钟周期数（不适合作为计算机系统整体的评估模块）
>

> CPU执行时间，指运行一个程序所花费的时间。
> CPU执行时间 = CPU时钟周期数/主频 = (指令条数xCPI)/主频
> CPU的性能取决于三个要素:主频、CPI 、指令条数

> - IPS(Instructions Per Second) = 主频/平均CPI，每秒执行多少指令
>
> - MIPS(Million Instructions Per Second) = 即每秒执行多少百万条指令。
>   $$
>   MIPS=\frac{指令条数}{执行时间\times 10^6}=\frac{时钟频率}{CPI\times 10^6}
>   $$
>
> - 
>   MFLOPS(Mega Floating-point Operations Per Second) = 浮点操作次数/(执行时间x$10^6$),即每秒执行多少百万次浮点运算。
>
> - 
>   GFLOPS(Giga Floating-point Operations Per Second) = 浮点操作次数/(执行时间x$10^9$)，即每秒执行多少十亿次浮点运算。
>
> - 
>   TFLOPS(Tera Floating-point Operations Per Second)=浮点操作次数/(执行时间x$10^{12}$)，即每秒执行多少万亿次浮点运算。
>

##### 基准测试程序

可以分为两类：

1. 测试系统中的元部件，如CPU（针对指令系统测试）、硬盘（针对IO操作测试）等

2. 测试全系统的性能进行（针对程序测试）。




#### 多机系统性能评价

1. 性能加速比$S(p,n)$：$p$为问题大小，$n$为处理机数，$h$为通信开销
   $$
   S(p,n)=\frac{T(p,1)}{T(p,n)+h(p,n)}
   $$

2. 性能可伸缩性

   定义：对一个给定的应用问题，系统性能随PE（Processing Element）增加而线性增长的性能

   影响因素：PE数，时钟频率，问题大小，求解时间等。

   评价方法：选择某参考机作为比较参照机，测量后得出性能可伸缩性值。



## 第二章 数据的表示与运算

### 进制转换

![在这里插入图片描述](assets/20210117191955803.png)



### 无符号数和有符号数

计算机中的数存储在寄存器中，通常称寄存器的位长为**机器字长**，无符号数和有符号数能表示的数字范围不同。

#### 有符号数

##### 原码

$$
[x]_{源}=\begin{cases} 
x & 2^n>x\ge 0 \\
2^{n-1}+x & 0\ge x>-2^n
\end{cases} \\
[x]_{源}=\begin{cases} 
x & 1>x\ge 0 \\
1-x & 0> x>-1
\end{cases}
$$

- 正数第一位为0，负数第一位为1

##### 补码

$$
[x]_补= \begin{cases} 
0,x & 2^n>x\ge0\\
2^n+x & 0>x> -2^n
\end{cases} \\
[x]_补= \begin{cases} 
x & 1>x\ge0\\
2+x & 0>x\ge -1
\end{cases}
$$

- 正数第一位为0，负数第一位为1
- 正数的补码就是本身，负数的补码是符号位不变，各位数取反然后+1



补码移位规则：

1. 正数
   - 符号位不变，左移右移空出位都补0。


2. 负数

   - 符号位都不变


   - 左移：数值左移，空出的位都补0 （小数点右移）

   - 右移：数值右移，空出的位都补1 （小数点左移）

##### 反码

$$
[x]_反= \begin{cases} 
0,x & 2^n>x\ge0\\
2^n-1+x & 0>x> -2^n
\end{cases} \\
[x]_补= \begin{cases} 
x & 1>x\ge0\\
2-2^{-n}+x & 0\ge x> -1
\end{cases}
$$

##### 总结

- 最高位是符号位
- 值为正的时候，三者一样
- 值为负的时候，补码是原码“求反加一”，反码是原码“求反”



##### 移码表示法

存在移码的意义是因为，补码不能直观的比较大小

所以对补码加上 $2^n$ 则转换为移码



### 定点表示和浮点表示 :star:

#### 定点表示

- 定点数的二进制表示中，小数点的位置是固定的（通常在某个固定的位置）。
- 数值范围和精度取决于小数点的位置

#### 浮点表示

$$
N=S\times r^j
$$

$S$ 为尾数，$j$ 为阶码，$r$ 是基数

$r$ 可以取 2，4，8

- $r$ 越大，可表示的浮点数范围越大
- $r$ 越大，精度越低

浮点数表示形式

| 阶符  | 阶码的数值部分 | 数符  |  尾数的数值部分   |
| :---: | :------------: | :---: | :---------------: |
| $j_f$ | $j_1j_2...j_m$ | $S_f$ | $S_1S_2S_3...S_n$ |



### 定点运算

#### 移位运算

**算术移位规则**

<img src="pics/image-20221014040929135.png" alt="image-20221014040929135" style="zoom:50%;" />

**逻辑移位规则**

- 带上符号位一起移位（无论左移还是右移都补0）

#### 加减运算

**补码加**

整数
$$
[A]_补+[B]_补=[A+B]_补 (mod\ 2^{n+1})
$$
小数
$$
[A]_补+[B]_补=[A+B]_补 (mod\ 2^{n})
$$

**补码减**
$$
[A-B]_补=[A+(-B)]_补=[A]_补+[-B]_补 (mod\ 2^{n+1})
$$

**连同符号位一起相加，然后去除符号位的进位**

##### 溢出判断

1位符号位：

- 通常用符号位产生的进位和最高有效位产生的进位异或操作，结果为1即溢出


2位符号位：

- 变形补码，将符号位变成两位，2位符号位连同数值一起参与运算，而且高位产生的进位自动丢失，即可得到正确结果

- 当2位符号位不同时溢出




#### 乘法运算

##### 两位乘

我们有两个原码数，分别是 $A$ 和 $B$，其表示为：

$ A = (-1)^{s_A} \cdot M_A $
$ B = (-1)^{s_B} \cdot M_B $

1. **确定结果符号位：**
   - 乘积的符号位 $s_R$ 由两个乘数的符号位异或得到：
      $
      s_R = s_A \oplus s_B
      $

2. **数值部分的二进制乘法：**
   - 将 $M_A$ 和 $M_B$ 的数值部分按位相乘（忽略符号位）。可以采用“部分积”法（Partial Product Method）进行运算。

3. **部分积法的计算：**
   - 对 $M_B$ 的每一位 $b_i$，乘以 $M_A$ 的值，得到部分积。
   - 每个部分积向左移位相应的位数，然后将所有部分积相加。



**原码两位乘**是通过两位乘数的状态来决定新的部分积如何形成

<img src="pics/image-20221020183921564.png" alt="image-20221020183921564" style="zoom: 67%;" />

运算规则：

<img src="pics/image-20221020183952422.png" alt="image-20221020183952422" style="zoom:67%;" />

**实际操作** $$+[x^*]_补 \ \ \ \ +[2x^*]_补 \ \ \ \ +[-x^*]_补 \ \ \rightarrow$$  补码移



##### 补码一位乘

1. 被乘数符号任意，乘数符号为正

   和原码一样，但是加和移位都必须按照补码的规则运算

2. 被乘数任意，乘数符号为负

   把乘数的补码 $[y]_补$ 去掉符号位，当成一个正数和$$[x]_补$$相乘，然后加上一个$$[-x]_补$$校正

3. 取双符号位

补码乘法的符号位是在运算中自然形成的



1. 通过异或运算确定结果的符号位。
2. 忽略符号位，对数值部分进行按位乘法和移位相加。
3. 组合符号位和数值部分，得到最终结果。



### 浮点运算

#### 浮点四则运算

1. 对阶

   1. 小数向大数看起

2. 尾数求和

   1. 补码求和

3. 规格化

   当基数r=2时，尾数规格化形式为
   $$
   \frac{1}{2}\leq|S|<1
   $$
   S>0 时，规格化为
   $$
   [S]_补=00.1xx...x
   $$
   S<0 时，规格化为
   $$
   [S]_补=11.0xx...x
   $$
   特规定，$-\frac{1}{2}$不是规格化数，$$-1$$是规格化数

   符号位符合标准时左规，直到符合标准

   符号位不符合标准时，采用右规



## 第三章 系统总线

总线是一组能够为多个部件**分时共享**的信息传送线路

- 共享：允许总线连接多个部件
- 分时：同一时刻只允许有一个部件向总线发送信息

总线的特性：

1. 机械特性：尺寸、形状、管脚数、排列顺序
2. 电气特性：传输方向和有效的电平范围
3. 功能特性：每根传输线的功能(地址、数据、控制)
4. 时间特性：信号的时序关系



### 总线的分类:star:

- 按总线功能

  - 片内总线
  - 系统总线
  - 通信总线
- 按时序控制方式

  - 同步总线
  - 异步总线
- 按数据传输格式

  - 串行总线
    - 优点：只需要一根线
    - 缺点：需要考虑串行并行转换问题
  - 并行总线
    - 可以传输若干数据
    - 信号线数量多，频率高的时候会产生严重干扰
- 按照传送的信息
  - 控制总线
  - 数据总线
  - 地址总线




### 总线的结构

- 单总线
  - 都连接在一组总线上
- 双总线
  - 主存总线和IO总线
- 三总线
  - IO和主存间有DMA总线



### 总线控制

主设备：对总线有控制权

从设备：响应总线命令

#### 总线判优控制的分类

集中判优方式：

1. 链式查询
2. 计数器查询
3. 独立请求方式

分布判优方式：无中央仲裁器，每个潜在的主模块都有自己的仲裁器和仲裁号，多个仲裁器竞争使用总线。



### 总线操作和定时

- 同步通信：由统一时钟控制
  - 同步通信适用于总线长度较短及总线所接部件的存取时间比较接近的系统。
- 异步通信：采用应答方式，没有公共时钟标准
  - 适合速度不匹配的设备间的数据传输，提供给用户灵活性

> - 不互锁方式：速度最快 可靠性最差
>
>   - 主设备发出“请求”信号后，不必等到接到从设备的“回答”信号，而是经过一段时间，便撤销“请求”信号。
>     - 从设备在接到“请求”信号后，发出“回答”信号，并经过一段时间，自动撤销“回答”信号。
>     - 双方不存在互锁关系。
> 
>   
>
>- 半互锁方式：
>   - 主设备发出“请求”信号后，必须待接到从设备的“回答”信号后，才撤销“请求”信号，有互锁的关系。
>   - 从设备在接到“请求”信号后，发出“回答”信号，但不必等待获知主设备的“请求”信号已经撤销，而是隔一段时间后自动撤销“回答”信号，不存在互锁关系。
> 
>   
>   
> 
>   - 全互锁方式：最可靠 速度最慢
>    - 主设备发出“请求”信号后，必须待从设备“回答”后，才撤销“请求”信号;
>     - 从设备发出“回答”信号，必须待获知主设备“请求”信号已撤销后,再撤销其“回答”信号。双方存在互锁关系。
> 
>

- 半同步通信：同步、异步结合

  - 同步：发送方用系统时钟前沿发信号，接收方用系统时钟后沿判断、识别

    异步：允许不同速度的模块和谐工作

    半同步通信：统一时钟的基础上，增加一个“等待”响应信号WAIT


- 分离式通讯：都是主模块
  - 得到总线使用权后，发送数据，不等待对方的回答信号，使得总线保持有效工作



## 第四章 存储系统

大纲：

1. 存储系统的**构成机制与性能优化**
2. 虚拟存储器（Cache）的**工作原理与主要设计思考**
3. **地址的映象和变换方法及优化**
4. 页面（Cache块）**替换算法及其实现**
5. 虚拟存储器（Cache）**性能的优化方法**



### 存储系统概述

#### 存储系统的分类

按计算机中存储器的作用分类：

- 主存储器
- 辅助存储器
- 高速缓存存储器

按材料工艺分类：ECL、TTL、MOS、磁表面、激光，SRAM，DRAM。

按存取方式分类：

- 随机存储器（RAM）。RAM是一种计算机内存，用于存储正在运行的程序和当前使用的数据。你可以直接访问存储在任何位置的数据，而不需要按顺序查找。RAM是易失性存储器，这意味着一旦电源关闭，其中存储的数据就会丢失。‘
- 只读存储器（ROM）。存储器的内容只能随机读出而不能写入。即使断电，内容也不会丢失。

按访问方式分类：随机访问、直接译码、先进先出、相联访问、块传送、文件组。

**RAID 对比：**

![image-20231017141828613](assets/image-20231017141828613.png)

#### 存储器的性能指标

衡量主存性能指标：**访问时间、存储时间、带宽**

存储器的主要性能指标：**速度、容量、价格。**

- **速度** 用存储器的访问周期、读出时间、频带宽度等表示。
- **容量** 用字节B、千字节KB、兆字节MB和千兆字节GB等单位表示。
- **价格** 用单位容量的价格表示。
- 用户对存储器的“容量，价格和速度”要求的**理想情况**：0延迟；无限体积；零花费；无限带宽（支持多路并行访问）

  - 速度越快，每位价格就高

  - 容量越大，每位价格就低，速度就越慢

##### 存储系统容量

1. 尽可能大的地址空间
2. 能够随机访问

方法有两种：

- 只对系统中存储容量最大的那个存储器进行编址，其他存储器只在内部编址或不编址。
  - Cache存储系统。
- 另外设计一个容量很大的逻辑地址空间，把相关存储器都映射这个地址空间中。
  - 虚拟存储系统



##### 存储系统的速度:star:

访问周期、存取周期和存取时间等。

- 命中：访问的块在存储系统的较高层次上
  - 命中率：存储器访问较高层次命中的比例 $H=N_1/(N_1+N_2)$
  - 命中时间：访问较高层的时间
- 失效：访问的块不在存储系统的较高层次上
  - 失效：$1-(Hit\ Rate)=1-H=N_2/(N_1+N_2)$
  - 当在M1中没有命中时：一般必须从M2中将所访问的数据所在块搬到M1中，然后CPU才能在M1中访问。
  - 设传送一个块的时间为TB,即不命中时的访问时间为：$TA_2+TB+TA_1 = TA_1+TM$
  - $TM$：失效开销Miss Penalty 
- 访问周期与命中率的关系：
  - 平均访存时间 $TA = HTA_1+(1-H)(TA_1+TM) = TA_1+(1-H)TM$
  - 当命中率 $H→1$ 时，$T→ TA_1$

提高存储速度的途径：

- 提高缓存的命中率
- 两个存储器的速度不要差太大

采用预取技术提高命中率，不命中时，把$M_2$存储器中相邻多个单元组成的一个数据块取出来送入$M_1$存储器中。

$$
H^{\prime}=\frac{H+n-1}n
$$


##### 存储系统的访问效率

$H$ 为命中率，$T_1$ 为全部访问 cache 的时间
$$
e=\frac{T_1}T=\frac{T_1}{H\cdot T_1+(1-H)\cdot T_2}=\frac1{H+(1-H)\cdot\frac{T_2}{T_1}}=f(H,\frac{T_2}{T_1})
$$

### 存储系统的层次结构:star::star:

- 两个或两个以上速度、容量和价格各不相同的存储器用硬件、软件、或软件与硬件相结合的方法连接起来成为一个存储系统。
- 存储系统对程序员是透明的，从程序员看，它是一个存储器，这个存储器的速度接近速度最快的那个存储器，存储容量与容量最大的那个存储器相等，单位容量的价格接近最便宜的那个存储器。

#### 存储层次系统中应解决的四个问题

（1）映像规则：当把一个块调入高一层存储器时，可以放到哪些位置上。 

（2）查找算法：当所要访问的块在高一层存储器中时，如何找到该块。  

（3）替换算法：当发生失效时，应替换哪一块。  

（4）写策略：当进行写访问时，应进行哪些操作。



#### 局部性原理 :star::star::star:

- 一些重要的基本观察结果来自于程序的性质：**程序在任何时刻都只能访问相对较小的地址空间**
- **局部性原则：程序倾向于重用它们最近使用过的数据和指令**
- 有两种不同类型的局部性
  - 时间局部性（局部性）：如果一个块被引用，它很快就会被再次引用（循环、重用等）
  - 空间局部性（空间/位置中的局部性）：如果一个指令被引用，其地址彼此接近的指令往往很快被引用（直线代码、数组访问等）
- 一个程序将90%的执行时间花在10%的代码上

缓存利用了局部性原则：

- 转换：虚拟地址到物理地址的映射
- 保护：访问内存地址的权限
- 虚拟化：使用磁盘透明地扩展内存空间

<img src="assets/image-20231017143350917.png" alt="image-20231017143350917" style="zoom: 67%;" />

应用程序局部性原理：

- 一个采用低成本技术达到的存储容量（容量大，价格低）
- 一个采用高速存储技术达到的访问速度（速度快）



### 并行访问存储器

- 高位交叉编址：**扩大存储器容量**

  - 实现方法：用地址码的高位部分区分存储体号

  - 当程序按体内地址顺序存放，即一个体存满之后，再存入下一个体时，这种方式称为顺序存储，高位地址表示题号，低位表示体内地址（注意 0，1，2，3......的顺序是从上往下的）：

    <img src="https://pic1.zhimg.com/80/v2-5ce1a27d30dde3bbcf919feaa3803af4_720w.webp" alt="img" style="zoom:50%;" />

  - 因此，CPU给出一次存储访问总是对一块连续的存储单元进行的，在多CPU系统中，不同的CPU访问不同的存储块，达到并行工作。 存储轨迹可以用下面的线条表示：

    <img src="https://pic3.zhimg.com/80/v2-d84841bbae6325f6e479ddc7e3fb4ffe_720w.webp" alt="img" style="zoom:67%;" />

- 低位交叉编址：**提高存储器速度**

  - 对应于高位交叉编址，低位交叉编址指的是将程序连续存放在相邻体中，又称**交叉存储**。（注意，0 1 2 3的顺序是从左往右的）

    <img src="https://pic3.zhimg.com/80/v2-883da96c8a3810d130ae58ce708bdf76_720w.webp" alt="img" style="zoom:50%;" />

  - 这种做法可以在不改变存取周期的前提下，提高存储器带宽，因为可以在一个访问周期下，访问多个不同的存储体。适用于单处理器系统存储轨迹可以用下图表示：

  <img src="https://pic1.zhimg.com/80/v2-e6fbe65afd57f7f24ab59bd8e74c2d80_720w.webp" alt="img" style="zoom: 63%;" />



### 半导体随机存储器

#### SRAM和DRAM

![image-20240531133246934](assets/image-20240531133246934.png)

- **DRAM (Dynamic Random Access Memory)**：
  - 电容存储数据，电容器会随着时间慢慢泄漏电荷
  - 破坏性读出
  - DRAM需要定期刷新这些电容器中的电荷，这个过程称为“刷新”操作
  - 便宜 高密度，但速度稍慢且需要更多的能量来维持数据。
  - 是现代计算机中最常用的主内存形式。
- **SRAM(Static Random Access Memory)**：
  - 触发器存储数据
  - 非破坏性读出
  - 不需要刷新
  - 比寄存器慢，因为增加了寻找正确缓存位置的电路，但比RAM快得多；
  - 常用作Cache的材料

##### DRAM的刷新

- 2ms刷新一次
- 一次刷新一行，刷新仅需要行地址
- 硬件读出后重新写入

刷新时刻：

- 分散刷新
  - 每次读写完都刷新一行
- 2ms内集中安排时间全部刷新
  - 有一段专门的时间用于刷新，被称为“死区”
- 异步刷新
  - 每2ms内刷新每行一次，假设有128行，则在2ms/128周期内有一个刷新。

#### ROM

- 掩模式只读存储器
- 一次可编程只读存储器
- 可擦除可编程只读存储器
- 闪速存储器
- 固态硬盘



### 虚拟存储器（Virtual Memory）

#### 虚拟缓存器工作原理

把主存储器、磁盘存储器和虚拟存储器都划分为固定大小的页：

- 主存储器的页称为实页
- 虚拟存储器中的页称为虚页

虚拟存储器为操作系统和应用程序提供了多项重要优势：

1. **扩大可用内存空间**：虚拟存储器通过硬盘空间来扩展物理内存（RAM），使得系统能够运行比物理内存更大的程序和数据集。这意味着即便物理内存有限，也能高效地运行大型应用程序。
2. **内存管理简化**：对于程序而言，虚拟存储器提供了一个连续的内存地址空间，从而简化了内存的管理。程序员无需关心物理内存的分配和管理，可以专注于程序逻辑。
3. **内存保护**：每个程序在虚拟空间中都有自己的地址空间，这有助于防止一个程序访问另一个程序的数据和代码，从而增强了系统的稳定性和安全性。
4. **数据共享和通信**：虚拟存储器允许不同的程序共享内存中的数据。这对于多任务操作系统中进程间的通信和数据共享非常重要。

在虚拟存储器的设计和实现过程中，需要应对多种挑战，主要包括：

1. **页面置换算法的选择**：虚拟存储器依赖于页面置换算法来决定哪些数据应该保留在内存中，哪些应该移动到硬盘。选择合适的页面置换算法（如LRU、FIFO、Clock算法等）对于系统性能至关重要。算法需要平衡内存利用率和页面置换成本。
2. **内存和磁盘的速度差异**：由于磁盘访问速度远慢于RAM，因此频繁的页面交换（Paging）会严重影响系统性能。设计时需要有效减少页面错误（Page Fault）的发生。
3. **内存碎片问题**：虚拟存储器需要有效管理内存碎片，特别是避免过多的小碎片造成的内存浪费。

#### 地址的映象和变换方法

- 三种地址空间：
  - 虚拟地址空间
  - 主存储器地址空间
  - 辅存地址空间（磁盘空间）
- 地址映象：
  - 把虚拟地址空间映象到主存地址空间
- 地址变换：
  - 在程序运行时，把虚地址变换成主存实地址
- 三种主要虚拟存储器：
  - 段式虚拟存储器
  - 页式虚拟存储器
  - 段页式虚拟存储器

##### 段式虚拟存储器

每访问一个数据，需要访问两次内存

方便编程：用户通常把自己的程序按逻辑关系分成若干段

> 共享：页只是信息存放的物理单位，没有实际意义，段是逻辑单位
>
> 保护：同样是对逻辑单位的包含，分段管理更容易实现

因为段的大小不一定，所以一定会产生碎片，解决碎片的办法：

1. 紧凑（开销很大）
2. 把段放入已经存在的洞中

放入段的算法：1. 最合适 2. 最先满足



##### 页式虚拟存储器

- 把虚拟地址空间划分为固定大小的块，每一块称为1页
- 主存的地址空间也划分为同样大小的页
- 用户程序只需要将虚页号变换为实页号即可实现到主存实地址空间的映像

页面和页表

1. 页面

   - 将逻辑地址空间分成若干大小相等的片，称为页面或页(page)。页号从0开始。
   
   
      - 内存空间分成与页大小相同的若干存储块，称为块或页框(frame)。也从0开始编号。
   
   
      - 页框=页帧=内存块=物理块=物理页面
   
   
      - 为进程分配内存时，以**块为单位将进程中的若干页分别装入到多个可以不相邻的物理页**中。最后一个页不满，称为页内碎片。 
   
   
      - **页的大小**：通常为512B～8KB 
   
2. 地址结构

   - 分页逻辑地址可以分为：$页号P+分页地址d$
   - 对于特定的机器来说，其地址结构是一定的


3. 页表
   - 系统为每个进程建立一张表，记录了相应页在内存中对应的物理块


基本的地址转换机构：

<img src="assets/image-20230423163942559.png" alt="image-20230423163942559" style="zoom:67%;" />

主要优点：

- 主存储器的利用率比较高。每个用户程序只有不到1页的浪费。
- 页表相对比较简单。需保存的字段数比较少。
- 地址变换的速度比较快。只需建立虚页和实页之间的联系即可。
- 对磁盘的管理比较容易。一页的大小是磁盘快大小的整数倍。

主要缺点：

- 程序的模块化性能不好。一页可能多个程序或者部分程序。
- 页表很长，需要占用很大的存储空间。
- 例如：虚拟存储空间4GB，页大小1KB，则页表的容量为4M存储字，16MB。



##### 段页式虚拟存储器

分页系统能有效地提高内存利用率

分段系统能很好地满足用户的需要，分段大小可以由用户决定

**原理：**将用户程序分成若干段，然后把段分成若干页

逻辑地址由3部分组成：段号，段内地址，页内地址



地址映象方法：每个程序段在段表中占一行，在段表中给出页表长度和页表的起始地址，页表中给出每一页在主存储器中的实页号

地址变换方法：先查段表，得到页表起始地址和页表长度，再查页表找到要访问的主存实页号，把实页号 $p$ 与页内偏移 $d$ 拼接得到主存实地址



##### 页表级数计算公式

$$
g=\left[\frac{\log2N_\nu-\log2N_p}{\log2N_p-\log2N_d}\right]
$$

$N_v$ 为虚拟存储空间大小，$N_p$ 为页面的大小，$N_d$ 为一个页表存储字的大小。

#### 加快内部地址变换的方法

1. 目录表

   - 基本思想：压缩页表存储容量，用一个小容量高速存储器存放页表，加快页表的查表速度。页表只为装入到主存的那些页面建立虚页号与实页号之间的对应关系。

   - 地址变换过程：把多用户虚地址中U与P拼接，相联访问目录表。读出主存实页号p，把p与多用户虚地址中的D拼接得到主存实地址。如果相联访问失败，发出页面失效请求。

   - 主要优点：与页表放在主存中相比，查表速度快。

   - 主要缺点：可扩展性比较差。主存储器容量大时，目录表造价高，速度低。

2. 快慢表

   - 快表(Translation Lookaside Buffer)：小容量(几～几十个字)。高速硬件实现。采用相联方式访问。

   - 慢表：当快表中查不到时，从主存的慢表中查找。快表是慢表的部分副本。访问速度接近快表，存储容量是慢表的容量。慢表按地址访问；用软件实现。

   - 快表与慢表也构成一个两级存储系统。

   - 主要问题：相联访问实现困难，速度低。

3. 散列函数

   - 目的：把相联访问变成按地址访问

   - 按地址查找信息，散列(Hashing)函数最快，对于快表就是要把多用户虚页号变成快表的地址：$A_h＝H(P_v)$

   - 把一个大得多的多用户虚页号Pv散列变成一个小的快表地址，必然有很多个多用户虚页号都变到相同的快表地址中，这种现象称为散列冲突。

   - 为避免散列冲突，必须把多用户虚页号也加入到快表中，并且与主存实页号存放到同一个快表存储字中。

   - 需要一个比较器，把快表中读出来的多用户虚页号与多用户虚地址中的虚页号进行比较。
     - 比较结果相等，继续正常进行主存的访问。
     - 比较结果不等，发生了散列冲突，需要查询主存中的慢表。

4. 倒排页表

   在传统的页表中，每个进程都有自己的页表，而在倒置页表结构中，整个系统只有一个页表，用于所有的进程。
   在倒置页表中，表的每一项不再直接对应特定进程的虚拟页，而是对应物理内存中的一个页框（Page Frame）。每个条目包含了映射到该页框的虚拟页信息，以及拥有该虚拟页的进程标识（如进程ID）。由于这种结构，倒置页表通常需要结合某种**快速查找技术**来有效地解析地址。

   实现步骤通常包括：

   **散列技术**：为了快速查找对应的物理页，IPT通常与散列技术结合使用。系统会使用一个散列函数来将虚拟地址映射到IPT中的条目。如果发生散列冲突，则可能需要链表或其他结构来处理这些冲突。

   **查找过程**：当进行虚拟地址到物理地址的映射时，系统会取出虚拟地址中的虚拟页号和进程标识，然后使用散列函数定位到IPT中的一个特定条目。然后，系统会检查该条目是否为正确的虚拟页和进程。如果是，那么就可以直接从该条目获取物理页号，完成映射。如果不是，系统需要遍历链表（如果使用了链表来处理冲突）来找到正确的条目。

   **处理缺页**：如果所需的虚拟页不在内存中，就会发生缺页中断，操作系统需要从磁盘上加载相应的页到内存中，并更新IPT。



#### 页面替换算法及其实现

1. 随机算法（RAND random algorithm）

2. 先进先出算法(FIFO first-in first-out algorithm)
   
3. 近期最少使用算法(LFU least frequently used algorithm)
   
4. 最久没有使用算法(LRU least recently used algorithm)
   
5. 最优替换算法（OPT optimal replacement algorithm）
   
6. 堆栈型替换算法
   定义：对任意一个程序的页地址流作两次主存页面数分配，分别分配m个主存页面和n个主存页面，并且有m≤n。如果在任何时刻 t，主存页面数集合Bt都满足关系：
            Bt（m）属于 Bt（n），
   则这类算法称为堆栈型替换算法。
   堆栈型算法的基本特点是：随着分配给程序的主存页面数增加，主存的命中率也提高，至少不下降。

   堆栈型替换算法的命中率随分配给该程序的主存页面上升而单调上升。

在多道程序中采用页面失效频率法动态调度页面。根据各道程序在实际运行过程中页面失效率的情况，由操作系统动态调整分配给每道程序主存页面数。当一道程序命中率低于某个限定值时就增加分配给该程序的主存页面书，以提高命中率。但某程序命中率高于某限定值时，将降低其主存页面数。

### 高速缓冲存储器(Cache)

虚拟存储器系统：对应用程序员透明

- 由主存储器和硬盘构成

- 目的：扩大存储器容量

  <img src="assets/image-20231017144024343.png" alt="image-20231017144024343" style="zoom:50%;" />

Cache存储系统：对系统程序员以上透明

#### 基本工作原理

地址映象：把主存中的程序按照某种规则装入到Cache中，并建立主存地址与Cache地址之间的对应关系。

地址变换：当程序已经装入到Cache之后，在程序运行过程中，把主存地址变换成Cache地址。

#### 地址映象与变换方法:star::star:

##### 全相联映象及其变换

<img src="https://img-blog.csdnimg.cn/f5b59dc73e4a46cf945c117e327bdc91.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBALem3vi0=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom: 50%;" />

映象规则：主存的任意一块可以映象到Cache中的任意一块。映象关系有 $C_b×M_b$ 种。

主存地址划分（没有索引）：

<img src="https://img-blog.csdnimg.cn/ffc15eb000534cedaeffd7a18510839d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBALem3vi0=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:33%;" />

需要结构：采用**目录表**存放这种关系，目录表的容量为$C_b$，字长为Cache地址中的块号长度加主存地址中的块号长度，再加1位有效位。

替换算法：

1. 利用主存地址去访问主存，将主存一个字内容送到CPU。
2. 包括被访问字的一块内容替换到Cache中。

3. 修改目录表中的主存块号字段，把当前的主存块号B写到目录表的存储字中。

4. 有效位表示目录表中各个存储字是否有效。
   如果为1，表示目录表中主存块号B与Cache块号b建立的映像有效，b是B的正确副本。
5. 如果为0，表示B和b之间映像无效，或没有关系。

优点：块的冲突率最小。Cache利用率最高。

缺点：需要一个相联访问速度很快，容量为Cb的相联存储器（目录表），代价高。相联比较所花费的时间会影响到Cache的访问速度

##### 直接映象及其变换

<img src="https://img-blog.csdnimg.cn/83990b8e103d4b29a0a00c4ae448870d.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBALem3vi0=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:50%;" />

映象规则：主存储器中一块只能映象到Cache的一个特定的块中。

Cache地址的计算公式：$b＝B\mod C_b$。其中：b为Cache块号，B是主存块号，$C_b$是Cache块数。

**地址划分**

<img src="https://img-blog.csdnimg.cn/4ef5f4373ce64e0190636f366f1f3615.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBALem3vi0=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:50%;" />

**主存划分的计算**

<img src="https://img-blog.csdnimg.cn/0c5e874a80d84d118c54bb8b36e664fb.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBALem3vi0=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:50%;" />

优点：硬件实现很简单，不需要相联访问存储器，访问速度也比较快，实际上不需要进行地址变换

缺点：块的冲突率比较高。主存中多块都映像到Cache同一块中，又是常用块，Cache的命中率很低。

##### 组相联映像及其实现

<img src="https://img-blog.csdnimg.cn/5edb667866a949018d8d3a3f40ccf98f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBALem3vi0=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:50%;" />

映象规则：

- 主存和Cache按同样大小划分成块和组。
- 主存和Cache的组之间采用直接映象方式。
- 组的内部采用全相联映象方式。

组相联映象方式的优点：块的冲突概率比较低，块的利用率大幅度提高，失效率明显降低。

<img src="https://img-blog.csdnimg.cn/1937598a40c7411a8a38beb48fd77dd5.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBALem3vi0=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom:50%;" />

<img src="https://img-blog.csdnimg.cn/100dae33b0bf4a24b7f1103cb7098c39.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBALem3vi0=,size_20,color_FFFFFF,t_70,g_se,x_16" alt="img" style="zoom: 50%;" />

##### 段相联映像及其实现

映象规则：

- 主存和Cache按同样大小划分成段和块。
- 主存和Cache的段之间采用全相联映象方式。
- 段的内部采用直接映象方式。

#### Cache替换算法及其实现

##### 轮换法

用于组相联映象方式中，有两种实现方法。

1. 为每一块设置一个计数器字段，字段长度与组内块号字段长度相同
   - 新装入或替换的块，它的计数器清0，同组其它块的计数器都加“1”。
   - 在同组中选择计数器的值最大的块作为被替换的块。
2. 为每一组设置一个计数器，每次访问计数器加一，计数器的值为多少，替换哪一个块
   - 优点：简单；缺点：没有利用局部性


##### LRU

未每一块设置一个计数器，计数器的长度与块号字段的长度相同



#### Cache存储系统的加速比

##### 加速比与命中率的关系

Cache存储系统的加速比 $S_P$ 为：
$$
S_P=\frac{T_m}{T}=\frac{T_m}{H\cdot T_c+(1-H)\cdot T_m}=\frac{1}{(1-H)+H\cdot\frac{T_c}{T^m}})=f(H,\frac{T_m}{T_c})
$$
其中：$T_m$ 为主存储器的访问周期，$T_c$ 为Cache的访问周期，$T$ 为Cache存储系统的等效访问周期，$H$ 为命中率。提高加速比的最好途径是提高命中率。

##### Cache命中率与容量的关系

Cache的命中率随它的容量的增加而提高，关系曲线可以近似地表示为：$H=1-\frac1{\sqrt{S}}$

<img src="assets/image-20231231163645774.png" alt="image-20231231163645774" style="zoom: 50%;" />

##### Cache命中率与块大小的关系

- 在组相联方式中，块大小对命中率非常敏感。
- 块很小时，命中率很低。随着块大小增加命中率也增加，有一个极大值。
- 当块非常大时，进入Cache中的数据可能无用。
- 当块大小等于Cache容量时，命中率将趋近零。

<img src="assets/image-20231231163731664.png" alt="image-20231231163731664" style="zoom: 67%;" />

##### Cache命中率与组数的关系

- 在组相联方式中, 组数对命中率的影响很明显。
- 随着组数的增加，Cache的命中率要降低。
- 当组数不太大时(小于512)，命中率的降低很少。
- 当组数超过一定数量时，命中率的下降非常快。

#### Cache读写策略:star::star:

1. Cache写入命中（Write Hit）

   - 写直达法，写通过法，WT(Write-through)：CPU的数据写入Cache时，同时也写入主存。
   - 写回法，抵触修改法，WB(Write-Back)：CPU的数据只写入Cache，不写入主存，仅当替换时，才把修改过的Cache块写回主存。

   优缺点对比：

   - 可靠性，写直达法优于写回法。
   - 与主存的通信量，写回法少于写直达法，也就是说写回法快。

2. Cache写入缺失（Write Miss）：

   - 按写分配 Write allocate： 把要写的数据载入到Cache中，写Cache，然后再通过flush方式写入到内存中。
   - 不按写分配 No write allocate： 直接把要写的数据写入到内存中。

3. Cache读缺失：

   - 直接从内存中读取数据。
   - 先把数据读取到Cache，再把Cache中数据读出。



#### Cache失效的原因 3C:star:

**强制性失效 (Compulsory)**

- 第一次访问某一块，只能从下一级Load，也称为冷启动或首次访问失效

**容量失效（Capacity)**

- 如果程序执行时，所需块由于容量不足，不能全部调入Cache， 则当某些块被替换后，若又重新被访问，就会发生失效。
- 可能会发生“抖动”现象

**冲突失效（Conflict)**

- 组相联和直接相联的副作用
- 若太多的块映像到同一组（块）中，则会出现该组中某个块被别的块替换（即使别的组或块有空闲位置)，然后又被重新访问的情况，这就属于冲突失效



#### Cache的预取算法:star:

1. 按需取：不命中时，取一个块
2. 恒预取：不管是否命中，都把紧接着的块装入
3. 不命中预取：当CPU访问存储器时，Cache如果不命中，就把当前块和下一块装入



### 三级存储系统

- 虚拟存储系统和Cache 存储系统可同时存在
- 存储系统可以有多种构成方法，不同的构成只是实现技术不同

<img src="assets/image-20231109142540760.png" alt="image-20231109142540760" style="zoom:50%;" />

既有虚拟存储器又有Cache系统：

- 虚拟存储器次啊用**位选择组相联方式**
- 虚拟存储器中的一页等于主存储器的一个区
- 用虚拟地址中的虚页号访问快表

#### 全cache存储系统

全Cache(all-Cache)是一种理想的存储系统，建立存储系统的目的：获得一个速度接近Cache，容量等于虚拟地址空间的存储器。

- 这个存储器如何构成，具体分成几级来实现，只是具体的实现技术而已。
- 随着计算机硬件和软件技术的发展，存储系统的实现技术也在不断改变。
- 最直接最简单的方法：用一个速度很高，存储容量很大的存储器来实现。



**缓存-主存** ：解决 **速度** 需求

**主存-辅存** ：解决 **容量** 需求

CPU与Cache连接方式

- CPU在片内连接Cache比在片外连接Cache具有更高的速度指标
- CPU与Cache之间的数据通道越多，则速度越快
- 一级CACHE集成在CPU同一芯片内，二级一般也在CPU同一芯片内，有的在芯片外；有的CPU还提供专门通道连结第三级CACHE。

#### 存储器的选择

1. 确定地址
2. 确定片选
3. 确定cpu地址线，数据线，片选线
3. 注意几根线W/R线



#### 汉明码

偶校验 1，2，4，8是校验位

分组：第几组的校验内容是倒数第几位是1的数

偶校验的话是校验位加检验组异或为0



#### Cache主存地址映射

1. 直接映射
2. 全相联映射
3. 组相联映射



## 第五章 输入/输出系统

### 输入/输出原理

输入/输出系统：**处理机与主存储器之外的部分**

包括**输入输出设备**、**输入输出接口**和**输入输出软件**

#### 输入输出系统的特点

- 处理机与外界进行数据交换的通道
- 异步性
  - 输入输出系统通常没有统一的中央时钟，各个设备按照自己的时钟工作
  - 外围设备与外围设备之间能并行工作
- 实时性
  - 如果处理机提供服务不及时，可能丢失数据，或造成外围设备工作的错误
  - 对于处理机本身的硬件或软件错误：如电源故障、数据校验错、页面失效、非法指令、地址越界等，处理机必须及时处理。
  - 对不同类型的设备，必须具有与设备相配合的多种工作方式。
- 与设备无关性
  - 独立于具体设备的标准接口
  - 处理机采用统一的硬件和软件对品种繁多的设备进行管理。

#### 输入输出系统的组织方式

- 针对实时性，采用层次结构的方法。
  - 最内层是输入输出处理机、输入输出通道等。
  - 中间层是标准接口。
  - 标准接口通过设备控制器与输入输出设备连接。
- 针对与设备无关性，采用分类处理的方法。
  - 面向字符的设备，如字符终端、打字机等
  - 面向数据块的设备，如磁盘、磁带、光盘等。
- 针对异步性，采用自治控制的方法。
  - 输入输出系统是独立于CPU之外的自治系统处理机与外围设备之间要有恰当的分工



### I/O系统基本概念

![在这里插入图片描述](assets/20210120105942936.png)

![在这里插入图片描述](assets/20210120110325900.png)



### I/O设备

**设备类型：**

输入设备：键盘鼠标

输出设备：打印机显示器

外存设备：磁盘、机械硬盘、固态硬盘、光盘



### I/O接口

**I/O接口概念：**

<img src="assets/20210120110518182.png" style="zoom:67%;" />

**I/O接口 是主机与I/O设备之间设置的一个硬件电路及其相应的软件控制**

接口的功能（需要解决的问题）：

- 实现设备选择和地址译码
- 传送命令的功能：有存放命令的命令寄存器以及命令译码器
- 传送数据的功能：数据缓冲器
- 信号格式转换
- 反映I\O设备工作状态的功能：完成触发器D和工作触发器B

接口类型：

- 按数据传送方式分类：并行接口和串行接口
- 按功能选择的灵活性分类：可编程接口和不可编程接口
- 按通用性分类：通用接口和专用接口
- 按数据传送的控制方式分类：程序型接口和DMA接口

#### 访问I/O的基本流程

![在这里插入图片描述](assets/20210120130738612.png)

#### I/O端口

I/O端口是指接口电路中可以被CPU直接访问的寄存器

#### I/O编址方式

![](assets/20210120131540410.png)



### I/O方式

#### 程序查询方式

只要启动I/O设备，CPU就在不断查询能否读取数据，导致CPU等待，不能继续执行程序。

程序控制输入输出方式有4个特点：

1. 何时对何设备进行输入输出操作受CPU控制。
2. CPU要通过指令对设备进行测试才能知道设备的工作状态。如：闲、准备就绪、忙碌等
3. 数据的输入和输出都要经过CPU。
4. 用于连接低速外围设备，如终端、打印机等。

![在这里插入图片描述](assets/20210120135231238.png)

##### 例题

问：一个处理机在一段时间内只能管理一台打印机。处理机执行指令的速度为1GIPS，字长32位，打印机每秒钟100个字符？

解：处理机用一条指令就能向打印机传送4个字符。因此，处理机的实际利用率只有即4千万分之一。 
$$
100/10^9\times 4＝0.25\times 10^{-7}
$$

#### 程序中断方式

CPU启动I/O设备后，不查询设备是否已就绪，继续执行自身的程序，只是当I/O设备准备就绪并向CPU发出中断请求后才予以响应。

特点：

1. CPU与外围设备能够**并行工作**。
2. 能够处理例外事件。
3. 数据的输入和输出都要经过CPU。
4. 用于连接低速外围设备。

![在这里插入图片描述](assets/20210120150843694.png)

#### DMA方式 :star::star:

直接存储器访问方式（DMA：Direct Memory Access），主要用来连接高速外围设备。

主存和 I\O 设备中有一条数据通路，主存与 I\O 设备交换信息时，无须调用中断服务程序。

<img src="assets/image-20231222085124414.png" alt="image-20231222085124414" style="zoom:70%;" />

- DMA在 I/O 设备和主存之间自动传输数据
  - 通过内存映射寄存器编程的直接存储器存取
  - 外围设备的访问请求直接发往主存储器，数据的传送过程不需要CPU的干预。
  - 全部用硬件实现，不需要做保存现场和恢复现场等工作。
  - DMA控制器复杂，需要设置**数据寄存器、设备状态控制寄存器、主存地址寄存器、设备地址寄存器和数据交换个数计数器**及控制逻辑等。
  - 在DMA方式开始和结束时，需要处理机进行管理。



**DMA输入设备的工作流程如下：**

- 从设备读一个字节到DMA控制器中的数据缓冲寄存器中。
- 若一个字没有装配满，则返回到上面；若校验出错，则发中断申请；若一个字已装配满，则将数据送主存数据寄存器。

- 把主存地址送主存地址寄存器，并将主存地址增值。

- 把DMA控制器内的数据交换个数计数器减1。

- 若交换个数为0，则DMA数据传送过程结束，否则回到上面



**DMA输出设备的工作流程如下：**

- 把主存地址送入主存地址寄存器，并启动主存储器，同时将主存地址增值。
- 将主存数据寄存器中的数据送DMA控制器的数据寄存器。

- 把数据写到输出介质上（可能要逐个字符输出）。

- 把DMA控制器内的数据交换个数计数器中的内容减1。

- 若交换个数为0，则DMA数据传送过程结束，否则回到上面。



目前使用DMA的方式：

- 周期窃取方式：
  - 若出现DMA和CPU同时访问主存，CPU总是将总线占有权让给DMA，通常把DMA的这种占有称为窃取或挪用。窃取的时间一遍为一个存储周期，故又把DMA占用的存储周期称为窃取周期
  - 在每一条指令执行结束时，CPU**检测**有没有DMA服务申请。
  - 借用CPU完成DMA工作流程：数据和主存地址的传送，交换个数计数器减1，主存地址的增值及测试判断等。
  - 优点：硬件结构简单，比较容易实现。
  - 缺点：在数据输入或输出过程种实际上占用了CPU的时间。

- 直接存取方式：
  - 整个工作流程全部用硬件完成。
  - 优点与缺点正好与周期窃取方式相反。
- 数据块传送方式：
  - 在设备控制器中设置一个比较大的数据缓冲存储器。设备控制器与主存储器之间的数据交换以数据块为单位，并采用程序中断方式进行。	
  - 采用数据块传送方式的外围设备有软盘驱动器、行式打印机、激光打印机、卡片阅读机、绘图仪等。



### 通道处理机

通道处理机的作用主要是在外围设备种类、数量很多的情况下把外围设备的管理工作从CPU中分离出来。

处理机与外部设备的连接方式：

- 直接连接
- 通道处理机
- 输入输出处理机

I/O 指令和通道指令有何区别？

- I/O 指令是CPU指令系统的一部分，是CPU用来控制输入/输出操作的指令，由CPU译码后执行。在具有通道结构的机器中，I/O指令不实现I/O数据传送，主要完成启、停I/O设备，査询通道和I/O设备的状态，及控制通道进行其他一些操作等
- 通道指令是通道本身的指令，用来执行I/O操作，如读、写、磁带走带及磁盘找道等操作

三种基本输入输出方式存在的问题：

1. CPU的输入输出负担很重，不能专心用于用户程序的计算工作
2. 低速外围设备，每传送每个字符都由CPU执行一段程序来完成

3. 高速外围设备的初始化、前处理和后处理等工作需要CPU来完成

4. 大型机中的外围设备台数很多，但一般并不同时工作。让DMA控制器能被多台设备共享，提高硬件的利用率

#### 通道的作用和功能:star:

通道处理机能够负担外围设备的大部分输入输出工作，包括管理所有**按字节传输方式工作**的低速和中速外围设备，按**数据块传输方式工作**的高速设备。对DMA接口初始化，设备故障的检测和处理。

可以看作一台能够执行**有限输入输出指令**，并且能够被多台外围设备共享的小型DMA专用处理机。

在一台大型计算机系统中可以有多个通道，一个通道可以连接多个设备控制器，一个设备控制器又可以管理一台或者多台外围设备。形成典型的I/O系统四层结构。

通道的主要功能：

- 接受CPU发来的指令，选择一台指定的外围设备与通道相连接
- 执行CPU为通道组织的通道程序
- 管理外围设备的有关地址
- 管理主存缓冲区的地址
- 控制外围设备与主存缓冲区之间数据交换的个数（传送计数）
- 指定传送工作结束时要进行的操作
- 检查外围设备的工作状态
- 在数据传输过程中完成格式变换

#### 通道的工作过程

通道完成一次数据输入输出的过程分为三步：

1. 在用户程序中使用访管指令进入管理程序，由CPU通过管理程序组织一个通道程序，并启动通道。
2. 通道处理机执行通道程序，完成指定的数据输入输出工作。

3. 通道程序结束后再次调用管理程序进行处理。


每完成一次输入输出工作，CPU只需要两次调用管理程序（两次中断）。

<img src="assets/image-20231228185026522.png" alt="image-20231228185026522" style="zoom:50%;" />

#### 三种通道及传输方式:star::star:

1. 字节多路通道

   - 为**多台**低中速的外围设备服务。字节交叉，“分时复用”


      - 有多个子通道，每个子通道连接一个控制器。


2. 选择通道

   - 为多台高速外围设备服务


      - 只有一个以成组方式工作的子通道，在**一段时间内只为一台高速外设`独占使用`**。


      - 高速外围设备必须设置专门通道在一段时间单独为一台外围设备服务，不同时间可以选择不同设备。一旦选中，通道进入忙状态。直至数据传输结束。

3. 数组多路通道

   - 字节多路通道和选择通道的结合。
   - 每次为一台高速设备传送一个数据块，并轮流为多台外围设备服务。
   - 从磁盘存储器读出文件的的过程分为三步：定位、找扇区、读出数据
   - 数组多路通道的实际工作方式：在为一台高速设备传送数据的同时，有多台高速设备可以在定位或者在找扇区（查找扇区的时间远长于传输时间）。
   - 与选择通道相比，数组多路通道的数据传输率和通道的硬件利用都很高，控制硬件的复杂度也高。



#### 通道流量分析 :star::star:

通道流量：单位时间内能够传送的最大数据量。又称通道吞吐率，通道数据传输率等。

通道最大流量：通道在满负荷工作状态下的流量。

通道流量与连接在通道上的设备的数据传输率的关系如下：
$$
f_{BYTE}=\sum_{i=1}^pf_i\quad f_{SELETE}=\operatorname*{Max}_{i=1}^pf_i\quad f_{BLOCK}=\operatorname*{Max}_{i=1}^pf_i
$$
三种通道的最大流量计算公式：
$$
\begin{aligned}
&\begin{aligned}f_{MAX.BYTE}&=\frac{p\cdot n}{(T_S+T_D)\cdot p\cdot n}=\frac{1}{T_S+T_D}\text{字节/秒}\end{aligned} \\
&\begin{aligned}f_{MAX.SELETE}&=\frac{p\cdot n}{(T_S/n+T_D)\cdot p\cdot n}=\frac{1}{T_S/n+T_D}\text{字节/秒}\end{aligned} \\
&\begin{aligned}f_{MAX.BLOCK}&=\frac{p\cdot n}{(T_S/k+T_D)\cdot p\cdot n}=\frac{1}{T_S/k+T_D}\text{字节}/\text{秒}\end{aligned}
\end{aligned}
$$
- Ts：设备选择时间（准备时间）

- Td：传送一个字节所用的时间
- p: 在一个通道上连接的设备台数，且这些设备同时都在工作。
- n: 每台设备需要传输的字节数，这里假设每台设备传输字节数都一样
- K: 数组多路通道传输一个数据块中所包含的字节数
- T: 通道完成全部数据传送工作所需要的时间

为保证通道不丢失数据，通道的实际流量应不大于通道最大流量



### 输入输出处理机

通道处理机存在如下问题：

1. 每完成一次输入输出操作要两次中断CPU的现行程序

2. 通道处理机不能处理自身及输入输出设备的故障

3. 数据格式转换、码制转换、数据块检验等工作要CPU完成

4. 文件管理、设备管理等工作，通道处理机本身无能为力

根据是否共享主存储器分为：

1. 共享主存储器的输入输出处理机
2. 不共享主存储器的输入输出处理机

根据运算部件和指令控制部件是否共享分为：

1. 合用同一个运算部件和指令控制部件：造价低，控制复杂。
2. 独立运算部件和指令控制部件：独立运算部件和指令控制部件已经成为主流。

#### 输入输出处理机的作用

输入输出处理机的多种组织方式：

- 多个输入输出处理机从功能上分工。
- 以输入输出处理机作为主处理机。
- 采用与主处理机相同型号的处理机作为输入输出处理机。
- 采用廉价的微处理机来专门承担输入输出任务。



### 中断系统

#### 中断的基本定义

当出现来自 系统外部，机器内部，甚至处理机本身的异常或者特殊情况，**CPU暂停执行现行程序，转去处理这些事件，等处理完成后再返回来继续执行原先的程序。**

#### 中断的基本流程

1. 中断请求
   - 中断源向CPU发送中断请求信号
2. 中断响应
   - 响应中断的条件
   - 选择优先级最高的中断请求
3. 中断处理
   - 中断隐指令
   - 中断服务程序

#### 中断请求的分类

- 中断系统需要**硬件和软件**共同来实现，引起中断的各种事件称为**中断源**。
- 中断系统的复杂性实际上主要是由**中断源的多样性**引起的。
- 中断源可以来自**系统外部**，也可以来自**机器内部**，甚至**处理机**本身。
- 中断可以是硬件引起的，也可以是软件引起的。

##### 中断源的种类

- 内中断（异常、陷入）
  - 由**处理机本身**产生的中断：如算术溢出，除数为零，数据校验错等
  - 由**存储器产生**的中断：如地址越界、页面失效、访问存储器超时等
  - 由**控制器产生**的中断：如非法指令、堆栈溢出、时间片到、切换到特权态
  - 由**总线产生**的中断：输入输出总线出错,存储总线出错等
- 外中断（中断）
  - 由**外围设备**引起的中断：低速外围设备每传送一个字节申请一次中断；高速外围设备的前、后处理。
  - 程序调试过程中，由断点产生的中断
  - 多处理机系统中，从其它处理机发送来的中断
  - 实时过程控制产生的中断

##### 中断源的分类组织

- 中断源分类组织的目的：在**响应中断后能尽快找到中断入口。**
- 根据中断事件的**紧迫程度**，中断源工作速度、性质等进行分类
- **为每一类中断源分配一个硬件的中断入口，**在进入这个入口之后，再通过软件找到具体的中断源。
- 可屏蔽中断与不可屏蔽中断，或称**一般中断和异常中断**。

##### 中断源的识别方法

**中断请求线**：

- 所有中断源共用一条中断请求线
- 处理机响应中断后都进入同一个程序入口
- 用软件找出申请中断的中断源
- 主要优点：灵活性好。主要缺点：速度慢。

![image-20231222092240386](file://C:/Users/23472/Desktop/study-note/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/assets/image-20231222092240386.png?lastModify=1716792370)



**软件排队链法**：

- 设置一个中断请求寄存器，每个中断源在其中占据一位，并且按照中断的优先级从高位到低的顺序排列。
- 所有中断源使用同一条公共的中断请求线，进入公共中断源服务程序入口，其过程与查询法相同。
- 在公共中断服务程序入口，用一条特殊指令读出中断请求寄存器中的内容，并根据读出的内容直接进入中断服务程序。



**硬件排队链法**：

- 用硬件排队器和编码器，在所有请求中断服务的中断源中，找出具有最高优先级的中断源。
- 设置一个中断请求寄存器，每个中断源在其中中占据一位。
- 所有中断源使用同一条公共的中断请求线，进入公共中断源服务程序入口。
- 转入公共的中断服务程序后，用一条特殊指令直接读到所有请求中断服务的中断源中具有最高优先级的中断源编号。
- 特点：**识别中断源的速度更快**



中断向量法

- 在主存储器的固定区域中开辟出一个专用的**中断向量区**
- 用硬件排队器和编码器在所有请求中断服务的中断源中，产生具有最高优先级的中断源编号
- 隐含执行上面方法中的两条识别中断源的指令，直接通过硬件转向这个中断源的中断服务程序入口。 不需要进入公共中断服务程序，能够实现到中断程序的最快转移



独立请求法

- 各个中断源使用自己独立的中断请求线。每一根中断请求线在处理机中有固定的或可编程的中断优先级。
- 如果同时有多个中断源请求中断服务，通过仲裁线路立即选择具有最高优先级的中断源，并向它发出中断响应信号INIT，处理机就可以立即转入这个中断源的中断服务程序。
- 独立请求法实际上是把分布在各个中断源内的串行排队器都集中到处理机中，从而克服了串行排队链法可靠性差的缺点，但灵活性差的缺点仍然存在。

![image-20231222092403388](file://C:/Users/23472/Desktop/study-note/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/assets/image-20231222092403388.png?lastModify=1716792370)

中断源用init信号清除中断请求信号。

不需要软件或硬件对中断源进行扫描，不需要中断源送回中断源编号或中断向量



分组独立请求法

- 把独立请求法与串行排队链法结合起来。
- 中断源分组：组内采用串行排队链法，组间采用独立请求法。



上面的2、3、4三种识别中断源的方法都属于串行排队链法：

- 串行排队链法的优点：
  - 识别中断源的速度比较快，特别是中断向量法。
  - 实现比较简单，中断源与处理机的连线很少。
- 串行排队链法的缺点：
  - 灵活性比较差，中断优先级是由硬件固定。不能由程序员通过软件修改。
  - 可靠性比较差，排队链串行分布在各个中断源中。一个出错，都出错。

#### 中断请求标记

每个中断源向CPU发出中断请求的时间是随机的。

中断请求标记触发器INTR：

- 用于记录是否产生中断
- 当其为1是，表示存在该类型的中断。
- 可以在CPU中，也可以在各个设备中

CPU响应中断应具备哪些条件？

1. 在CPU内部设置的中断屏蔽触发器必须是开放的
2. 外设有中断请求时，中断请求触发器必须处于“1”状态，保持中断请求信号。
3. 外设(接口)中断允许触发器必须为“1”，这样才能把外设中断请求送至CPU。

具备上述三个条件时，CPU在现行指令结束的最后一个状态周期响应中断。

#### 中断优先级

- 安排中断优先顺序主要由下列因素来决定：
  - 中断源的急迫性。
  - 设备的工作速度。
  - 数据恢复的难易程度。
  - 要求处理机提供的服务量。
- 中断优先级与中断服务顺序
  - 要求：**响应速度快，灵活性好**。
  - 做法：由硬件排队器决定**中断优先级**。
- **通过软件设置中断屏蔽码改变中断服务顺序**。



✋：在IBM 370系列机中，把7类中断分为5个中断优先级，从高到低分别是：

1. 紧急的机器检验错误引起的中断。
2. 调用管理程序，程序性错误，可以抑制的机器检验错误引起的中断。
3. 外部事件引起的中断。
4. 外围设备的中断。
5. 重新启动引起的中断。



✋：某处理机共有4个中断源，中断优先级从高到低分别是：1级、2级、3级和4级。当处理机在执行主程序时，同时有3级和2级两个中断源向处理机发出中断服务请求。当处理机为2级中断源服务时又有4级中断源发出中断服务请求。当处理机为４级中断源服务时又有１级中断源发出中断服务请求：

![image-20231222091639730](file://C:/Users/23472/Desktop/study-note/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90%E4%B8%8E%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84/assets/image-20231222091639730.png?lastModify=1716792370)



#### 中断处理方式

1. 现行指令结束，且没有更紧急的服务请求，CPU获得中断信号
2. 调用中断隐指令
   1. 关中断：为了保证中断现在不被新的中断所打断，保证中断服务程序能正常执行
   2. 保存断点：将原来的程序的断点保存，主要保存PC中的内容。
      - 撤消中断源的中断请求
      - 保存硬件现场，主要是PSW及SP等
      - 保存软件现场，在中断服务程序中使用的通用寄存器等
   3. 获取中断服务程序的入口地址，将地址传送给PC
      - 软件查询法
      - 硬件向量法
        - *中断向量地址的形成部件* 的输入时来自 *硬件排队器* 的输出IMTP1，INTP2...它的输出是中断向量地址，其位数与计算机可以处理中断源的个数有关，即一个中断源对应一个向量地址。
        - 向量地址对应一个中断向量，用于寻找设备的中断服务程序入口地址
3. 开CPU中断，可以响应更高级别的中断请求。
4. 执行中断服务程序
5. 关CPU中断。恢复软件现场，恢复屏蔽状态，恢复硬件现场
6. 开CPU中断。返回到中断点

#### 中断系统的软硬件分配

**恰当分配中断系统的软硬件功能**，是中断系统最关键问题。

必须用硬件实现的有：

- 保存中断点和进入中断服务程序入口。
- 这两个功能相当于执行一条转子程序指令，因为中断发生在现行程序的什么地方是不确定的，不能由程序员来安排。

必须用软件实现的有：

- 中断服务和返回到中断点。
- 返回到中断点，通过执行一条中断返回指令来实现。
- 中断服务必须用软件实现，因为是“程序中断方式”。

主要考虑的两个因素：

- **中断响应时间：中断响应时间是一个非常重要的指标。**
- **灵活性：硬件实现速度快，灵活性差；软件实现正好相反。**



##### 中断响应时间

定义：从**中断源向处理机发出中断服务请求开始**，到**处理机开始执行这个中断源的中断服务程序时为止**，这一段时间称为中断响应时间。

影响中断响应时间的因素主要有4个： (前2个属于处理机设计，后2个属于中断系统)

1. 最长指令执行时间 有些指令的执行时间很长，甚至无法预测。
2. 处理其它更紧急的任务所用时间 如处理DMA请求等。
3. 从第一次关CPU中断到第一次开CPU中断所经历的时间 中断系统的软件与硬件功能分配，主要就是要考虑这一段内要所的事情用软件来实现，还是用硬件来实现。
4. 通过软件找到中断服务程序入口所用时间 主要是第1和第3两部分。其中，第1部分是指令系统设计时考虑的问题，在中断系统的设计中，主要考虑第3部分。



#### 中断屏蔽⭐️⭐️

设置中断屏蔽有三个用处：

1. 在中断优先级由硬件确定了的情况下，改变中断源的中断服务顺序。
2. 决定设备是否采用中断方式工作。
3. 在多处理机系统中，把外围设备的服务工作分配到不同的处理机中。

中断屏蔽的实现方法主要有两种：

1. 每级中断源设置一个中断屏蔽位。
   - 中断屏蔽位可以分部在各个中断源中，也可以集中到处理机，如放到处理机的状态字中。
2. 改变处理机优先级
   - 中断优先级不仅在处理机相应中断源的中断服务请求时使用，而且为每个中断的中断服务程序也赋予同样的中断优先级。

两者的区别：

- 两者使用的概念不同
  - 前者使用中断屏蔽，后者使用中断优先级。
- 需要屏蔽码的位数不同
  - 前者所需要的屏蔽位数比较多，$n$：$log_2n$
- 可屏蔽的中断源数量和种类不同
  - 前者可以任意屏蔽掉一个或几个中断源，后者只能屏蔽掉比某一个优先级低的中断源。

### I/O系统性能

#### I/O系统性能

- 连接特性 容量 响应时间 吞吐率 

-  考虑I/O操作对CPU的打扰情况。
   -  即考查某个进程在执行时，由于其他进程的I/O操作，使得该进程的执行时间增加了多少。 




##### 简单 Producer-Server 模型

![image-20231107143558675](assets/image-20231107143558675.png)

- 吞吐量：

  - 服务器在单位时间之间内完成的任务

  - 为了获得尽可能高的吞吐量
    - 服务器不应该处于空闲
    - 队列不应该是空的


- 响应时间
  - 任务放入队列时开始，在被服务完成时结束
  - 最小化响应时间
    - 队列应该是空的
    - 服务应该处于空闲状态

*吞吐量* 和 *响应时间* 的函数应该是指数增长的



一般来说，吞吐量可以通过以下方式提高:

- 投入更多硬件
- 减少与负载相关的延迟

响应时间更难减少:

- 最终它会受到光速的限制(但我们离光速还很远)



##### 响应时间

- 系统响应时间 = I/O系统的处理时间 + CPU的处理时间
- **多线程技术**只能提高系统吞吐率，并不能减少系统响应时间
- 进程切换时可能需要增加I/O操作
- 可切换的进程数量有限，当I/O处理较慢时，仍然会导致CPU处于空闲状态

![image-20231107203626014](assets/image-20231107203626014.png)

##### 连接特性

物理上的规定和标准只要是需要互联的，必须各方面一致，否则无法连接

接口尺寸，接口形式，协议的一致性每根线的定义，电压，电流，频率等



#### I/O数据传输的三个要求

1. 数据位置
   - 必须选择正确的设备
   - 数据必须能在该设备内寻址
   - 一旦选择正确的设备，数据位置可能就变得微不足道了
     - 从键盘获取数据
   - 位置可能需要搜索
     - 磁道需要选择和旋转
   - 位置可能不是简单的二进制数字
2. 数据传输
   - 需要指定设备
   - 传输速率因设备而异
     - 键盘最快的可能就1秒10字节，但是磁盘块可能会快很多
   - 数据可以是输出、输入
3. 同步
   - 不仅I/O速率与处理器速度差别很大，而且I/O是异步的
   - CPU只能在时钟周期间隔询问I/O状态和传输信息，I/O状态和信息在被访问时必须是稳定的
   - 对于输出设备，只有设备准备好接收数据时才必须发送数据
   - 对于输入设备，处理器只有在设备可用时才能读取数据



#### 如何在数据传输中减少定位和同步

- 不同设备的数据结构不同，设备需要翻译地址
  - 处理器选择设备，但是地址只是处理器发送给设备的一个消息
- 处理器在读取读取设备状态时可以解决同步问题
- 为了提高速度，我们需要更高效的同步方法：DMA 和 中断



#### I/O系统可靠性能的参数:star::star:

反映存储外设可靠性能的参数有：

- 可靠性
  - 系统从某个初始参考点开始一直连续提供服务的能力。
  - **平均无故障时间MTTF**来衡量
  - 系统中断服务的时间用**平均修复时间MTTR**来衡量
  - 系统的失效率 = MTTF的倒数
  - 如果系统中每个模块的生存期服从指数分布，则**系统整体的失效率是各部件的失效率之和**（通过这个来算整体失效率和MTTF，各部件的失效率也等于MTTF的倒数）。
- 可用性
  - 系统正常工作的时间在连续两次正常服务间隔时间中所占的比率。
  - $可用性=\frac{MTTF}{MTTF+MTTR}$
  - $MTTF+MTTR$：**平均失效间隔时间MTBF**
- 可信性（不能够度量）
  - 服务的质量。即在多大程度上可以合理地认为服务是可靠的



:hand:栗子：

<img src="assets/image-20231221172118998.png" alt="image-20231221172118998" style="zoom: 67%;" />

<img src="assets/image-20231221172153376.png" alt="image-20231221172153376" style="zoom: 67%;" />



##### 故障、错误和失效

(1) 一个故障可能会导致一个或者多个错误；

(2) 错误通常具有以下特性：

  ◆ 错误在潜在状态和有效状态间相互转换；
  ◆ 潜在的错误可能通过激活而有效；
  ◆ 有效错误的影响可以传递，引起新的错误。

(3) 如果错误影响到部件正常的服务时，部件就发生了失效；

**故障的分类：**

(1) 按故障产生的原因分：

  ◆ 硬件故障：设备失效产生的故障 
  ◆ 设计故障
  ◆ 操作故障：由于用户操作的失误引起的故障 
  ◆ 环境故障

(2) 按故障出现的周期分：

  ◆ 暂时性故障 间歇性故障 永久性故障



##### 提高系统组成部件可靠性

- 有效构建方法：在构建系统的过程中消除故障隐患，这样建立起来的系统就不会出现故障

- 纠错方法：在系统构建中采用容错方法

  -  故障避免技术

  -  故障容忍技术

  -  错误消除技术

  -  错误预报技术





## 第六章 指令系统

### 指令系统概述

- 指令系统是计算机体系结构的主要组成部分，标识软硬件直接的接口，是软硬件之间的桥梁
- 指令系统是使用处理器的基本方法
- 指令系统**设计原则**：**加快经常性事件**
- 大多数指令系统都很相似，学习主流但也要了解少数指令系统。



### 数据

#### 数据类型:star:

定义：具有一组**值的集合**，且定义了作用于该集合的操作集

目的：防止不同类型数据的误操作，为了满足软件的需求，是计算机软件系统需要使用的。

分类：基本类型、结构类型

**基本数据类型**：二进制位、二进制位串、整数、十进制数

**结构数据类型：由一组相互有关的数据元素复合而成的数据类型**，数组、字符串、向量、堆栈、队列、记录等

> **大多数系统结构只能部分支持结构数据类型**



#### 数据表示

DR (Data Representation) 是电脑硬件可以直接识别的，可以直接被指令系统使用的。

需要确认哪些 DS 是使用 DR 实现的，使用 DR 的数据类型更高效，DR决定怎么选择软硬件

数据类型的确定原则：

- 减少程序运行实践
- 减少CPU和内存间通信
- 数据类型的普遍和实用效率

DR 是在发展和扩大的，实现新的DR可以更好的使用软硬件

高质量的数据表示：栈、向量、数组等；

目标：支持数据结构，提高系统有效性和性能/价格。



> 例：实现A＝A＋B，A和B均为200×200的矩阵，分析向量数据表示的作用
>
> 解：如果在没有向量数据表示的计算机系统上实现，一般需要6条指令，其中有4条指令要循环4万次。因此，CPU与主存储器之间的通信量：
>
> 取指令2＋4×40,000条，读或写数据3×40,000个，
>
> 共要访问主存储器7×40,000次以上。
>
> 如果有向量数据表示，只需要一条指令。
>
> 减少访问主存（取指令）次数：4×40,000次
>
> 缩短程序执行时间一倍以上。



**数据表示增加的原则：**

1. 是否提高了系统的有效性

   是否减少实现时间，是否减少专用空间。例如：向量被操纵A=A+B，当采用向量数据表示时，矢量算法组件管道计算可以节省时间，辅助开销时间减少；

2. 数据表示是否具有通用性和利用率就足够了

   通用性：是否适用于多种数据结构。

例子：增加树结构数据类型还是指针数据类型

- 树结构对向量、数组等支持不好
- 更好支持多种数据结构
- 出现选择困难的时候依据 性能/价格比



**DS与DR的关系：**

- DR 是 DS 的子集
- DR 是软硬件的接口，DS 属于软件程序

<img src="assets/image-20231211082431724-17022542740091.png" alt="image-20231211082431724" style="zoom:50%;" />



#### 自定义数据表示

数据存储单元（寄存器、主内存储器、外存储器等）仅存储纯数据。

- 由指令中的运算符解释的：数据类型(定点，浮点，字符，字符串，逻辑，矢量等)进位系统(2、10、16等)
- 数据字长(字、半字、双字、字节等)
- 寻址方式(直接寻址，间接寻址，相对寻址，寄存器寻址)
- 数据功能(地址，数值，控制字，符号等)

有很多指令在高级语言和应用软件中，数据的属性是由数据本身定义的，高质量语言和机器语言之间的语义差异由编译器来解决。



##### 带数据标识符的数据表示

目的：为了减少高级语言和机器语言的差异，减少数据分类

实现：编译器建立，由硬件完成转换

例子：

<img src="assets/20200227230742.png" alt="img" style="zoom:60%;" />

> 功能位：操作数、指令、地址、控制字
> 陷井位：由软件定义四种捕捉方式
> 封写位：指定数据是只读的还是可读可写
> 类型位：二进制,十进制,定点数,浮点数,复数,字符串,单精度,双精度；绝对地址、相对地址、变址地址、未连接地址等。

**标志符的处理机所占用的存储空间通常要小**

<img src="assets/20200227231722.png" alt="img" style="zoom:70%;" />

通过合理的设计可以让橙色框比紫色框小

标识符数据表示方法的**优点**：

- 简化了指令系统。

- 由硬件实现一致性检查和数据类型转换。
- 简化程序设计，缩小了人与计算机之间的语义差距。
- 简化编译器，使高级语言与机器语言之间的语义差距大大缩短。
- 支持数据库系统，一个软件不加修改就可适用于多种数据类型。
- 方便软件调试，在每个数据中都有陷井位。

**缺点**：

- 数据和指令长度可能不一致：可以通过精心设计指令系统来解决
- 指令速度降低，但是采用标志符设计，程序的设计编译调试实践都会降低
- 硬件复杂度增加



##### 数据描述符

数据描述符与标志符的**区别**：标志符只作用于一个数据，而**数据描述符要作用于一组数据**

<img src="assets/image-20231010151645522.png" alt="image-20231010151645522" style="zoom:67%;" />

举个栗子：
$$
A=\left[\begin{array}{llll}
a_{11} & a_{12} & a_{13} & a_{14} \\
a_{21} & a_{22} & a_{23} & a_{24} \\
a_{31} & a_{32} & a_{33} & a_{34}
\end{array}\right]
$$
<img src="assets/image-20231010152134805.png" alt="image-20231010152134805" style="zoom: 50%;" />

第一行的3表示有三个这样的数据组并且存了他们的起始地址（**这一行是用来描述之后数据类型的（比如说三个单行数组）**）；后三个101表示每一组数据有4个数据并且存了数据的起始地址（**这几行是用来描述具体数据的（描述单行数组中的数据）**）；后面就是顺序存放的数据



### 指令

**指令**是处理器进行操作的最小单元，如加减乘除、读写存储器操作

组成：操作 + 源地址 + 目标地址 + 下一个指令地址

类型：数据的处理、存储、移动、程序的流程控制

#### 操作数

- 操作数类型：是面向应用、面向软件系统所处理的各种数据类型。
  - 整型、浮点型、字符、字符串、向量类型等
  - 类型由操作码确定或数据附加硬件解释的标记，一般采用由操作码确定
  - 数据附加硬件解释的标记，现在已经不采用
- 操作数的表示：操作数在机器中的表示，硬件结构能够识别，指令系统可以直接使用的表示格式
  - 整型：原码、反码、补码
  - 浮点：IEEE 754标准
  - 十进制：BCD码/二进制十进制表示

常用操作数类型：

- ASCII character = 1 byte (64-bit register can store  8 characters
- Unicode character or Short integer = 2 bytes = 16 bits （half word) 
- Integer = 4 bytes = 32 bits (word size on many RISC Processors)
- Single-precision float = 4 bytes = 32 bits (word size)
- Long integer = 8 bytes = 64 bits (double word)
- Double-precision float = 8 bytes = 64 bits (double word)
- Extended-precision float = 10 bytes = 80 bits (Intel architecture)
- Quad-precision float = 16 bytes = 128 bits

#### 指令结构分类 :star::star:

分类准则：

1. CPU中操作数的存储方法分类
2. 指令中显式操作数个数分类
3. 根据操作数能否放在存储器中分类

指令集划分成**堆栈型（没有地址）、累加器型（半隐式）、通用寄存器型**三类

通用寄存器结构，根据操作数的来源不同，又可进一步分为:

- 寄存器-存储器结构（RM结构）
- 寄存器-寄存器结构（RR结构）：也称为load-store结构，只有load指令和store指令能够访问存储器
- 存储器-存储器结构

对于不同类型的结构，操作数的位置、个数以及操作数的给出方式（显式或隐式）也会不同：

- 显式给出：用指令字中的操作数字段给出
- 隐式给出：使用事先约定好的单元

<img src="https://img-blog.csdnimg.cn/20200718070301474.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYzMzc4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:30%;" />

<img src="https://img-blog.csdnimg.cn/20200718070836735.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MzYzMzc4NA==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述" style="zoom:33%;" />

#### 编址方式

编址单位：字编址、字节编址、位编址、块编址等

- 一般：字节编址，字访问；部分机器：位编址，字访问；辅助存储器：块编址


#### 零地址选择 :star:

  - **三个零地址空间**：通用寄存器、主存储器、输入输出设备独立编址
    - 由于三种存储设备所采用的寻址技术差别比较大，因此对它们分别进行编址是很自然的。

- **两个零地址空间**：主存储器与输入输出设备统一编址
  - 主存储器与输入输出设备统一编址能够简化指令系统，因为在指令系统中不必另外设置输入输出指令，所有能够访问主存储器的指令都能够用来对输入输出进行操作

- **一个零地址空间**：所有存储设备统一编址。最低端是通用寄存器，最高端是输入输出设备，中间为主存储器
  - 采用一个零地址空间的处理机通常有一个存储容量比较大的高速存储器，有多个进程或线程存放在高速存储器中，并且可通过硬件进行进程和线程的且换。

- **隐含编址方式**，实际上没有零地址空间：堆栈、Cache等
  - 在堆栈计算机中，运算指令是不需要地址的，有关设备（包括寄存器、主存储器和输入输出设备等）不需要进行编址。

- 对于I/O设备
  - 一个地址一个设备：必须通过指令中的操作码来识别该输入输出设备上的有关寄存器
  - 两个地址一个设备：一个地址是数据寄存器，一个地址是状态/控制寄存器
  - 单设备多地址：对编程增加困难

#### 寻址方式

1. 寄存器寻址（Register）
2. 立即数寻址（Immediate or literals）
3. 偏移寻址（Displacement）
4. 寄存器间接寻址（Register deferred or indirect）
5. 索引寻址（Indexed）
6. 直接寻址或绝对寻址（Direct or absolute）
7. 存储器间接寻址（Memory indirect or memory deferred）
8. 自增寻址（Auto increment）
9. 自减寻址（Auto decrement）
10. 缩放寻址（Scaled）

**采用多种寻址方式可以显著地减少程序的指令条数，但可能增加计算机的实现复杂度以及指令的CPI。**

重要的寻址方式:

- 偏移寻址方式，立即数寻址方式，寄存器间址方式，使用频度达到 75%--99%

偏移字段的大小应该在 12 - 16 bits

- 可满足75%-99%的需求

立即数字段的大小应该在 8 -16 bits

- 可满足50%-80%的需求



##### 存储器寻址

**尾端问题：**

尾端问题描述的是多字节数据在内存中的存储顺序。主要有两种类型的尾端格式：

1. **大端（Big-Endian）**：在这种格式中，最高有效字节（MSB）存储在最低的内存地址，而最低有效字节（LSB）存储在最高的内存地址。简而言之，数据的“头部”在前。xx00位置是字的最高字节
2. **小端（Little-Endian）**：相反地，在小端格式中，LSB存储在最低的内存地址，而MSB存储在最高的内存地址。在这种格式下，数据的“尾部”在前。xx00 位置是字的最低字节

不同的计算机架构可能采用不同的尾端格式。例如，Intel的x86架构是小端的，而很多网络协议和一些RISC架构使用大端格式。尾端问题在不同架构之间进行数据交换时尤为重要，需要确保正确地解释数据。



**对齐问题：**

对s字节的对象访问地址为A，如果 $A \, {\rm mod} \, s =0$，则称为边界对其，

如果边界没有对其，就可能访问一个对象需要读取两次寄存器，也可能会引发异常

<img src="assets/image-20231012102609291.png" alt="image-20231012102609291" style="zoom:40%;" />



##### 间接寻址与变址寻址

间接寻址（Indirect Addressing）

在间接寻址模式中，指令中包含的地址并不是操作数的实际地址，而是指向操作数实际地址的指针（或称为地址的地址）。换句话说，CPU首先要读取指令中给出的地址处的内容，这个内容才是操作数的实际地址。

- **优点**：提供了更大的灵活性，可以动态改变操作数的地址。
- **缺点**：由于需要额外的内存访问来获取实际的操作数地址，所以可能会降低指令的执行速度。

变址寻址（Indexed Addressing）

变址寻址是一种在指令执行时动态计算操作数地址的方法。它通常涉及一个基地址（在指令中直接给出或存储在某个寄存器中）和一个索引量（通常存储在另一个寄存器，称为索引寄存器）。最终的操作数地址是这两个数值的和。

- **优点**：对于处理数组和循环结构非常有效，因为可以通过改变索引寄存器的值来遍历数组中的元素。
- **缺点**：相对于直接寻址，它的计算过程更复杂，可能需要额外的时间来计算地址。

#### 指令的格式

许多计算机支持不止一种指令格式：不同指令长度的指令

指令格式大小与数据总线宽度的关系：

- 指令的大小小于数据总线的大小：32 位总线上的 16 位指令——一次获取多条指令！
- 比数据总线宽的指令：整个指令需要多次获取

指令集支持的指令格式各不相同。

指令格式主要因其操作数的数量和类型而异。

##### 指令格式设计举例

例子1：为以下两种指令格式的设计指令：

- 格式A：Reg, Reg: R1 <- R1 OP R2

- 格式B：Reg, Mem: R1 <- R1 OP Mem


机器有 16 个寄存器，有 32 条 A 类指令，B 类指令有 16 条，内存访问是 13 位的位移加上一个基寄存器。

<img src="assets/image-20231227155032887.png" alt="image-20231227155032887" style="zoom:50%;" />

例子2：

我们需要开发支持以下操作的指令集和格式：

R1 <- R1 OP R2, 64 instructions
R3 <- R1 OP R2, 64 instructions
MEM <- R1, 64 instructions
MEM <- R1 OP R2, 32 instructions
R3 <- R1 OP MEM, 32 instructions

机器有 16 个通用寄存器，每个寄存器大小为 16 位。 通过 8 位的基数加位移访问内存。

答：需要四种长度的指令即可，因为后两种的指令长度一样，64个指令需要6位操作码，32个指令的需要5位操作码

#### 程序的装入和链接

##### 程序的装入

将程序(模块)装入内存时，可以有三种方式：

- 绝对装入方式
  - 编译时知道程序在内存中位置，产生绝对地址

  - 地址不需要修改

  - 单道程序

- 可重定位装入方式(静态重定位方式)
  - 在装入时对程序中逻辑地址的偏移值加入起始地址中

  - 在装入时一次完成

  - 只能连续装入

- 动态运行时装入方式



##### 程序的链接

源程序经编译后，可得到一组目标程序，再利用链接程序将这组目标模块链接，形成装入模块。

- 静态链接
- 装入时动态链接
- 运行时动态链接



### 优化指令格式

目标：

- 节省程序存储空间
- 指令格式尽量规整，便于译码

三种方法：固定长度，哈夫曼编码，扩展编码

#### Huffman:star::star::star:

主要使用 Huffman 编码：

**每个字符最少所需要的位数（信息熵/最优Huffman编码）：**
$$
H=-\sum_{i-1}^nP_i \cdot \log_2P_i
$$
$P_i$ 表示第$i$个数出现的概率的排序

固定长度编码冗余：
$$
\mathrm{R}=1-\frac{-\sum_{\mathrm{i}=1}^{\mathrm{n}} \mathrm{P}_{\mathrm{i}} \cdot \log _2 \mathrm{P}_{\mathrm{i}}}{\left[\log _2 \mathrm{n}\right]}
$$
使用变长编码的时候我们要极其注意冲突问题，我们使用前缀码来编码哈夫曼，也就是说在一个树上，没有一个字符的编码可以是另一个字符的祖先，因此一个字符的编码不可能是另一个字符的前缀



计算 Huffman 方法：

- 对于n个字母的字母表，Huffman 算法从第n个节点开始，标记字母和其频率
- 我们确定两个具有最低频率的顶点，并将它们替换为树，其根标记为这两个频率的和，其两个子节点是我们替换的两个顶点。

> 注意！！！！！！
>
> 如果出现新节点和原有节点等概率时，先用原有节点组成新节点，这样会短！！！！！！


缺点：

- 操作码长度不规整，硬件译码苦难
- 与地址码共同组成固定长的指令比较困难



#### 拓展编码:star::star::star:

扩展编码法：由固定长操作码与Huffman编码法相结合形成

<img src="assets/image-20231016144657727.png" alt="image-20231016144657727" style="zoom:50%;" />

扩展方法：等长扩展和不等长扩展两种。

扩展编码中选择某些特征位用于扩展。

注意扩展目标(各频率段)间关系。

<img src="assets/image-20231016144812788.png" alt="image-20231016144812788" style="zoom:67%;" />



不等长扩展：

例3：指令系统共有78种指令，前10种使用频率平均为0.049，中间18种使用频率平均为0.02，最后50种使用频率平均为0.003。如何编码？

同上例方法，码长可有三种；

因每段指令数比例为1：2：5，故不可采用等长扩展，采用不等长编码（4-6-10位）较能减少平均码长。



### 编译器优化

编译器优化目标：

- 所有程序都被正确编译
- 大多数编译程序执行更快
- 快速编译
- 支持调试

**优化类型：**

高级——在源代码级别或接近源代码级别完成

- 如果过程只被调用一次，则将其内联并保存CALL
- （更一般的情况）如果调用次数 < 某个阈值，则将它们内联

本地——完成的直线代码

- 公共子表达式产生相同的值——要么分配一个寄存器，要么用一个拷贝替换
- 常量传播——用常量替换常量值变量
- 堆栈高度缩减——重新安排表达式树以最小化临时存储需求

全局——跨分支

- 复制传播——将赋值为X(即a =X)的变量a的所有实例替换为X。
- 代码移动——从循环中删除每次循环计算相同值的代码，并将其放在循环之前
- 简化或消除循环中的数组寻址计算

依靠机器优化

- 长度减少——通过移位和加法减少乘法
- 流水线调度——对指令重新排序，以提高流水线性能
- 分支偏移优化——重新排序代码以最小化分支偏移

编译器技术综述

- 尽量避免依赖停滞
- 循环展开——减少循环开销
- 软件流水线——减少单体依赖失速
- 跟踪调度——减少其他分支的影响
- 所有的技术都依赖于预测的准确性



### 指令系统的功能设计

要求：完整性、规整性、高效率和兼容性

- 完整性：是指应该具备的基本指令种类，通用计算机必须有５类基本指令
- 规整性：包括对称性和均匀性对称性：所有寄存器同等对待，操作码的设置等都要对称，如：A－B与B－A
- 均匀性：不同的数据类型、字长、存储设备、操作种类要设置相同的指令
- 高效率：指令的执行速度要快；指令的使用频度要高；各类指令之间要有一定的比例
- 兼容性：在同一系列机内指令系统不变（可以适当增加）

指令系统的优化设计有两种截然不同的方向：CISC和RISC

1. 复杂指令系统计算机CISC(Complex Instruction Set Computer)增强指令功能，设置功能复杂的指令面向目标代码、高级语言和操作系统用一条指令代替一串指令
2. 精简指令系统计算机RISC(Reduced Instruction Set Computer)只保留功能简单的指令功能较复杂的指令用子程序来实现

#### 指令类型：CISC和RISC :star:

##### CISC

经典的CISC架构有x86，CISC出现较早，显得大而全。其指令数很多，不仅包含了处理器常用的指令，也包含了许多不常用的特殊指令。

提出的原因：

- 软件成本远远超过硬件成本
- 日益复杂的高级语言
- 语义差距

其特征主要有：

- 指令系统复杂，可以使用变长指令，寻址方式多，各种指令都能访问存储器，微程序控制

存在的问题：

- 效率低下：CISC的指令只有20%被经常使用，80%则很少被用到；且20%的指令占据了80%的存储空间
- 难以进行编译优化生成高效目标代码
- 研发周期长，难以保证设计的正确性，难以调试和维护
- 大量的特殊指令让CPU设计变得复杂，增加了硬件上的时间成本和面积开销
- CISC发展后期，硬件实现时将x86指令转换成内部的RISC操作，使CISC处理器能够使用RISC处理器设计技术。
- 复杂的指令使指令的执行周期大大加长，一般CISC处理机的指令平均执行周期都在4以上，有些在10以上



##### RISC

- **减少CPI是RISC思想的精华**
- **减少指令种数和简化指令功能来降低硬件设计的复杂度**
- RISC指令的特征有：

  - 简化的指令系统，选取使用频率最高的指令，并补充一些最有用的指令
  - 以寄存器-寄存器方式工作
  - 指令功能尽可能简单，在一个机器周期内完成
  - 只有load和store操作指令才能访问存储器，采用大量通用寄存器以减少访问内存次数
  - 采用优化的编译系统，力求有效的支持高级语言程序

RISC的速度要比CISC快3倍左右，关键是RISC的CPI减小了

<img src="assets/image-20231016153320452.png" alt="image-20231016153320452" style="zoom:50%;" />



#### VIEW

VLIW（Very Long Instruction Word）指令系统是一种特殊的计算机架构，其核心特点是使用非常长的指令字（Instruction Word）。这些指令字包含多个操作，可以并行执行。VLIW体系结构的设计理念是将指令级并行（ILP，Instruction-Level Parallelism）的复杂性从硬件转移到编译器，使得硬件设计相对简化。

##### VLIW的特点

1. **长指令字**：VLIW的指令字包含多个操作，每个操作可以是一个独立的指令。
2. **编译器优化**：编译器负责识别可以并行执行的操作，并将它们打包到一个长指令字中。
3. **简化的硬件**：由于编译器负责处理指令的并行性，硬件可以在不涉及复杂的动态调度逻辑的情况下实现并行执行。

##### 为什么VLIW被较少使用或“淘汰”

尽管VLIW架构在理论上具有显著的性能优势，但在实践中它面临着一些挑战：

1. **编译器的复杂性**：将并行性的责任转移到编译器意味着编译器必须非常智能和复杂，能够准确识别并行执行的机会。
2. **代码密度问题**：长指令字可能导致代码密度低下，因为并不是所有的指令都能被有效地打包为并行操作。
3. **可移植性问题**：VLIW架构密切依赖于特定的编译技术，这可能导致针对特定VLIW处理器优化的代码在其他处理器上运行效率低下。
4. **动态性能调整的局限**：由于VLIW依赖于编译时确定的静态指令调度，它不擅长处理动态变化的运行时环境，例如分支预测和数据依赖。



### ISA (Instruction Set Architecture) 

指令集架构是计算机抽象模型的一部分，它定义了**软件如何控制 CPU**。 

ISA 提供了用户与硬件交互的唯一方式。它是机器中对汇编语言程序员、编译器编写者和应用程序程序员可见的部分。

<img src="assets/image-20231210212348970.png" alt="image-20231210212348970" style="zoom:50%;" />

ISA 应当具备**特性**：

- 成本低
- 简洁性
- 架构和具体实现分离：可持续多代，以保持向后（backward) 兼容
- 易于编程/链接/编译
- 兼容性
  - 可持续用于很多代机器上(portability)
  - 可以适用于多个领域 (generality)
  - 对上层提供方便的功能（convenient functionality)
  - 可以由下层有效地实现（efficient implementation )


ISA 需要设计的内容：

- 指令集功能设计：主要有RISC和CISC两种技术发展方向
- 寻址方式的设计
- 操作数的类型和表示
- 指令集架构的设计：变长编码、固定长度编码和混合型编码



- 重要的系统界面（System Interface）
  - ISA界面（Instruction Set Architecture）
  - ABI界面（Application Binary Interface）

- ISA：用户级ISA+特权级ISA
  - 用户级ISA 适用于操作系统和应用程序
  - 特权级ISA 适用于硬件资源的管理（操作系统）

#### ISA 的实现

![image-20231010142433457](assets/image-20231010142433457.png)





格式：操作码字段+地址码字段   寻址方式

1. 操作码

   反应机器做什么操作

2. 地址码



## 第七章 系统结构

- 体系结构要做的事情：

  - 从设计者角度，分析和评价**系统性能/价格**，在分析和评价的基础上，进行系统结构的设计和优化，

- 计算机体系结构的定义：
  - 狭义观点：**软件设计者与硬件设计者之间的中间层，以及微体系，软件与硬件的接口**
  - 扩展观点：**算法层、语言层、系统软件层、ISA层、微体系结构、逻辑电路层**
- **计算机性能提高的原因：**

  - 科技：更多晶体管
  - 机器组织和实现
  - 更深的流水线 更多并行执行




### 计算机系统结构概念

#### 计算机系统结构:star:

计算机系统结构是对计算机系统中各机器之间界面的划分和定义，以及对各级界面上、下的功能进行分配

**计算机系统结构是计算机系统的软硬件分界面，计算机组成是计算机系统结构的逻辑实现，计算机实现是计算机组成的物理实现。$系统效率=\min(器件速度)*\min(系统结构效率)$**

<img src="assets/image-20230912151826216.png" style="zoom:67%;" />

> **基本定义：程序员所看到的计算机的属性，即概念性结构和功能特性。**

透明性概念： 在计算机中，客观存在的事物或属性从某个角度看不到，称这些事物或属性对它是透明的。计算机重的“透明”与社会生活中的“透明”，含义正好相反。

#### 计算机多层结构

1. 六级层次结构

2. 层次结构的实现方式：根据性价比决定，软硬件逻辑是等同的

### 系统结构设计

#### 计算机系统设计思路

1. **由上向下方法**：根据用户的要求，设计基本的命令、数据类型与格式等，然后再逐级往下设计，并考虑对上一级进行优化来实现

   - **适合于专用机的设计，从应用到实现级，周期几年。**

   - **缺点：当应用对象或范围变化时，效率急剧下降。**

   - **原因：软、硬件脱节，不能利用最新的软件技术。**

2. 由下向上方法：根据器件条件，先把微程序机器级及传统机器级研制出来，然后再配合不同的操作系统和编译系统软件，使应用人员根据所提供的条件来采用合适的算法满足相应的应用要求

   - 前提：硬件不能改变

   - 缺点：易形成软、硬脱节，软件不能获得最新硬件的支持，结果软件繁杂、效率低。

3. 从中间开始方法：

   - 从软、硬件交界面开始设计。
   - 要求首先进行软、硬件功能分配，同时考虑硬件能为软件提供什么支持。



#### 系统结构的设计步骤

1. 需求分析

2. 需求说明：主要包括设计准则、功能说明、器件性能说明等。

3. 概念性设计：进行软、硬件功能分析，确定机器级界面。

4. 具体设计：机器级界面各方面的确切定义，可考虑几种方案。

5. 反复优化设计及评价

设计需求的转变：

1. Power Wall：以前能源便宜，晶体管贵；现在晶体管便宜，能源贵
2. ILP Wall：以前依靠编译器、架构创新来提高ILP (Out- of-order, speculation, VLIW)；现代利用ILP的好处变得越来越小
3. Memory Wall：以前乘法器慢，存储器速度快；现代相反
4. Power Wall + ILP Wall + Memory Wall = Brick Wall

#### 软硬件取舍原则

1. 现有软、硬件条件下，选择能提高**性价比**的方法；
2. 考虑到准备采用和可能采用的组成技术，所选方法能否尽量不限制组成和实现技术；
3. 不能仅从“硬”的角度去考虑如何便于应用组成技术的成果和发挥器件技术的进展，还应考虑所选方法能否从“软”的角度为编译和操作系统的实现，以至高级语言程序的设计提供更多更好的硬件支持。

硬件和软件在功能实现上是等效的，即一种功能可以由软件实现，也可以由硬件实现。在实现性能上是不等效的。软件实现的优点是设计容易、改进简单；硬件实现的优点是速度快。

#### 专注于常见情况

- 更倾向于优化常见情况：改善频繁事件，而不是罕见事件
  - 例如：指令提取和解码单元比乘法器使用频率更高，因此首先对其进行优化
  - 例如：如果数据库服务器有50个磁盘/处理器，存储可靠性高于系统可靠性，因此首先优化它明显有助于提高表现
- 频繁的情况通常比不频繁的情况更简单、更快地改善
  - 例如，当添加2个数字时溢出是罕见的，所以通过优化更常见的无溢出情况来提高性能
  - 可能会减慢溢出速度，但通过对正常情况的优化，整体性能有所提高
- 我们必须决定频繁的情况是什么，以及通过使情况更快可以提高多少性能  => Amdahl's Law



### 计算机设计的定量原则:star::star::star:

#### 常用的4个基本原理:star::star:

（1）以**经常性事件**为重点。在计算机系统的设计中， 对经常发生的情况，赋予它优先的处理权和资源使用权， 以得到更多的总体上的改进。

（2）Amdahl定律。**加快某部件执行速度所获得的系统性能加速比**，受限于**该部件在系统中所占的重要性**。

（3）CPU性能公式。执行一个程序所需的 $CPU时间 = IC ×CPI ×时钟周期时间$。

（4）程序的局部性原理。程序在执行时所访问地址的分布不是随机的，而是相对地簇聚。

2 3在下面 4在上面

#### Amdahl's Law :star::star:

- Amdahl 定律定义了通过使用特定特性可以获得的性能提高
- 通过改进计算机的某些部件而获得的性能增益可以使用Amdahl定律来计算

$$
Speedup(E)=\frac{Execution\_Time\_Without\_Enhancement}{Execution\_Time\_With\_Enhancement}\\S_n=\frac{T_o}{T_n}=\frac{1}{(1-F_e)+\frac{F_e}{S_e}}
$$

其中：

$S_n$ —— 全局加速比；

$\mathrm{T_o} $—— 原执行时间(old) 一新执行时间(new)

$T_n$ —— 新执行时间

$S_e $ —— 被改进部分的局部加速比

$F_e $ —— 被改进部分原执行时间占原来总时间的百分比。

计算公式：改进之前程序运行总时间可写为: $T_o=T_o\left(1-F_e+F_e\right)$，改进之后由于其中部分操作加快，总时间降为：$T_n=T_o\left(1-F_e+\frac{F_e}{S_e}\right)$

根据加速比定义, 有: $S_n=\frac{T_o}{T_n}=\frac{1}{\left(1-F_e\right)+\frac{F_e}{S_e}}$

<img src="assets/image-20231222204935798.png" alt="image-20231222204935798" style="zoom:80%;" />



例题1：设改进后的某部件运行速度是原速度的10倍，而该部件原运行时间占全系统运行时间的比例为40%，那么此项改进会使全系统的性能得到多少提升？

解：按照Amdahl定律，系统性能的提升可以用加速比表示。据题意：Fe = 0.4；Re = 10，直接使用式：

<img src="assets/image-20231108174829864.png" alt="image-20231108174829864" style="zoom: 50%;" />

<img src="assets/image-20231108174847365.png" alt="image-20231108174847365" style="zoom: 67%;" />

<img src="assets/image-20231108174912003.png" alt="image-20231108174912003" style="zoom: 67%;" />

1. 提高CPU的时钟频率，即减少 CPI

   实现困难，实用的考虑：体系结构设计者所作的工作不是进行元件级别的设计，但是可以选择元件，如果市面上没有所要求的元件或者价格太贵，则应考虑放弃这种方案；

2. 将CPU的流水线条数增加为n条，在理想情况下其运行速度可以提高n倍

   与上面同样的理由，因为速度相差太大，需要增加的流水线数目也相当大。

   一方面会给工艺上带来极大的困难，甚至达到不可能制作的地步（体系结构受到元件发展的限制）。

   另一方面如果流水线条数太多，指令机器字长的分配和调度也会带来许多困难，使实际效果大打折扣。

3. 设计专门的多媒体指令及处理硬件，大幅度提高同一条指令处理大量数据的能力。



#### CPU性能公式:star::star:

- 时钟频率：指同步电路中时钟的基础频率
- 时钟周期=1/时钟频率

一个程序的CPU时间为：
$$
\text{CPU时间} = \text{指令数} \times \text{CPI} \times \text{时钟周期时间} =程序的CPU时钟周期\times时钟周期时间=ncycle*Tcycle\\
\text{CPU时间} = \frac{\text{指令数} \times \text{CPI}}{\text{时钟频率}}
$$
IC：指令计数，取决于指令集架构和编译技术

CPI：平均每个指令的时钟周期，取决于计算机组成和指令集架构

CPU性能依赖于：时钟周期时间、CPI 和 IC，它们是独立的



### 计算机系统结构的发展

- 体系结构发展历史

  - Minicomputers, Microprocessors
  - RISC vs CISC，VLIW 

- 集成电路技术方面

  - 芯片的集成度不断提高，但提升的速度在放缓；时钟频率的提高在放缓，并有降低的趋势
  - 登纳德缩放比例定律的终结
    - 功耗成为关键制约条件
  - Moore定律的终结：晶体管的集成度提高延缓

- 现代体系结构发展趋势：并行！！！

- 体系结构的发展及机遇

  - 指令集并行受到制约，线程级并行和数据级并行是发展的方向
  - 提高单处理器性能花费的代价呈现上升趋势
  - 面向特定领域的体系结构正蓬勃发展

  

#### 冯·诺依曼机组系统结构的演变

**单处理器结构：**

1. 组成：由运算器、控制器、存储器、I/O设备组成

2. 特点（也叫存储计算机）

   - 采用存储程序原理

   - 指令串行执行，由控制器控制

   - 存储器按地址访问，是顺序的一维线性空间

   - 使用机器语言，数据以二进制表示

   - 单处理机结构，以运算器为中心

   - 输入输出设备与存储器之间的数据传送都途经运算器

<img src="assets/image-20231031163130567.png" alt="image-20231031163130567" style="zoom:50%;" />

3. 缺点
   - 两个瓶颈：CPU——存储器，指令串行执行
   - 机器语言与高级语言间语义差别较大
   - 复杂数据结构必须经过地址映象存放
4. 改良
   - 程序运行中不允许被修改
   - 采用先行控制、流水线等方法，开发并行性
   - 采用多体交叉存储器，增加存储带宽
   - 增加新的数据表示，进一步支持高级语言
   - 以存储器为核心，使I/O设备和CPU可并行工作



### 系统结构中并行性:star:

> :star:并行性概念：在同一时刻或同一时间间隔内完成两种或两种以上工作，只要在时间上相互重叠，均存在并行性。
>
> - 并行性：解题中具有可以同时进行运算或操作的特性。目的是为了能并行处理，提高解题效率。 
> - 广义并行性：只要在同一时刻或是在同一时间间隔内完成两种或两种以上性质相同或不同的工作， 在时间上能相互重叠，都称为并行性。
>
> 并行性的两重含义！！！！：
>
> - **同时性**——指两个或多个事情在同一时刻发生的并行性
> - **并发性**——指两个或多个事情在同一时间间隔内发生的并行性

**并行度与并行体系分类**：数据级并行  任务级并行

计算机通过以下方式开发这两类应用并行：

1. **指令集并行**在编译器帮助下，利用流水线思想适度开发数据级并行
2. **向量体系结构和图形处理器 (GPU)** 将单条指令并行应用于一个数据集
3. **线程级并行**在一种紧搞合硬件模型中开发数据级并行或任务级并行
4. 请求级并行在程序员或操作系统指定的大量去搞合任务之间开发并行

#### 如何使用并行性提高性能

- （超级）流水线
- 强大的指令
  - MD-technique：每次操作有多个数据操作数
  - MO-technique：每条指令执行多个操作
- 多指令问题
  - 单指令程序流
  - 多个流(或程序，或任务)

#### 并行性等级:star:

- 从执行角度从高到低

  - 指令内部并行，即指令内部的微操作之间的并行；（硬件和组织的设计）
- 指令间并行，即并行执行两条或多条指令（处理好指令间的关联  ILP）
  - 线程级并行
- 过程级（任务级）并行，即并行执行两个或多个过程或任务（程序段 TLP）（任务分解）
  - 作业级（程序级）并行，即在多个作业或程序间的并行（并行算法）

- 从数据处理角度从高到低：**字并位并 字并位串 字串位并 字串位串** 

- 从信息加工角度 

  - 存贮器操作并行；处理器操作步骤并行；处理器操作并行；指令、任务、作业并行

#### 提高并行性的技术途径:star::star::star:

- **时间重叠**
  - 多个处理过程在时间上相互错开，轮流重叠使用同一套硬件的各个部件，以加快部件的周转而提高速度
  - 举例：流水线——分离、细化功能部件→流水线→功能不同的多机系统→异构型多处理机系统
- **资源重复**
  - 以数量取胜原则，重复设置硬件资源以大幅度提高计算机系统的性能
- **资源共享**
  - 利用软件方法，使多个用户分时使用同一个计算机系统。例如多道程序、分时系统就是资源共享的产物。它是提高计算机系统资源利用率的有效措施。 
  - 多道程序、分时OS →真正的处理机代替虚拟机→分布处理系统

#### 并行处理的发展

##### 单机系统中并行处理的发展

- 单处理机并行性开发的主要途径是**时间重叠**。
- 实现时间重叠的基础是**部件功能专用化**。
- 将一件工作按功能分割成若干联系的部分，每一部分有指定的专门部件来完成，然后按时间重叠的原则把各部分执行过程在时间上重叠起来，使所有部件依次分工完成一组同样工作。   


> 将若干台具有独立功能的处理机（或计算机）相互连接起来，在操作系统（或分布式操作系统）的控制下，统一协调的运行，这就是**分布式处理系统（distributed processing system）** 。
>
> 分时系统是以“集中”为特征，分布系统是以“分布”为特征。 

##### 多机系统中并行处理的发展 

- 多计算机系统：多台独立的计算机构成的系统。
- 多处理机系统：多台处理机构成的系统（任务级并行）

#### 多机系统耦合:star:

耦合度反映多机系统中各机器之间物理连接的紧密程度和交互作用能力的强弱

- 最低耦合：仅通过中间存储介质互相通信，除此之外，各机器间并无物理连接，也无共享的联机硬件资源 。例如：磁带
- 松散耦合（间接耦合）：机器之间是通过通道或通信线路实现互联，共享某些外围设备。特点：通信频带较低；例如：计算机网络
- 紧密耦合（直接耦合）：通过总线或高速开关实现互连，共享主存储器，机器间通信频率高，信息传输率和吞吐量大。

两种典型的松散耦合形式：

- 多台计算机通过**通道和共享的外围设备连接**，各个机器实现功能专用化，机器处理结果以文件和数据集合形式送到共享外设，供其他机器调用，从而获得较高的系统使用效率；
- 各节点计算机通过计算机网络连接，在网络操作系统管理下，合理调度软、硬件资源，以求得更大范围内资源共享。 



## 第八章 标量处理机

只有标量数据表示和标量指令系统的处理机称为标量处理机

提高指令执行速度的主要途径：

1.  提高处理机的工作主频

2.  采用更好的算法和设计更好的功能部件
3.  采用指令级并行技术

三种指令级并行处理机：

1. 流水线处理机和超流水线(Super-pipelining)处理机

2. 超标量(Superscalar)处理机
3. 超长指令字(VLIW: Very Long Instruction Word)处理机



### 流水线结构原理

**流水作业的特点：**

- 流水线不减少单个任务的耗时，增加整个工作的吞吐量，但被最慢的阶段限制
- 速度=通道数

**指令流水线：**把指令的解释过程分解为“分析”和“执行”两个子过程，并让这两个子过程分别用独立的分析部件和执行部件来实现。

- 理想情况：速度提高一倍

  <img src="assets/image-20231225213850770.png" alt="image-20231225213850770" style="zoom:67%;" />

- 当分析部件完成上一条指令的“分析”后，就立即将之送入执行部件，同时分析部件可以开始处理下一条指令。

- 虽然从执行一条指令的全过程来看，仍需要2∆t的时间，但从机器的输出端来看，却是每隔一个∆t就能给出一条指令的执行结果。

**流水线结构原理**：

如何加快指令的解释过程是计算机组成设计的基本任务。除了采用高速部件外，一次重叠，先行控制和流水等控制方式是常用的，意在提高指令的并行性，从而加速指令的解释过程。控制方式分类：**顺序方式、 重叠方式、 流水方式。**



计算机的各个部分几乎都可以采用：

  **(1)**指令的执行过程可以采用流水线，称为**指令流水线**。

  **(2)**运算器中的操作部件，如浮点加法器、浮点乘法器等可以采用流水线，称为**操作部件流水线**。

  **(3)**访问主存的部件可以采用**访存部件流水线**。多个计算机之间，通过存储器连接，也可以采用流水线，称为**宏流水线**。

#### 指令的重叠执行方式:star:

##### 顺序执行方式

$$
执行n条指令的时间\quad T=\sum_{i=1}^n\left(t_{\text{取指令 }i}+t_{\text{ 分析 }i}+t_{\text{执行 }i}\right)
$$

优点：简单，节省设备；缺点：执行指令的速度慢，功能部件的利用率很低。

##### 重叠方式

在两条相近指令的解释过程中，某些不同解释阶段在时间上存在重叠部分。包括一次重叠、先行控制技术和多操作部件并行。 

###### 一次重叠

把取指令操作隐含在分析、执行指令过程中，则在任何时候只允许**上条指令“执行”与下条指令“分析”相重叠。**           $  T=（n+1）×t $

若执行时间不等，则实际执行时间：
$$
\begin{aligned}{T=t_{\text{分}1}+\sum_{i=2}^{n}[\max(t_{\text{分}i},t_{\text{执}i-1})]+t_{\text{执}n}}\end{aligned}
$$

###### 二次重叠执行方式

把取第k+1条指令提前到分析第k条指令同时执行

- 如果三个过程的时间相等，执行n条指令的时间为：T=(2+n)t

- 理想情况下同时有三条指令在执行

- 处理机的结构要作比较大的改变，必须采用先行控制方式

  <img src="assets/image-20231225215531524.png" alt="image-20231225215531524" style="zoom:50%;" />

采用二次重叠执行方式，必须解决两个问题：

  (1) 有独立的取指令部件、指令分析部件和指令执行部件

​    独立的控制器：存储控制器、指令控制器、运算控制器

  (2) 要解决访问主存储器的冲突问题

​    取指令、分析指令、执行指令都可能要访问存储器



**解决访存冲突的方法**：

  (1) 采用低位交叉存取方式：这种方法不能根本解决冲突问题。

  (2) 两个独立的存储器：独立的指令存储器和数据存储器。
	如果再规定，执行指令所需要的操作数和执行结果只写到通用寄存器，那么，取指令、分析指令和执行指令就可以同时进行。

   (3) 采用先行控制技术。
    先行控制技术的关键是缓冲技术和预处理技术。
    缓冲技术是在工作速度不固定的两个功能部件之间设置缓冲栈，用以平滑它们的工作。
    采用了缓冲技术和预处理技术之后，运算器能够专心于数据的运算，从而大幅度提高程序的执行速度。

<img src="assets/image-20231225215730464.png" alt="image-20231225215730464" style="zoom:50%;" />

多操作部件并行：采用有多个功能部件的处理机，把ALU的多种功能分散到几个具有专门功能的部件中，这些功能部件可以并行工作，使指令流出速度大大提高。 

### 流水线技术

流水线技术的特点：

1. **并行处理**：流水线技术允许将指令的不同阶段（如取指令、译码等）在不同的处理器硬件上同时进行。这种并行处理方式可以显著提高处理器的工作效率。
2. **吞吐量增加**：通过流水线，处理器可以在每个时钟周期完成一个指令的某个阶段，理想情况下可以在每个时钟周期完成一个指令，从而增加吞吐量。
3. **延迟与吞吐量的权衡**：虽然流水线技术提高了吞吐量，但每个指令的总执行时间（从开始到结束的时间）并没有减少，甚至可能由于流水线各阶段的管理开销而略有增加。
4. **效率依赖于指令序列**：流水线的效率在很大程度上取决于执行的指令序列。例如，频繁的分支预测失败会导致流水线中断，从而降低效率。
5. 复杂的设计和管理

#### 流水线的表示方法:star::star:

连接图、时空图、预约表（主要前两种）

**简单流水线**：

流水线的每一个阶段称为**流水步、流水步骤、流水段、流水线阶段、流水功能段、功能段、流水级、流水节拍**等。一个流水阶段与另一个流水阶段相连形成**流水线**。指令从流水线一端进入，经过流水线的处理，从另一端流出。

有些复杂指令在执行阶段也采用流水线方式工作，称为操作流水线。

<img src="assets/image-20231225220247778.png" alt="image-20231225220247778" style="zoom:67%;" />

**指令流水线**：

<img src="assets/image-20231225220332027.png" alt="image-20231225220332027" style="zoom:67%;" />

一般4-12个流水段，大于等于8个为超级流水线处理机

**时空图：**

采用“时空图”表示流水线的工作过程。在时空图中，横坐标表示时间，也就是输入到流水线中的各个任务在流水线中所经过的时间。当流水线中各个流水段的执行时间都相等时，横坐标被分割成相等长度的时间段。纵坐标表示空间，即流水线的每一个流水段 

<img src="assets/image-20231225220605624.png" alt="image-20231225220605624" style="zoom: 50%;" />

- 建立时间：在流水线开始时有一段流水线填入时间，使得流水线填满。
- 正常流动时间：流水线正常工作，各功能段源源不断满载工作。
- 排空时间：在流水线第一条指令结束时，其他指令还需要一段释放时间。



#### 流水线的特点

- 流水一定是重叠的，但是比重叠更苛刻。
- 一条流水线通常有多个子过程。每个子过程称为流水线的“级”或“段”。其数目称为流水线的“深度”。
- 流水线有建立时间、正常满载时间、排空时间。另外，流水线需要有“通过/装入时间”（第一个任务流出结果所需的时间），在此之后流水过程才进入稳定工作状态，每一个时钟周期（拍）流出一个结果。
- 流水线每一个功能段部件后面都要有一个缓冲寄存器，或称为锁存器，其作用是保存本流水段的结果，由于流水线中每一个流水段的延迟时间不可能绝对相等，再加上电路的延迟时间及时钟等都存在偏移，因此流水段之间传送任务时，必须通过锁存器。
- 流水线中各功能段的时间应尽量相等，否则将引起堵塞、断流，这个时间一般为一个时钟周期 。要求流水线的时钟周期不能快于最慢的流水段。另一方面，执行时间长的一个流水段将成为整个流水线的瓶颈，此时流水线中的其他功能部件就不能发挥作用。因此瓶颈问题是流水线设计中必须解决的问题。
- 只有连续不断地提供同一种任务时才能发挥流水线的效率。例如，要使浮点加法器流水线充分发挥作用，需要连续提供浮点加法运算。只有流水线完全满载时，整个流水线的效率才能得到充分发挥。
- 给出指标如最大吞吐率，为满负载最佳指标。

#### 消除瓶颈段的方法:star:

细分瓶颈段  重复设置瓶颈段

<img src="https://pic2.zhimg.com/80/v2-6a236f7d759ceba5bd8e6c2a44f71b49_720w.webp" alt="img" style="zoom: 50%;" />

#### 五级流水线:star::star:

- IF：取指，同时确定下一条*指令地址*（指针指向下一条指令）；
- ID：翻译指令，让计算机知道这条指令是要干什么的，同时让计算机得出要使用的寄存器，或者让**立即数**进行拓展（方便后续指令执行），亦或者（**转移指令**）是给出转移目的寄存器与转移条件；
- EX：执行指令，此阶段按照指令给的内容进行执行；
- MEM：若为 *load/store* 指令，这个阶段就要访问存储器。此外，指令从EX向下执行到WB阶段。**另外**，**在这个阶段还要判定是否有异常要处理，如果有，那么就清除流水线，然后转移到异常处理例程入口地址处继续执行。**
- WB：将运算结果保存到目标寄存器。

> MIPS整数流水线是指在MIPS（Microprocessor without Interlocked Pipeline Stages）架构中实现的整数指令流水线。MIPS架构是一种典型的精简指令集计算机（RISC）架构。
>
> MIPS处理器的整数流水线通常被划分为几个主要阶段，每个阶段完成指令执行过程中的一部分工作。一个典型的MIPS流水线包括以下阶段：
>
> 1. **取指（Instruction Fetch, IF）：**
>    - 在这个阶段，处理器从内存中取出下一条要执行的指令。通常涉及到程序计数器（PC）的读取和更新。
> 2. **译码/寄存器取值（Instruction Decode/Register Fetch, ID）：**
>    - 在译码阶段，处理器解析指令，确定要执行的操作类型，并从寄存器文件中取出所需的操作数。
> 3. **执行/地址计算（Execute/Address Calculation, EX）：**
>    - 执行阶段根据译码阶段的结果执行算术或逻辑操作，或者计算内存访问的地址。对于分支指令，这个阶段也包括条件判断和计算跳转地址。
> 4. **访存（Memory Access, MEM）：**
>    - 如果指令涉及内存访问（如加载和存储指令），这个阶段负责实际的内存读写操作。
> 5. **写回（Write-back, WB）：**
>    - 在写回阶段，执行结果（如果有的话）被写回到寄存器文件中。对于加载指令，从内存读取的数据在这个阶段写入寄存器。
>
> MIPS流水线的设计旨在每个时钟周期内推进一个阶段，以实现高吞吐率和效率。



### 流水线相关

两条指令之间存在某种依赖关系。如果两条指令相关，则它们就有可能不能在流水线中重叠执行或者只能部分重叠执行。

分类有：数据相关，控制相关，结构相关

#### 数据相关（真相关）

在处理器的流水线执行中，后续指令依赖于前面指令的执行结果的情况。这种依赖关系导致流水线无法连续流畅地执行，因为某些操作必须等待之前的操作完成后才能开始。

对于两条指令i和j，如果下述条件之一成立，则称指令j与指令i数据相关。

- 指令j使用指令i产生的结果；
- 指令j与指令k数据相关，而指令k又与指令i数据相关。

数据相关具有传递性。数据相关反映了数据的流动关系，即如何从其产生者流动到其消费者。

- 当数据的流动是经过寄存器时，相关的检测比较直观和容易。

- 当数据的流动是经过存储器时，检测比较复杂。

  - 相同形式的地址其有效地址未必相同；

  - 形式不同的地址其有效地址却可能相同。


#### 名相关（假相关）

名：指令所访问的寄存器或存储器单元的名称。

如果两条指令使用相同的名，但是它们之间并没有数据流动，则称这两条指令存在名相关。

指令j与指令i之间的名相关有两种：

1. **输出相关（Output Dependency）**:
   输出相关发生在两个指令向同一个寄存器或内存位置写入数据。虽然它们之间可能没有直接的数据依赖关系，但如果改变这些指令的执行顺序，可能会导致不同的结果。例如，指令1和指令2都写入寄存器A，指令1后于指令2执行，但如果调整顺序，可能会改变最终寄存器A的值。
2. **反相关（Anti-Dependency）**:
   反相关发生在后面的指令读取一个寄存器或内存位置，而前面的指令将要写入同一个位置。在这种情况下，如果改变指令的执行顺序，可能会导致读取操作使用了错误的数据。例如，指令1读取寄存器A的值，而指令2将要写入寄存器A，如果调整顺序，指令1可能会读取到指令2写入的值。

名相关的两条指令之间并没有数据的传送。如果一条指令中的名改变了，并不影响另外一条指令的执行。

换名技术：通过改变指令中操作数的名来消除名相关。对于寄存器操作数进行换名称为寄存器换名。既可以用编译器静态实现，也可以用硬件动态完成。

#### 控制相关

**控制相关**因为程序执行转移类指令而引起的相关。转移类指令如无条件转移、条件转移、子程序调用、中断等，它们属于分支指令，执行中可能改变程序的方向，从而造成流水线断流。

数据相关影响到的仅仅是本条指令附近少数几条指令，所以称为局部相关。**而控制相关影响的范围要大得多，它会引起程序执行方向的改变，使流水线损失更多的性能，所以也称为全局相关。**

当执行条件转移指令时，有两种可能结果：

1. 如发生转移，将程序计数器PC的内容改变成转移目标地址；
2. 如不发生转移，只是将PC加上一个增量，指向下一条指令的地址。

> "Control Dependence Ignored"（忽略控制依赖）是在编译优化和程序并行化领域中的一个概念，尤其是在尝试提高程序执行效率的过程中。它涉及到一种假设或技术，即在某些情况下可以忽略控制依赖，以便在不改变程序意义的前提下进行更大范围的代码重组或并行化。
>
> **忽略控制依赖的动机**：
>
> - **性能优化**：通过重排指令顺序或并行执行原本依赖于控制流的指令，可以提高程序的性能。
> - **编译器优化**：编译器在优化代码时可能会选择忽略某些控制依赖，以便重新安排指令序列，减少延迟，或增加并行度。
> - **并行处理**：在多线程或多核心处理中，忽略控制依赖可以帮助更有效地利用资源，通过并行执行原本串行的代码片段。
>
> 实现忽略控制依赖的技术可能包括但不限于：
>
> - **谓词执行**（Predication）：将条件分支转换为条件执行的指令，这样所有路径上的指令都会执行，但只有在给定条件为真时才会影响状态。
> - **编译时分析**：静态分析代码以确定哪些控制依赖可以安全地忽略或重新排列。
> - **动态重排**：在运行时动态地决定指令的执行顺序，可能结合硬件支持。

控制依赖性施加了两个约束

- 控制依赖于分支的指令不能移动到分支之前，因此其执行不再受分支控制。
- 控制不依赖于分支的指令不能移动到分支之后，从而使其执行由分支控制。



### 流水线冲突:star::star::star:

#### 数据冲突（Data Hazards）

当相关的指令靠得足够近时，它们在流水线中的重叠执行或者重新排序会改变指令读/写操作数的顺序，使之不同于它们串行执行时的顺序，则发生了数据冲突。

假设我们需要执行指令：

1. `I1: ADD R1, R2, R3` - 将寄存器R2和R3的值相加，结果存储在R1中。
2. `I2: SUB R4, R1, R5` - 从寄存器R1的值中减去R5的值，结果存储在R4中。
3. `I3: MUL R6, R4, R7` - 将寄存器R4和R7的值相乘，结果存储在R6中。

**分类如下：**

- 先写后读（RAW, Read After Write读后写）： 一条指令需要读取前一条指令写入的数据。
  - 例子： I1和I2之间存在RAW相关，因为I2需要使用I1计算的结果（R1的值）
- 先读后写（WAR, Write After Read写后读）： 一条指令需要写入的数据之前被另一条指令读取。
  - 假设例子： 如果I2写入R2，而I1要读取R2，那么I1和I2之间就存在WAR相关。
- 写后写（WAW, Write After Write写后写）： 两条指令写入相同的位置。
  - 假设例子： 如果有另一条指令I4: ADD R1, R8, R9紧跟I1，那么I1和I4之间存在WAW相关，因为它们都想写入R1。

后两种类型只会出现在异步流水线中！

**解决方法：**

1. **正常定向路径（Data Forwarding/Bypassing）：**

   - 设置相关专用通路

   - **应用于RAW：** 在`I1`和`I2`的情况中，可以将`I1`计算出的结果直接从执行单元传递给`I2`，而不必等待其写回到R1。

     <img src="assets/image-20231226104609209.png" alt="image-20231226104609209" style="zoom:50%;" />

   - 上一阶段的

<img src="https://img-blog.csdnimg.cn/direct/4f85987fee8c4c3aa73fd2013bbb2dd9.png" alt="img" style="zoom: 33%;" />

1. **指令重排（Instruction Reordering）：**
   - 如果可能，重新安排指令的顺序，以减少指令之间的直接依赖。
   - 例如，如果`I3`不依赖于`I1`和`I2`的结果，可以先执行`I3`。
2. **流水线暂停（Pipeline Stalling）：**
   - 当检测到数据相关时，特别是在前递不可能的情况下，暂停流水线直到所需数据准备好。
   - 例如，在`I1`和`I2`的例子中，如果前递不可行，则`I2`可能需要等待直到`I1`完成写回操作。
3. **动态调度（Dynamic Scheduling）：**
   - 处理器在运行时动态地检测指令之间的依赖性，并调整指令的执行顺序。
   - 这种方法在现代处理器中常见，特别是在乱序执行环境中。



#### 控制冲突（Control Hazards）

##### 减轻控制冲突的方法：

1. **分支预测（Branch Prediction）：**
   - **原理**：提前预测分支指令的结果（是否会跳转以及跳转目标地址），并据此继续指令的取指和执行。
   - **实现**：可以是简单的静态预测（如始终预测跳转或不跳转），或复杂的动态预测（基于历史信息进行预测）。
   - 预测分支失败
     - 流水线继续照常流动，就像没发生什么似的。在知道分支结果之前，分支指令后的指令不能
       改变机器状态，或者改变了之后能够回退。
     - 若预测分支失败，则照常执行；否则，从转移目标处开始取指令执行。
   - 预测分支成功
     - 假设分支转移成功，并开始从分支目标地址处取指令执行。
     - 起作用的前题：先知道分支目标地址，后知道分支是否成功。
   - 想办法提高猜测的正确率，可以有效提高流水线效率
2. **延迟分支（Delayed Branch）：**
   - **原理**：在分支指令后安排几条无关的指令执行，这些指令无论分支结果如何都要执行。
   - **实现**：编译器或汇编程序员负责在分支指令后安排适当的指令。
3. **双指令缓冲：**
   - 同时运行判断语句的两个分支，使用正确的那一个
4. **分支目标缓冲区（Branch Target Buffer, BTB）：**
   - **原理**：缓存分支指令的目标地址，使得在再次遇到相同的分支指令时，可以快速获取跳转地址。
   - **实现**：硬件中实现一个专门的缓存，存储分支指令的地址及其对应的跳转目标地址和分支结果。
5. **分支历史表（Branch History Table, BHT）：**
   - **原理**：记录分支指令的历史行为（跳转或不跳转），用于动态分支预测。
   - **实现**：在硬件中维护一个表格，记录每个分支指令的历史行为，以指导未来的预测。
6. **动态预测技术：**
   - **原理**：使用更复杂的算法，如基于局部或全局历史的预测算法，以提高分支预测的准确性。
   - **实现**：例如，两级自适应训练（Two-Level Adaptive Training）或全局历史表（Global History Table）等。
7. **乱序执行和指令重排：**
   - **原理**：允许处理器乱序执行指令，并在保证数据一致性的前提下调整指令的完成顺序。
   - **实现**：在处理器中实现复杂的逻辑，以允许乱序执行和动态调度。



##### 延迟分支:star:

延迟分支（Delayed Branch）是一种用于处理流水线中控制相关的技术，尤其是在分支指令导致的流水线停顿（Branch Stall）中。延迟分支的核心思想是**在分支决定是否跳转以及跳转到哪里之前，执行一个或多个“分支延迟槽”（Delay Slot）中的指令。这样做的目的是在分支指令的影响被解析出来之前，利用原本会空闲的流水线周期。**

延迟分支所使用的填充指令通常来源于：

1. 从前调度 分支必须不依赖于被调度的指令 总是可以有效提高流水线性能
2. 从目标处调度 如果分支转移失败，必须保证被调度的指令对程序的执行没有影响，可能需要复制被调度指令 分支转移成功时，可以提高流水线性能。但由于复制指令，可能加大程序空间
3. 从失败处调度 如果分支转移成功，必须保证被调度的指令对程序的执行没有影响 分支转移失败时，可以提高流水线性能

移动指令到延迟槽的方式：

1. **简单移动**：直接将分支后紧接着的指令移动到延迟槽中。
2. **复杂重排**：进行更全面的代码分析和重排，找到可以安全移动到延迟槽的指令。
3. **循环展开**：在循环结构中，将循环体内的某些指令移动到循环条件的分支延迟槽中。
4. **与其他优化技术结合**：如和指令流水线优化、循环变换等结合，以找到更多合适的指令。

##### 动态分支预测

动态分支预测是一种在现代微处理器中常用的技术，用于提高处理器执行指令时的效率。这种技术旨在预测程序中的条件分支（如if-else语句或循环）将如何执行，以减少因等待分支结果而导致的处理器空闲时间。

**动态分支预测的基本原理**

动态分支预测依赖于在运行时收集的信息，以预测分支指令的行为。它的核心思想是基于分支指令的历史行为来预测它未来的行为。这种方法认为程序的行为具有一定的模式，通过观察过去的行为来预测未来的行为。

**动态分支预测必须解决两个问题**：

- 如何记录一个分支操作的历史
  - 仅仅记录最近一次或最近几次的分支历史；
  - 记录分支成功的目标地址；
  - 记录分支历史和分支目标地址，相当于前面两种方式的结合；
  - 记录分支目标地址的一条或若干条指令。  
- 决定预测的走向。

**如何预测**

- 如果预测正确，则不会产生分支惩罚，因为我们获取了正确的指令
- 如果预测错误（错误预测），则必须从流水线中清除错误指令
- 最简单的预测器：始终预测未执行的指令
- 动态分支预测器在分支历史表（BHT）（又称分支预测缓冲区）中跟踪过去的行为

**关键组件和技术**

1. **分支历史表（Branch History Table, BHT）**：这是一种硬件机制，用于记录每个分支指令的最近几次执行情况（是否发生了跳转）。
2. **分支目标缓冲区（Branch Target Buffer, BTB）**：存储分支指令的目标地址，当再次遇到相同的分支指令时，可以快速获取跳转地址。
3. **分支预测算法**：例如二位饱和计数器（Two-bit Saturating Counter），它为每个分支维护一个小型状态机，根据最近几次的跳转或不跳转历史来预测下一次的行为。
4. **全局历史记录**：考虑整个程序的分支历史，而不仅仅是单个分支的历史。这可以通过全局历史表（Global History Table）等实现。
5. **局部历史记录**：仅考虑特定分支的历史。

:hand:例子：

1. 只有1个预测位的分支预测缓冲 

  - 索引：分支指令地址的低位。

  - 存储区：1位的分支历史记录位，又称为预测位，记录该指令最近一次分支是否成功。

    - “0”记录分支不成功 
    - “1”记录分支成功

  - 状态转换图 

    <img src="assets/image-20231226115027385.png" alt="image-20231226115027385" style="zoom:33%;" />

  - 分支预测错误时，预测位就被修改，并且需要恢复现场，程序从分支指令处重新执行。 

  - 缺点：只要预测出错，往往是连续两次而不是一次。

2. 采用两个预测位

  - 必须有两次连续预测错误才更改

    <img src="assets/image-20231226122138385.png" alt="image-20231226122138385" style="zoom: 50%;" />

3. n 位分支预测缓冲

  - 采用n位计数器，则计数器的值在0到2n-1之间：
      当计数器的值大于或等于最大值的一半（2n-1）时，
      预测下一次分支成功；否则预测下一次分支不成功。
  - 预测位的修改和两位预测时相同：
      当分支成功时计数器的值加1，不成功时减1。
  - 研究表明：n位分支预测的性能和两位分支预测差不多，因而
      大多数处理器都只采用两位分支预测。

#### 结构冲突（Structure Hazards）

硬件资源满足不了指令重叠的要求

**结构相关解决方法**：

- 当两个指令同时需要相同的硬件资源时，就会产生结构冲突
  - 能否在硬件上通过拖延新指令直到旧指令用完资源来解决问题
- 通过在设计中添加更多的硬件，总是可以避免结构上的危险
  - 例如，如果两个指令同时需要一个端口到内存，可以通过增加第二个端口到内存来避免危险

#### 异常和中断

##### 精确中断与非精确中断

精确中断（Precise Interrupts）与非精确中断（Imprecise Interrupts）是处理器在面对中断和异常时的两种不同处理机制。

**精确中断（Precise Interrupts）**

精确中断指的是处理器能够在任何指令的执行点准确地报告程序的状态。当发生精确中断时，处理器保证以下条件：

1. **所有先于中断点的指令都已完全执行**：这意味着所有影响程序状态的操作都完成了。
2. **所有后续指令尚未执行**：即中断点之后的指令不会影响程序状态。
3. **程序计数器（PC）精确地指向引起中断的指令**：这允许程序在处理中断后恢复执行。
4. **所有的寄存器和内存状态都能反映出中断发生时的确切情况**。

精确中断对于调试、错误恢复和多线程程序的正确性至关重要。它确保在中断处理后，程序能够无缝地从中断点继续执行。

**非精确中断（Imprecise Interrupts）**

非精确中断是指处理器不能保证上述所有条件，特别是在现代高性能处理器使用复杂技术（如乱序执行、规格执行）时。在非精确中断发生时：

1. **一些先于中断点的指令可能尚未完成**。
2. **一些后续指令可能已经部分或完全执行**。
3. **程序计数器可能不精确指向引起中断的指令**。

非精确中断使得错误恢复和程序调试变得更加困难，因为中断时的程序状态可能不完全清晰。

##### 处理中断的四种可能的办法

方法1：忽略这种问题，当非精确处理

- 原来的supercomputer的方法
- 但现代计算机对 IEEE 浮点标准的异常处理，虚拟存储的异常处理要求必须是精确中断。

方法2：缓存操作结果，直到早期发射的指令执行完。

- 当指令运行时间较长时，缓冲区较大
- Future file
  - 缓存执行结果，按指令序确认
- history file
  - 尽快确认
  - 缓存区存放原来的操作数，如果异常发生，回卷到合适的状态

方法3：以非精确方式处理，用软件来修正

- 为软件修正保存足够的状态
- 让软件仿真尚未执行完的指令的执行
  - Instruction 1 – A 执行时间较长，引起中断的指令
  - Instruction 2, instruction 3, ….instruction n-1 未执行完的指令
  - Instruction n    已执行完的指令
  - 由于第n条指令已执行完，希望中断返回后从第n+1条指令开始执行，如果我们保存所有的流水线的PC值，那么软件可以仿真Instruction1 到Instruction n-1 的执行

方法4：暂停发射，直到确定先前的指令都可无异常的完成，再发射下面的指令。

- 在EX段的前期确认（MIPS流水线在前三个周期中）

  

### 流水线分类:star:

流水线（Pipeline）在计算机架构中是一种重要的概念，用于提高处理器的性能。流水线可以按照不同的方式进行分类，每种分类侧重于流水线的某个特定特征或设计理念。以下是一些常见的流水线分类方式及其类别：

#### 按照流水线的级别来分

- 处理机级流水线，又称为指令流水线 (Instruction Pipelining)，例如：在采用先行控制器的处理机中，各功能部件之间的流水线

  <img src="assets/image-20231226110240480.png" alt="image-20231226110240480" style="zoom: 33%;" />

- 部件级流水线（操作流水线），把处理机的算术逻辑部件分段，使得各种数据类型的操作能够进行流水。如浮点加法器流水线

  <img src="assets/image-20231226110317649.png" alt="image-20231226110317649" style="zoom: 33%;" />

- 宏流水线 (Macro Pipelining)，每个处理机对同一个数据流的不同部分分别进行处理，它是指由两个以上的处理机串行地对同一数据流进行处理，每个处理机完成一项任务。

  <img src="assets/image-20231226110343597.png" alt="image-20231226110343597" style="zoom: 33%;" />

#### 单功能流水线与多功能流水线

- 单功能流水线：只能完成一种固定功能的流水线
  - Cray-1计算机中有12条；YH-1计算机有18条；Pentium有一条5段的定点和一条8段的浮点流水线；PentiumⅢ有三条指令流水线，其中两条定点指令流水线，一条浮点指令流水线。
- 多功能流水线：流水线的各段通过不同连接实现不同功能
  - Texas公司的ASC计算机中的8段流水线，能够实现：定点加减法、定点乘法、浮点加法、浮点乘法、逻辑运算、移位操作、数据转换、向量运算等。

#### 按照指令处理的方式分类

a. 静态流水线（Static Pipeline）

- **定义**：每个流水线阶段在每个时钟周期内**执行固定的操作**（只能进行加减运算或者定乘运算），流水线的行为在编译时就已经确定。
- **特点**：结构简单，易于实现，但在面对复杂指令或数据依赖时效率较低。只有当输入端是一串相同的运算操作时，流水的效率才能发挥。

b. 动态流水线（Dynamic Pipeline）

- **定义**：流水线能够根据运行时的情况动态调整，同一时间内，某些段正在实现某种操作（如定乘）而另外一些段却在实现另一种运算（如浮点加法）。
- **特点**：能更有效地处理各种冒险和依赖，提高执行效率，但设计复杂。


#### 按照指令执行的顺序分类

a. 线性流水线（Linear Pipeline）

- **定义**：指令按照固定的顺序逐阶段进行处理，每个阶段固定。
- **特点**：设计简单，适合顺序执行的任务。

b. 超标量流水线（Superscalar Pipeline）

- **定义**：在每个时钟周期内可以同时发射和完成多条指令。
- **特点**：能够提高吞吐率，但需要复杂的指令调度和冒险管理机制。

c. 乱序执行流水线（Out-of-Order Pipeline）

- **定义**：指令可以根据数据依赖和资源可用性乱序执行。
- **特点**：提高资源利用率和执行效率，但设计和实现相对复杂。

#### 标量流水处理机和向量流水处理机

- 标量流水处理机：处理机不具有向量数据的表示，仅对标量数据进行流水处理。
- 向量流水处理机：处理机具有向量数据的表示，通过向量指令对向量的各元素进行处理。

#### 线性流水线和非线性流水线

- 线性流水线: 流水线的各段串行连接，没有反馈回路。
- 非线性流水线：流水线中除有串行连接的通路外，还有反馈回路。一次运算中多次使用流水线中的某些功能段



### 线性流水线的性能分析 :star::star:

1. 吞吐率

   - 定义：**单位时间内流水线完成指令的数量**。

    - $TP=n/T_k$，$TP$为吞吐率，$n$为指令数，$T_k$为完成n个指令所用时间

    - 若各段执行时间相等，则输入连续任务情况下完成n个连续任务需要的总时间为：$T_k=(k+n-1)D_t$，$k$为流水线段数，$D_t$为完成一条指令所需时间

      - 最大吞吐率： $TP_\max=\underset{n\to\infty}{\operatorname*{Lim}}\frac n{(k+n-1)\Delta t}=\frac1{\Delta t}$

    - 各段执行时间不相等、输入连续任务情况下：吞吐率为

$$
\begin{aligned}TP=\frac{n}{\sum_{i=1}^kt_i+(n-1)\max(\Delta t_1,\Delta t_2,\cdot\cdot\cdot,\Delta t_k)}\end{aligned}
$$

2. 延迟（Latency）**如果要填流水线的性能指标 忽略这个！！**

   - 定义：一条指令从开始到结束所需的时间。

   - 计算方法：通常以时钟周期数计算。在流水线中，延迟等于流水线的深度（阶段数）乘以时钟周期时间。


3. 流水线效率（Pipeline Efficiency）

   - 定义：流水线资源的利用率。

   - 计算方法：**有效执行时间与总执行时间的比率**。如果存在流水线停顿（如由于数据冒险），效率会下降。

   - 若各段时间相等，则各段的效率$e_i$相等，即 $e_1=e_2=\dots=e_k=\Delta t_o/T_{流水}$

     整个流水线的效率：$\begin{aligned}E=\frac{n\Delta t_0}{T_\text{流水}} = \frac n { k + n - 1 }&=\frac1{1+\frac{k-1}n}\end{aligned}$

     从时空图上看，效率实际上就是 **n 个任务所占的时空区与 k 个段总的时空区**之比，即：

   $$
   E=\frac{n\text{个任务占用的时空区}}{ k\text{个流水段的总的时空区}} = \frac { T _ 0 }{ k \cdot T _ k}
   $$

   - 若各段时间相等，输入$n$个连续任务流水线的效率为：$E=\frac{k\cdot n\cdot\Delta t}{k\cdot(k+n-1)\cdot\Delta t}=\frac n{k+n-1}$

     最高效率为：$\begin{array}{rcl}E_\mathrm{max}=Lim\frac n{k^2+2n^2-1}=1\end{array}$

   - 各流水段执行时间不等，输入n个连续任务流水线的效率为：
     $$
     E=\frac{n\cdot\sum_{i=1}^k\Delta t_i}{k\cdot[\sum_{i=1}^k\Delta t_i+(n-1)\cdot\max(\Delta t_1,\Delta t_2,\cdots,\Delta t_k)]}
     $$


4. 速度提升比（Speedup Ratio）

   - 定义：流水线相比于非流水线执行的速度提升。

   - 计算方法：**非流水线执行时间与流水线执行时间的比率**。理想情况下，速度提升与流水线的阶段数相等。$S = 顺序执行时间T_0 / 流水线执行时间T_k$

   - 各段执行时间相等，输入连续任务情况下加速比为：
     $$
     S=\frac{k\cdot n\cdot\Delta t}{(k+n-1)\Delta t}=\frac{k\cdot n}{k+n-1}
     $$

   - 最大加速比：$S_\max=\underset{n\to\infin}{\operatorname*{Lim}}\frac{k\cdot n}{k+n-1}=k$

    - **各段执行时间不等**，输入连续任务情况下实际加速比为：
      $$
      S=\frac{n\cdot\sum_{i=1}^{\kappa}\Delta t_i}{\sum_{i=1}^{k}\Delta t_i+(n-1)\cdot\max(\Delta t_1,\Delta t_{2,\cdots,\Delta t_k})}
      $$

### 调度

假设 lw 指令后面紧跟着一连串的计算指令，且这些计算指令和 lw 指令没有关系，在这种情况下，如果lw指令发生Cache缺失，那么它可能会被卡在访存阶段几十上百个周期，而因为处理器是顺序执行的，所以后面的一连串计算指令也都被阻塞住。

在理想情况下，我们肯定希望在 lw 指令阻塞的时候，别的可以执行的指令继续执行。但是这在一个顺序执行的处理器中是做不到的，顺序执行的处理器只能一个接着一个地执行，如果想要实现“继续执行”，即后面的指令“绕过” lw 指令继续执行，那么就需要处理器支持乱序。

#### 静态指令调度

静态调度(static scheduling)是由优化的编译程序来完成，其基本思想是重排指令序列，拉开具有数据相关的有关指令间的距离。由于是用编译程序判测潜在的数据相关，并在程序运行之前完成调度，故称为静态调度。

#### 动态调度

- 通过忽略 "顺序 "程序中人为的串行限制，实现更多并行性，也称为失序问题（OOO-issue）：指令不需要按照原来的程序顺序执行

优点：

1. **提高资源利用率**：动态调度可以更有效地利用处理器资源，如算术逻辑单元（ALU）、寄存器等，减少空闲时间。
2. **提升性能**：通过减少指令间的依赖和冲突，减少阻塞和等待时间，提高执行效率。
3. **更好的适应性**：能够根据当前系统的负载和环境条件灵活调整，适应多变的工作条件。
4. **容错和负载均衡**：在发现错误或性能瓶颈时，能够动态地重新分配任务，实现负载均衡。

#### ScoreBoard 记分牌算法

记分牌算法是 CDC 公司在上个世纪提出的一个乱序执行算法，合理使用记分牌算法，就可以让多配置流水的处理器实现乱序执行。首个应用记分牌算法的处理器是CDC公司在上个世纪六十年代研发的 CDC 6600，实际上 CDC 6600 不能说是一个处理器，因为 CDC 6600 是一个几吨重的超级计算机。

##### 记分板信息

积分板其实是一个信息存储单元，包含了两块信息：

**功能单元状态**：记分牌是面向功能部件的，在记分牌中每一个功能部件都有一组信息，信息包括部件是否正在忙、部件执行的指令类型、部件现在需要的源寄存器、部件现在的目的寄存器、源寄存器是否准备好（Rj、Rk 表示）和如果源寄存器没准备好部件该向哪里要数据（Qj、Qk 表示，PPT 中有一个表格，表格 Mult1 这一行 Qj 是 Integer，这就表示乘法单元 1 的 F2 源寄存器的数值将由整数部件算出）

<img src="assets/image-20231227175514497.png" alt="image-20231227175514497" style="zoom:50%;" />

**寄存器结果状态：**

<img src="assets/image-20231227175722202.png" alt="image-20231227175722202" style="zoom:50%;" />

##### 工作流程

<img src="https://pic1.zhimg.com/80/v2-6b7e47a0ccd134bb87f058bc23ff2468_720w.webp" alt="img" style="zoom:67%;" />

**黄色方框表示流水段寄存器**，分别有指令寄存器、部件寄存器（即 MUL_1 这一列）、操作数寄存器（ OPRAND ）、结果寄存器（ RESULT ）。**蓝色部分是解码单元和运算单元。红色部分是寄存器堆。绿色部分是记分牌**。解码单元和记分牌的交互是指解码单元要“问”记分牌当前指令是否有“ WAW 冒险”和“ Structure 结构冒险”，如果没有，指令就可以顺利渡过当前的阶段，后面的 RAW、WAR 也都是这个意思。

一条指令分四个阶段执行，分别是**发射、读数、执行、写回**

**发射**

对指令进行解码，并观察记分牌信息，主要观察各个功能部件的占用情况，和寄存器堆的写情况，以此来判断是否可以把解码得到的信息存进对应的部件寄存器。

如果指令对应的功能部件空闲，且指令要写的目标寄存器没有别的指令将要写（这是为了解决 WAW 冒险），那么阶段结束的时候，就可以把指令信息存进部件寄存器，同时改写记分牌，把指令相关信息进入记分牌。

**取数**

观察记分牌，了解当前指令需要哪些寄存器的数值、该数值是否准备好、如果数值没有准备好的话数值正在哪个功能部件进行运算。如果数值没有准备好（这是为了解决 RAW 冒险），那么指令就卡在部件寄存器中，无法读取数据。

如果寄存器都可以读取，那么阶段结束的时候，对应的寄存器数值会被存进操作数寄存器中，注意，这里不会改写记分牌。

**执行**

执行计算过程，计算过程可能维持很多个周期。

在第一个计算周期结束时，记分牌的读取寄存器部分内容（即 Rj、Rk ）会被修改，表明指令不再需要读寄存器。至于为什么不在读取阶段结束时就这么修改，我也不清楚。

在得到计算结果的那个周期结束时，结果会被存进结果寄存器。

**写回**

此时需要观察记分牌，如果别的指令不需要读当前计算结果即将写入的寄存器（这是为了解决 WAR 冒险，需要观察所有 Rj、Rk，如果相关寄存器的 Rj、Rk 是 Yes ，那就说明有指令要读当前要写入的寄存器，如此一来就要先等前序指令读完寄存器再写回），那么周期结束时，就会把结果写回到寄存器堆，同时会清空记分牌中的信息。

总结和补充一下记分牌工作流程中的要点：

- 一条指令能否发射，一看是否有功能部件空闲可用，这个信息包含在功能状态中；二看指令要写的寄存器是否正要被别的指令写，这个信息包含在寄存器状态中，观察这个信息是为了解决 WAW 冒险。
- 一条指令能否读数，要看记分牌是否提示源寄存器不可读，如果不可读，就说明该寄存器将要被别的前序指令改写，现在的指令要等待前序指令写回，观察这个信息是为了解决 RAW 冒险。
- 一条指令一旦读数完成，就必然可以进行运算，运算可以是多周期的，在第一个周期结束时应该改写功能状态，表明自己不再需要读寄存器。
- 一条指令能否写回，要看是否有指令需要读即将被改写的这个寄存器，具体一点来说，就是要观察标记 Yes 的Rj、Rk 对应的寄存器里是否有当前指令的目的寄存器，如果有，就说明有指令需要读取寄存器的旧值，这样一来我们就要等指令读完旧值之后再写回，观察这个信息是为了解决 WAR 冒险。

**优缺点：**

记分牌算法的优点是**实现了指令的乱序执行，解决了乱序执行过程中的数据冒险问题**，实现了指令的数据流式运行（即数据一旦准备好就开始运行，这区别于传统五级流水线中控制运行方式），并且实现起来并不复杂。

但是记分牌算法还是会因为 WAR 和 WAW 冒险而产生阻塞，**且一旦产生阻塞，后续相同类型的指令就没办法继续发射**（在乱序执行过程中，记分牌规定每一条配置路线都只能同时存在一条指令），即图中所列的“ Limited waiting space at functional units ”，如果后续相同类型的指令没法发射，那么更后面的也许可以立马执行的指令也会被阻塞到，这对性能有很大的影响。

而且记分牌算法在指令完成时不是顺序的（即写回的时候不按顺序），**不按顺序完成指令会对程序的调试提出挑战**。

#### Tomasulo算法:star:

Tomasulo算法是一种用于处理器流水线的动态调度算法，由Robert Tomasulo在IBM为System/360设计的浮点单元中首次实现。这个算法的主要目的是通过乱序执行和寄存器重命名来减少指令之间的数据依赖，从而提高执行效率。

##### 消除假的数据冒险

根据判断结果，**SocreBoard采用停滞发射、tag广播和停滞写回机制解决了三种数据冒险，从而在逻辑上支持了乱序执行**。

但是记分板算法有很大缺点：

1. 每一个运算部件都只拥有一个OPRAND流水段寄存器，也只拥有一个译码信息流水段寄存器，这意味着多配置处理器中的每一条配置通路同一时间只能存在一条指令，如果某一配置通路被占据，而INST中又来一条该配置通路的对应指令，那这条指令就没法发射到配置通路上
2. 为了乱序执行指令，在碰到写后写、读后写这两个冒险的时候也会暂停流水线，而这其实是不必要的
3. 而且记分牌的“写回”是乱序的，乱序完成指令不利于处理器处理中断、异常等情况，不利于程序员debug程序

**“读后写”、“写后写”两个冒险是“假的冒险”**。只需要更改写入的寄存器，就可以解决写入的冒险。即这两种冒险其实没有数据依赖，**即发生冒险的指令之间其实没有数据流动**。



**寄存器重命名：**

消除假数据相关的主要方法是寄存器重命名

有两种方法实现寄存器重命名：

1. 在逻辑寄存器之外存在一组物理寄存器。假如逻辑寄存器正要被改写或被读，就置Busy位为1，并通过Tag指示最新数据将被写到哪一个物理寄存器。通过这样的方法，我们可以在新数据计算完毕时立刻写回，同时也允许前序指令读取寄存器旧值（因为旧值没有被覆盖，它还存在于逻辑寄存器中）。
2. 把两者混合起来，即为处理器提供超过逻辑寄存器数量的寄存器，如MIPS指令集要求32个逻辑寄存器，那就设计40个物理寄存器给处理器，至于哪些寄存器是ISA要求的32个寄存器，则视程序运行情况而定，相关信息可以用一个表格存储起来，理论上任何一个物理寄存器都可能是任何一个逻辑寄存器。

Tomasulo在解决这两个冒险的时候是这样的：发生写后写冒险时总是把最新的值写进寄存器，稍微旧一点的值不写进寄存器，但是广播，如果有指令需要这个稍微旧的值，就可以通过广播接收到数据；发生读后写冒险时，咳咳，Tomasulo算法里不会出现读后写冒险，因为指令一旦发射，指令就会把能读取的数据拷贝下来，一旦拷贝下数据，源寄存器是否被改写就和该指令没关系了。

##### Tomasulo算法

Tomasulo是一种计算机硬件架构的**算法**，用于动态调度指令的指令，允许乱序执行以及更有效率的使用多个执行单元。它由IBM公司在1967年提出，首次应用是在IBM system 360上。**第一节花那么大功夫讲解数据冒险和寄存器重命名，是因为Tomasulo最大的特点就是通过借助重命名的思想消除了假数据冒险，从而提高了机器的乱序性能**。Tomasulo算法的实现结构如图4。在开始了解Tomasulo之前，首先观察一下这个结构：

- 首先是FP OP Queue，这里是浮点指令队列，指令在这里等待发射；
- 青绿色模块是加法单元和乘法单元的保留站；
- 蓝绿色的Address Unit是地址计算单元，在这个算法中存储指令在执行前会先计算好存储地址；
- Memory Unit则是存储单元；
- CDB是数据广播总线（在[记分牌一文](https://zhuanlan.zhihu.com/p/496078836)提到过），它可以直达寄存器堆（用来更新通用寄存器）、加法乘法存储单元的保留站（输送保留站中指令需要的数据）。

<img src="https://pic2.zhimg.com/80/v2-7c9ec91e4b9d9a052d39fcde3a2316c1_720w.webp" alt="img" style="zoom: 50%;" />

###### 保留站和寄存器结果状态表

保留站是Tomasulo算法提出的新结构，有点类似记分牌中每一个配置通路前面的译码信息流水段寄存器，但是记分牌中每一条配置通路只能存放一条指令，**而Tomasulo算法则为每一条通路配置了一组缓冲**，就像图4中的绿色模块，其中浮点加法单元拥有能够缓冲三条指令的保留站。保留站存储的信息和记分牌有点类似：

<img src="assets/image-20231227185805690.png" alt="image-20231227185805690" style="zoom:67%;" />

保留站的结构有点像cache，可能有多行数据，每一行都对应一条被发射到保留站的指令。保留站每一行都有Busy位，指示这一行是否现存有指令；Vj和Vk与记分牌不同，记分牌的Vj和Vk会记录源寄存器的编号，**而保留站则直接把能读取的数据直接拷贝到保留站中**，可想而知，一旦数据进入保留站，那对应的寄存器就和这条指令没瓜葛了；Qj和Qk的信息和记分牌一样，记录尚不能读取的数据将由哪条指令算出；A是存储的地址，用于存放立即数和计算得到的地址数据。

看上去保留站和记分牌非常相似，但是两者其实有很大的不同。以图5的Add为例，保留站中有三行Add信息，这三行数据对应的是同一个加法单元，而在记分牌中这代表着三个加法单元。记分牌那样的一条通路只对应一条信息的做法容易造成指令堵塞、无法发射，**而保留站则为每条通路预留了缓冲区，指令可以在加法单元忙碌的时候发射到保留站的缓冲区待命**。

其次，保留站会直接把读取的数据缓冲下来，而不像记分牌一样只记录一个寄存器编号，只记录编号的话会造成读后写阻塞，因为一条指令在正式执行前一直在监控着它的源寄存器，源寄存器的值是不能改变的，因此后续指令无法写回，只能阻塞流水，**而保留站则贯彻了“数据一旦准备完毕，就立马执行指令”的思想**，指令一旦发现有数据可读，就立马读下来，读下来之后，那个源寄存器的写与不写就不关己事了。

记分牌和保留站相同的地方是都记录了Qj和Qk，即一旦需要的数据被算出来，就通过Qj和Qk捕捉广播数据，**这样的做法其实就是重命名，即用保留站的编号而不是寄存器编号来标记数据源**。



**Tomasulo算法的调度分为三个步骤：发射、执行、写回**。相比记分牌少了读数这个环节，因为在Tomasulo中指令在发射时就会读数。

- 发射：**Tomasulo算法是顺序发射的**，即指令按照程序中的顺序一条接一条被发射到保留站。**判断能否发射的唯一标准是指令对应通路的保留站是否有空余位置**，只要保留站有空余，就可以把指令发射到保留站中。周期结束时会更新保留站和寄存器结果状态表，如果指令有可以读取的数据，就会立刻拷贝到保留站中；寄存器结果状态表中总是存有最新的值，即如果后序指令的目的寄存器和前序指令的目的寄存器重合，那就只保留后序指令的写信息。
- 执行：指令通过拷贝数据和监听CDB获得源数据，然后开始执行，执行可能是多周期的，在执行过程中不改变处理器状态。
- 写回：指令在写回阶段通过CDB总线将数据直通到寄存器堆和各个保留站；周期结束时，根据寄存器结果状态表来更新寄存器堆，并且清除保留站和寄存器结果状态表的信息。



##### 要点总结和补充（重点）

总结和补充一下Tomuasulo调度流程中的要点：

- 一条指令能否发射，要看对应配置通路的保留站是否有空余，**只要有空余，就可以发射到保留站中等待执行；发射的同时会把能读取的数据直接拷贝到保留站**，这样做就不用考虑读后写冒险，后续的指令只要完成就可以写回，不用顾虑是否会有前序指令需要读取寄存器，换句话说，每一条被发射到保留站中的指令都不再需要读取寄存器堆。
- 指令在发射的时候会更新寄存器状态表，如果后序指令和前序指令的目的寄存器重合了，就用后序指令的写信息标志寄存器，**表示只会把后序指令的计算结果写进寄存器**，这样可以解决写后写冒险；
- 如果执行单元中有指令正在执行，其他指令就在保留站中等待；**如果指令缺少源数据，就留在保留站中，时刻监听CDB总线**，如果CDB总线广播了需要的数据，就立马拷贝下来，然后准备执行。
- 一条指令在源数据全部准备好之后就可以执行，执行可能是多周期的。
- 一条指令只要完成计算，就可以写回，**写回的数据通过CDB总线直通寄存器堆和各个保留站**。**但是要注意的一点是指令的结果未必会写进寄存器堆**，因为寄存器结果状态表中总是存有最新的状态，即如果发生写后写冒险，Tomasulo算法会记录下最新的写指令，而抛弃前序的写指令结果，前序写指令的结果不会写回到寄存器堆，这样的做法很符合数据流思维。



缺点：

1. 执行单元只能一次执行一条指令，但可能有多个指令准备好
2. 一个周期只能有一条写回指令
3. 目前只保证了单发射的，但是高性能的现代处理器是多发射，为此需要增加寄存器堆的读写口，**还要增加额外的控制逻辑使得多条指令变得有序**，让它们就像单发射一样按照顺序更新保留站和寄存器结果状态表。
4. **Tomasulo算法没办法实现精确中断，**要支持精确中断，就要确保指令按序提交

### 超处理器:star:

<img src="https://img2020.cnblogs.com/blog/2190912/202010/2190912-20201030112944650-45555698.png" alt="img" style="zoom: 67%;" />

#### 超标量处理机

- **指令发射**：超标量处理器能够在一个时钟周期内从指令队列中取出并发射（发起执行）多条指令。
- **指令流水线**：超标量处理器广泛使用流水线（Pipelining），这是一种将指令处理过程分为多个阶段的技术。每个阶段完成指令执行的一小部分，从而允许同时处理多条指令。
- **多个执行单元**：具备多个独立的执行单元，使得多条指令可以并行执行。
- **乱序执行（Out-of-Order Execution）**：许多超标量处理器能够乱序执行指令，即按照可以最有效地利用CPU资源的顺序执行指令，而不是按照指令在程序中的顺序。
- **指令重排序（Re-order Buffer, ROB）**：为了提高执行效率，处理器会对指令进行乱序执行，但为保证指令的逻辑顺序，最终结果的提交是按照指令原有顺序（即程序顺序）进行的。

#### 超流水线处理机

- 指令执行时序
- 典型处理机结构
- 超流水线处理机性能

两种定义：

- 一个周期内能够分时发射多条指令的处理机称为超流水线处理机。
- 指令流水线有8个或更多功能段的流水线处理机称为超流水线处理机。

提高处理机性能的不同方法：

- 超标量处理机是通过增加硬件资源为代价来换取处理机性能的。
- 超流水线处理机则通过各硬件部件充分重叠工作来提高处理机性能。

两种不同并行性：

- 超标量处理机采用的是空间并行性
- 超流水线处理机采用的是时间并行性



指令执行时序

- 每隔1/n个时钟周期发射一条指令，流水线周期为1/n个时钟周期
- 在超标量处理机中，流水线的有些功能段还可以进一步细分

例如：ID功能段可以再细分为译码、读第一操作数和读第二操作数三个流水段。也有些功能段不能再细分，如WR功能段一般不再细分。因此有超流水线的另外一种定义：有8个或8个以上流水段的处理机称为超流水线处理机



每个时钟周期分时发送3条指令的超流水线

<img src="assets/image-20231226123705923.png" alt="image-20231226123705923" style="zoom: 33%;" />

##### 性能分析

指令级并行度为(1,n)的超流水线处理机，执行N条指令所的时间为：$T\left(1,n\right)=(k+\frac{N-1}n)\Delta t$

超流水线处理机相对于单流水线普通标量处理机的加速比为：
$$
S\left(1,n\right)=\frac{T\left(1,1\right)}{T\left(1,n\right)}=\frac{(k+N-1)\Delta t}{(k+\frac{N-1}n)\Delta t}=\frac{n(k+N-1)}{nk+N-1}
$$


#### 超标量超流水线处理机

把超标量与超流水线技术结合在一起，就成为超标量超流水线处理机

超标量超流水线处理机在一个时钟周期内分时发射指令n次，每次同时发射指令m条，每个时钟周期总共发射指令m × n条。

<img src="assets/image-20231227104726196.png" alt="image-20231227104726196" style="zoom: 33%;" />

##### 性能分析

指令级并行度为(m,n)的超标量超流水线处理机，连续执行N条指令所需要的时间为：$T(m,n)=(k+\frac{N-m}{m\cdot n})\Delta t$

超标量超流水线处理机相对于单流水线标量处理机的加速比为：
$$
\begin{aligned}
&\begin{aligned}S(m,n)=\frac{S(1,1)}{S(m,n)}=\frac{(k+N-1)\Delta t}{(k+\frac{N-m}{mn})\Delta t }\end{aligned} \\
&S(m,n)=\frac{m\cdot n\cdot(k+N-1)}{m\cdot n\cdot k+N-m}
\end{aligned}
$$
、

## 第九章 向量处理机

- 向量处理机是解决数值计算问题的一种高性能计算机结构
- 向量处理机一般都采用流水线结构，有多条流水线并行工作
- 向量处理机通常属大型或巨型机，也可以用微机加一台向量协处理器组成
- 一般向量计算机中包括有一台高性能标量处理机
- 必须把要解决的问题转化为向量运算，向量处理机才能充分发挥作用

向量处理机

提高流水性能方法：

- 增加流水线段数，以减少Δt；
- 每个时钟同时启动多条指令；
- 减少相关，减少功能变换次数，增加处理指令条数。

向量操作特点：

- 1.向量元素间操作相互独立，且为相同操作。

- 2.相当于标量循环，对指令带宽的访问要求不高。

- 3.可采用多体交叉存储器，减少访存延迟。

  向量操作很适合于流水处理或并行处理。



### 向量的基本概念

#### 向量处理方式:star:

根据向量运算的特点和向量处理机的类型选择向量的处理方式。

**有三种处理方式：**

1. **横向处理方式**，又称为水平处理方式，横向加工方式等。向量计算是按行的方式从左至右横向地进行。
   - 不适合向量机

2. **纵向处理方式**，又称为垂直处理方式，纵向加工方式等。向量计算是按列的方式自上而下纵向地进行。

3. **纵横处理方式**，又称为分组处理方式，纵横向加工方式等。横向处理和纵向处理相结合的方式。
   - 将长度为n的向量分成若干组，每组长度为m，组内按纵向方式处理，依次处理各组。

### 向量处理机结构

向量处理机在系统结构方面所采用的主要技术都是设法维持连续的数据流，调整操作的

存储器-存储器结构



寄存器-寄存器结构

<img src="assets/image-20231229142510525.png" alt="image-20231229142510525" style="zoom: 33%;" />



## 第十章 互联网络

由开关元件按照一定的拓扑结构和控制方式构成的网络，用于实现计算机系统内部多个处理机或多个功能部件之间的相互连接

**三要素**

- 开关元件：网络中最基本模块，在不同系统和控制中，开关元件所处的物理位置和工作状态不同。
- 互连结构：网络合理布局关键，反映系统结构特征。用有向图或无向图表示，节点对应开关元件或处理机，边对应通信链路。
- 控制方式：网络中各种开关的控制方法。



**基本特征**

拓扑结构

静态网：各节点间有专用通信线路（链路），运行间不改变或重新组合，又称直接网络（节点通过链路直接连接）

组成：由链路、结构及网络节点组成。

结构：线性、环形、树形、立方体等。

动态网：各节点间有专用通信线路（链路），可通过网络中开关重新组合。节点与节点的连接由程序或控制信号动态地改变，又称间接网络（节点与交换开关连接）。

组成：由链路、结构、开关及节点组成。
结构：总线、环状、开关、（单）多级。

- 控制策略

  - 集中控制：全局控制器接收所有通信请求，设置互连网络的开关连接。
  - 分散控制：通信请求和开关设置由互连网络分散地进行。

- 定时方式

  - 同步系统：系统使用一个集中的统一时钟。

- 异步系统：无统一时钟，节点根据各自情况独立工作。


- 交换方法

  - 线路交换：源结点和目的结点间的物理通路在整个数据传送期间一直保持连接。

- 分组交换：信息分割成组，各组通过多个不同路径传分别送入互连网络，传送不存在一个实际连接的固定通路。


### 互联函数

#### 表示方法

1. 函数表示法：变量 x 表示输入，函数 f(x) 表示输出，建立输入与输出端的一一对应关系。
   自变量和函数常用二进制、十进制表示。互连函数反映网络输入数组和输出数组之间对应的排列关系，也称排列函数。

2. 输入输出对应表示法：

   <img src="https://img-blog.csdnimg.cn/img_convert/63bc93fe10f3114899d1a64bf686286d.png" alt="image-20210617152912706" style="zoom:53%;" />

3. **图形表示法**：用图形表示输入端与输出端之间的一一对应关系

4. 循环表示法：如 (0 4)(1 5)(2 6)(3 7)



#### 恒等函数

恒等函数：实现同号输入端和输出端之间的连接

#### 交换函数

交换函数：实现二进制地址编码中第 k 位互反的输入端与输出端之间的连接。

进制地址编码下，某一位的输入与输出端编号相反：

- 主要用于构造立方体和各种超立方体互连网络。
- 它共有 n = log2N 种互连函数。（N 为结点个数）
- 当 N = 8 时，n = 3，可得到常用的立方体互连函数：

<img src="https://img-blog.csdnimg.cn/img_convert/12bb6f5c1076fca4a3ed1d01a60b5801.png" alt="image-20210617182530859" style="zoom: 33%;" />

#### 均匀洗牌函数

均匀洗牌函数：将输入端分成数目相等的两半，前一半和后一半按序一个隔一个，从头依次与输出端相连，类似洗牌方式，也称为混洗函数（置换）

循环左移！！！

#### 蝶式函数

蝶式互连函数：把输入端的二进制编号的最高位与最低位互换位置，便得到了输出端的编号。

#### PM2I函数

P 和 M 分别表示加和减，2I 表示 2i。
该函数又称为 “加减2i ” 函数。
PM2I 函数：一种移数函数，将各输入端都错开 2i 个位置（模 N）后连到输出端。



### 基本的多级互连网络

#### 基本概念

互连网络：一种由开关元件按照一定的拓扑结构和控制方式构成的网络，用来实现计算机系统中结点之间的相互连接。在拓扑上，互连网络是输入结点到输出结点之间的一组互连或映象。

互连函数：用变量x表示输入，用函数f(x)表示输出。则f(x)表示：在互连函数f的作用下，输入端x连接到输出端f(x)。它反映了网络输入端数组和输出端数组之间对应的置换关系或排列关系，所以互连函数有时也称为置换函数或排列函数。

网络直径：指互连网络中任意两个结点之间距离的最大值。

结点度：指互连网络中结点所连接的边数（通道数）。

等分带宽：把由N个结点构成的网络切成结点数相同（N/2）的两半，在各种切法中，沿切口边数的最小值。

对称网络：从任意结点来看，网络的结构都是相同的。

多级互连网络采用多个相同的或不同的单级互连网络直接连接起来，实现任意节点间的直接互连。

- 交换开关
- 交换开关之间的拓扑连接
- 对交换开关的不同控制方式

##### 交换开关

交换开关是具有两个入端和两个出端的交换单元,用作各种多级互连网络的基本构件。无论入端或出端,如果令居于上方的都用i表示,居于下方的都用j表示，则可以定义下列4种开关状态或连接方式：

1. 直连，即i入连i出,j入连j出；
2. 交换，即i入连j出,j入连i出；
3. 上播，即i入连i出和j出,j入悬空；
4. 下播，即j入连i出和j出,i入悬空。

<img src="https://img-blog.csdnimg.cn/20200422134242642.png" alt="在这里插入图片描述" style="zoom:70%;" />

##### 控制方式

1. 级控制：同级交换开关使用同一个控制信号控制。
2. 单元级控制：每个交换开关分别控制。
3. 部分级控制：第i级使用第i+1个控制信号控制。
