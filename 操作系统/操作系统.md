# 操作系统原理

**学习顺序：**

1. 学习原理：看书

> - 《操作系统导论》
>
>
> - 《现代操作系统》
>
>
> - 书名（英文）：Operating Systems : Design and Implementation (3rd Edition)
>   - 书名（中文）：操作系统：设计及实现 (第三版)
>   - 原作者：Andrew S. Tanenbaum / Albert S. Woodhull
>   - 翻译者：王鹏、尤晋元、朱鹏、敖青云
>
> - Operating System (操作系统)
>   - 书名（英文）：Operating System Concepts (7th Edition)
>   - 书名（中文）：操作系统概念 (第七版)
>   - 原作者：Abraham Silberschatz / Peter Baer Galvin / Greg Gagne

2. MIT的实验

MIT6.828： [Operating System Engineering](https://link.zhihu.com/?target=https%3A//pdos.csail.mit.edu/6.828/2020/index.html)

官网主页：`https://pdos.csail.mit.edu/6.828/2020/index.html`



## 绪论

*操作系统* 是控制和管理计算机硬件与软件资源，提供一个有效、合理地组织、控制和监视硬件资源，以及为运行应用软件提供支持的环境的程序集合。

### 操作系统的目标和作用:star:

#### 操作系统的目标

1. 方便性：可使计算机系统更容易使用
2. 有效性：提高系统资源利用率
3. 可扩展性：更方便添加新的功能
4. 开放性：便于在不同设备上使用

#### 操作系统的作用/目的

1. 作为用户和计算机硬件之间的接口
   - 给用户的：
     - 命令行接口：用户使用命令接口来与计算机进行交互
     - 图像界面接口：图形界面
   - 给程序的
     - 系统调用
2. 作为计算机系统资源的管理者
   1. 计算机系统资源可归结为四类：处理机、存储、设备、文件
   2. OS的主要功能也正是针对这四类资源进行有效管理
3. 实现了对计算机资源的抽象，向上层提供方便易用的服务
4. 实现对硬件的扩展



### OS的发展顺序和分类

- **无OS**：人工操作
- **单道批处理系统**：引入**脱机输入/输出系统（外围机+磁带）**，将程序预先存入磁带，由监督程序负责控制作业的输入输出
  - 主要特征：自动性、顺序性、单道性
  - 优点：缓解一定人机速度矛盾，资源利用率有所提高
  - 缺点：内存中有且仅有一道程序，资源利用率低，CPU空闲等待I/O完成

- **多道批处理系统**：将程序先存入外存，使并发和共享变成可能
  - 缺点：没有人机交互
- **分时操作系统**：一台主机上连接多个带有显示器和键盘的终端，同时允许多个用户通过自己的终端，以交互方式使用计算机，共享主机中的资源。计算机以时间片为单位轮流为各个用户/作业服务

  - 及时接收:  分时多路复用
  
  
    - 及时处理：驻留内存 
  
  
    - 多路性 独立性 交互性 及时性


- **实时操作系统**：在实时操作系统的控制下，及时处理**外部事件响应**，在规定时间完成任务，并控制所有实时任务协调一致地运行，对**截止时间**要求
  - 主要特点：可靠性 及时性
  - 硬实时操作系统：必须在绝对严格的规定时间内完成处理
  - 软实时操作系统：能偶尔违反时间规定


- 微机系统：

  - 单用户单任务操作系统

  - 单用户多任务操作系统


  - 多用户多任务操作系统
    - 允许多个用户通过各自的终端使用同一台机器，共享主机系统的各种资源，而每个用户程序又可以进一步分为几个任务，使它们能够并发地执行，从而进一步提高资源利用率和系统吞吐量。


- **多处理机系统：**

  1. **非对称多处理模式：主-从模式（ Master-Slave node）**

     - 把处理机分为主处理机和从处理机，主处理机只有一个，其上配置了操作系统，用于管理整个系统的资源，并负责为从处理机分配任务。
     - 从处理机可以有多个，他们执行预先规定的任务以及由主处理机所分配的任务。

  2. **对称多处理模式（Symmetric Multiprocessor Model)**

     - 所有的处理机都是相同的，在每个处理机上运行一个相同的OS拷贝，用它来管理本地资源和控制进程的运行，以及各个计算机之间的通信。

     - 允许多个进程同时运行，然而必需小心地控制I/O，以保证能将数据送至适当的处理机。同时还需考虑各CPU的负载均衡。

- 微内核
  - 足够小
- 基于客户/服务器模式
  - 机制与策略分离
- 面向对象技术



### OS的特征:star:

**`并发`和`共享`是操作系统的两个最基本的特征，它们是互为存在条件的。**

1. 并发：在多道程序环境下，并发性指的是在一段时间内，宏观上有多个程序同时运行，在微观上是交替发生的。

   > 并发：在同一时间间隔内发生
   >
   > 并行：在同一时刻发生
   >
   > 注意单核CPU和多核CPU
   
2. 共享：系统中的资源可供内存中多个并发执行的进程共同使用。
   - 互斥资源共享
   - 同时资源共享


3. 虚拟：是指通过某种技术把一个物理实体变为若干个逻辑上的对应物。 

   - 空分复用技术
   - 时分复用技术

3. 异步：在多道程序环境下，多个进程并发执行，进程进行的顺序是未知的



### 中断和异常

- 程序分为**内核程序**和**用户程序**
  - `内核程序负责管理和分配系统资源，为用户提供服务。`
  - `用户程序运行时，所需资源必须向操作系统提出请求，自己不能随意取用资源。`
- 特权指令：系统态运行时的指令
- 非特权指令：用户态时运行的指令
- 根据对资源和机器指令的使用权限，将处理机执行时的工作状态分为**核心态（管态，内核态，kernel mode）和用户态（目态，user mode）**。
  - 处于内核态时，内核程序，内核态允许执行特权指令
  - 处于用户态时，应用程序，用户态只能允许非特权指令
- 拓展：CPU上有一个寄存器叫“程序状态字寄存器（PSW）”，01分别表示不同状态

#### 内核态和用户态的切换

内核态->用户态：执行一条特权指令——修改PSW标志位，操作系统让出处理机控制权

用户态->内核态：由“中断”引发，硬件自动完成变态过程

#### 中断调用的类型

中断：CPU对系统发生某事件时的一种响应，CPU暂停正在执行的程序，在保留现场后自动地转去执行该事件的中断处理程序；执行完后，再返回到原程序的断点处继续执行。

- 外中断：由外部设备事件引起的中断，中断信号来自CPU外部
  - 时钟中断
  - I/O中断
- 内中断：由CPU内部事件引起的中断，由现行指令引起
  - 陷阱、陷入：由陷入指令引起，由程序故意引发的
  - 故障：由错误条件引起的，可能被内核程序修复。修复后会把CPU使用权继续交还给应用程序
  - 终止：由致命错误引起的，内核程序无法修复该错误，一般CPU直接终止程序（除0）

#### 中断调用原理

检查中断信号：

- 内中断：CPU在执行指令时候会检查是否有异常发生
- 外中断：每个指令周期末尾，CPU都会检查是否有外中断信号需要处理

不同的中断信号，需要调用不同的中断处理程序来处理，通过“中断向量表”查找对应中断程序



### 系统调用

系统调用是操作系统提高给应用程序使用的接口，可以理解为一种可供应用程序调用的特殊函数，应用程序可以通过系统调用来请求获得操作系统内核的服务。

> 系统调用实质上是应用程序请求操作系统内核完成某一功能的一种特殊的过程调用

#### 系统调用的类型

<img src="assets/image-20240215163227636.png" alt="image-20240215163227636" style="zoom:50%;" />


#### 系统调用的实现

实现过程：系统调用→指令中断（陷入指令，用户态发出的）→信号送入中断和陷入硬件机构→启动中断和陷入处理程序



### 操作系统体系结构

内核是操作系统最核心、最基本的部分

<img src="assets/image-20240215195531352.png" alt="image-20240215195531352" style="zoom:57%;" />



### 操作系统启动过程

1. **按下电源按钮**
2. **电源自检 (POST)**:
   - 电源供应器通过检查各个硬件部件（如CPU、内存、显卡等）是否正常工作。如果POST检测到问题，会通过蜂鸣声或错误代码来提示。
3. **加载BIOS/UEFI**:
   - BIOS（基本输入输出系统）或UEFI（统一可扩展固件接口）固件开始运行。这段代码存储在主板上的ROM芯片中。
   - BIOS/UEFI负责初始化硬件，设置基本的系统配置，并寻找启动设备（如硬盘、SSD、光盘等）。
4. **查找和加载引导加载程序**:
   - BIOS/UEFI查找并加载存储设备上的引导加载程序（如GRUB、Windows Boot Manager等）。
   - 引导加载程序的主要任务是将操作系统内核加载到内存中。
5. **加载操作系统内核**:
   - 引导加载程序将操作系统的内核加载到内存，并将控制权交给操作系统。
   - 内核初始化硬件抽象层，配置内存管理，并开始加载系统进程和驱动程序。
6. **启动系统服务和后台进程**:
   - 操作系统开始加载各种系统服务和后台进程，这些进程负责管理网络连接、用户登录、图形界面等。
7. **加载用户界面**:
   - 最终，操作系统加载图形用户界面（GUI），如Windows的桌面环境或Linux的图形界面。
   - 显示登录界面，用户可以输入用户名和密码登录系统。



### 虚拟机

虚拟化技术：虚拟机管理程序

![image-20240215213139490](assets/image-20240215213139490.png)



## 进程管理

### 进程基本概念

**进程**是具有独立功能的程序在一个数据段上的运行过程，是系统进行资源分配和调度的一个独立单位，是系统进行资源分配的基本单位。

- **顺序执行的特征**
  1. 顺序性：严格按照程序规定的顺序执行
  2. 程序是在封闭的环境下执行的
     - 独占资源
     - 内部不受外部影响
  3. 可再现性：只要程序的初始条件和环境相同，程序的执行结果就相同。

- **并发执行的特征**
  1. 间歇性：共享系统资源，并发程序间互相制约
  2. 失去封闭性
  3. 不可再现性

#### 进程的数据结构

> 内部数据结构：内存表，设备表，文件表，进程表（程序控制块PCB）

**进程控制块PCB：**

- 进程描述信息	
  - 进程标识符PID
  - 用户标识符UID
- 进程控制和调度信息（内存中地址，进程同步和通信信息）
- 资源分配清单
  - 正在使用哪些文件
  - 正在使用哪些内存区域
  - 正在使用哪些I/O设备
- 处理机状态信息：如PSW、PC等各种寄存器的值

**为什么说PCB是进程存在的唯一标志?**

> 因为PCB包含了进程的描述信息和控制信息，是进程的动态特征的集中反映，系统在建立进程的同时就建立该进程的PCB，在撤消一个进程时也就撤消其PCB，系统根据PCB而感知某一进程的存在，所以PCB是进程存在的唯一标志。
>



#### PCB的组织方式

1. 链接方式：把相同状态的PCB链接成一个队列
2. 索引方式：根据所有进程的状态建立索引表



#### 进程的特征

- 进程实体的静态描述
  - PCB：常驻在内存之中，一个程序开始前就要创建
  - 程序段：程序的代码
  - 数据段：程序允许的过程中产生的数据

- 动态性：它由创建而产生，由调度（这里主要指**进程调度**，而不是作业调度）而执行，由撤销而消亡。
- 并发性：指多个进程实体存于内存中，且能在同一时间段内执行，（这里同操作系统的并发性）。
- 独立性：进程实体是一个能独立运行，独立获得资源和独立接收调度的基本单位。
- 制约性：进程间对于资源的争用而相互制约。
- 异步性：各进程按各自独立的、不可预知的速度向前推进。
- 结构性：进程包含了数据集合和其上运行的程序。为了描述和记录进程的动态变化过程，还需要配置一个进程控制块，所以每个进程由三要素组成：程序、数据和进程控制块。



#### 进程与程序 :star:

- 进程是一个动态的概念，是程序的一次执行，程序是静态的概念。
- 进程可以具有并发性，在系统中作为资源分配的基本单位，但是程序不能独立运行。

- 一个程序对应多个进程，一个进程又可以为多个程序服务。



### 进程控制

#### 进程的状态:star:

- 创建状态：PCB已填写标识符，但是其他资源未分配，进程自身没有进入主存，无法调用
- 就绪状态：已经具备运行条件，CPU忙碌无法进行服务
- 阻塞状态/等待状态：因为等待某个事件而被阻塞了
- 执行状态/运行状态
- 终止状态
- 挂起/解挂状态（不一定要考虑这个）

进程不能从阻塞态直接转换为运行态！！！！！



#### 进程的挂起和解挂

挂起状态：暂时调到外存等待的进程状态为挂起状态

进一步被细分为：**就绪挂起**、**阻塞挂起**

- 被挂起原因：用户，操作系统，父进程，系统负载过重等

- 挂起过程

  - 首先判断进程状态，若该进程正处于活动就绪状态，将其改为静止就绪态；
  
  - 若该进程处于活动阻塞状态，将该进程改为静止阻塞状态；
  
  - 若该进程处于执行状态，将其改为静止就绪状态，调度程序重新进行调度。



#### 进程控制原语

**原语的执行具有“原子性”，一气呵成，通常把进程控制用程序段做成原语**

**如何实现原子性：**使用两个特权指令，“关中断指令”和“开中断指令”

创建原语 `create`：

1. 申请空白PCB
2. 为新进程分配资源
3. 编写PCB
4. 将PCB插入就绪队列

终止原语 `kill`: 

1. 从PCB集合中找到终止进程的PCB
2. 若进程正在运行，立即剥夺CPU，将CPU分给其他进程
3. 终止其所有子进程
4. 将该进程拥有的资源归还父进程或者操作系统
5. 删除PCB



### 进程的互斥和同步

#### 同步、互斥与临界资源

**目的：**

1. 进程按照一定规则使用系统资源
2. 对多个相关进程在执行次序上进行协调，是程序具有可再现性。

进程同步：各自的执行结果为对方进程的执行条件，称为**直接制约**，这组进程被称为**合作进程**



**制约关系：**

1. 间接制约(互斥)关系：由于**共享系统的临界资源**而相互制约（EX：打印机）
2. 直接制约关系：同步制约关系



**临界资源：**一段时间内只允许一个进程访问的资源

**临界区：**访问临界资源的那段程序

> 进程互斥：**不允许**两个以上的共享该临界资源的并发进程同时进入临界区
>



##### 临界资源互斥执行的原则

1. 空闲让进
2. 忙则等待
3. 让权等待：进程不能进入临界区，就应当释放CPU资源，让权指让出CPU
4. 有限等待：对请求访问的进程，应该保证在有限时间可以访问



#### 进程互斥的软硬件方法

##### 软件方法

整体思路：通过记号标记是否有标志在检查区中，**入区通过循环检查进行等待，进程离开临界区后则在退出区修改标志。**

###### 单标志法

- 算法思想：两个进程在访问完临界区后把使用临界区的权限交给另一个进程，也就是说每个进程的权限只能由另一个进程给予
- 可以实现**互斥访问**
- 不满足“空闲让进”



###### 双标志先检查法

- 每个进程有两个标志，一个是表达自己是否有意愿进入临界区，一个表达是否已经进入临界区
- 主要问题：请求和上锁的操作不是原子的，如果运行顺序改变可能会导致结果变化
- 违背了“空闲让进”和“有限等待”



###### `peterson`算法

不满足让权等待



##### 硬件方法

###### 中断隐藏方法：

1. 使用原子的指令“开\关中断”
2. 简单高效
3. 只适用于单处理机，关中断指令只对使用的处理机有效



###### `Test-and-Set`指令

- 将**检查和上锁**变成一步的原子操作
- 适合多处理器
- **缺点：**不满足让权等待



#### 信号量机制

信号量：仅由互斥控制原语对其进行操作的变量（可以是整数，也可以是更复杂的记录xin）

**互斥控制原语：**

​			  `P/wait操作；`
​            `V/signal操作；`

- 信号量机制：
  - 信号量说明：`var s:semaphore;`
  - wait操作即是申请资源，signal操作是释放资源
  - 原子操作不能被打断
- 整形信号量：
  - 把整型信号量定义为一个用于表示资源数目的整型量S
  - 依然没有实现**让权等待**
- 记录形信号量
  - 为了实现让权等待

  - 将请求资源的进程加入等待队列，之后阻塞

- 信号量集机制

```
semaphore mutex = 1; //初始化记录型信号量
```



#### 经典进程的同步与互斥问题

##### 生产者消费者问题

- 生产者向缓冲区输入


- 缓冲区输出到消费者


缓冲区有容量限制

1. 一个生产者，一个消费者，一个缓冲区
2. 一个生产者，一个消费者，n个缓冲区
3. n个生产者，n个消费者，n个缓冲区



设置信号量：

```
semaphore mutex = 1;			// 缓冲区使用权
semaphore empty = n;			// 缓冲区空闲区域数
semaphore full = 0;				// 缓冲区被填充区域数
```



##### 哲学家就餐问题

描述：五个哲学家五双筷子，只有拿起左右两支筷子才能就餐，哲学家交替思考和就餐

常见解决算法：

1. 同一时间只允许一个哲学家就餐
2. 仅当哲学家左右均可用的时候，才允许就餐
3. 四个哲学家只允许先拿左手的筷子，最后一个哲学家只允许先拿右手的
4. 奇数哲学家先拿左边筷子，偶数哲学家先拿右边筷子



##### 读者——写者问题

1. 允许多读者读
2. 不允许边读边写
3. 不允许两写者一起写



##### 进程控制伪代码

```
semaphore Wmutex; //声明型号量
parbegin
process Reader{  //进程声明
	wait(Wmutex);
	read();
	signal(Wmutex);
}
parend  //声明代码结束
```

> PS：
>
> 1. 共享变量都需要信号量控制
> 2. 通信需要信号量控制



### 管程

把分散在各进程中的临界区集中起来进行管理，并把系统中的共享资源用数据结构抽象地表示出来。

**组成：**

1. 局部于管程的**共享数据结构说明**；
2. 对该数据结构进行操作的**一组过程**；
3. 对局部于管程的数据设置初值的语句。
3. 管程有一个名字

```python
type PH=monitor
   	var chop:array[0..4] of integer; 
   	cc: array[0..4] of condition;
   	procedure entry get(integer i)  #第i号哲学家取筷子过程
    	begin
    	         j:=(i+1) mod 5;
      	L1: if chop[i]=0 or chop[j]=0 then
	 		begin
				if chop[i]=0 then cc[i].wait;
				else cc[j].wait;
				goto L1;  #被唤醒后必须回到if语句开头
			end
		chop[i]:=0;	   #拿起左边的筷子
		chop[j]:=0; 	   #拿起右边的筷子
		end
```



### 进程间通信 :star:

进程间通信（IPC）	：两个进程之间产生的数据交互

#### 共享内存

1. 先向系统申请共享存储区中的一个分区，并指定该分区的关键字；
1. 若系统已经将该分区分配给其它进程，则将其描述符返回给申请者； 
1. 申请者将获得的共享存储分区连接到本进程上； 
1. 此后，便可象读写普通存储器那样地读写该公用存储分区。——UNIX/LINUX与之有关的系统调用有4个

```c++
int shm_open();		//系统调用，申请共享内存区
void * mmap();		//将共享内存区映射到自己的地址空间
```



#### 管道通信 

用于连接一个读进程和一个写进程以实现它们之间通信的一个共享文件

1. 只能采用半双工通信，同一时间段内只能进行单向的传输
2. 互斥：各进程互斥访问管道（操作系统实现）
3. 同步：互相唤醒，完成后睡眠
4. 在管道内的数据是**先进先出**的，这里与共享存储不同
5. 在管道满和空时，写进程和读进程分别被堵塞



#### 消息队列通信

进程间的数据交换**以格式化的消息**为单位。进程通过操作系统提供的“发送消息/接收消息”两个原语进行数据交互。

- 直接通信方式：点名道姓，指出发送和接收的进程ID
- 间接通信方式：存在一个信箱，不指出具体的进程



#### 其他一些方式

- 信号
- 文件
- 信号量

### 线程

> 引入线程后，线程是调度和分配处理机的基本单位；进程只是资源分配的基本单位

线程优点：

1. 响应速度快
2. 进程内资源共享，切换线程减少系统开销
3. 一个线程阻塞不会妨碍其他线程

#### 线程的属性

- 一个进程可以创建多个线程
- 多核计算机中，各个线程可以占用不同的CPU
- 每个线程都有一个线程ID、线程控制块（TCB）
- 线程也拥有许多的状态，也是一个动态的概念（执行 就绪 阻塞）
- 线程几乎不拥有系统资源
- 同一进程内线程共享资源；同一进程内线程通信甚至无需系统干预
- 同一进程内线程切换，系统开销小



TCB（线程控制块）：

- 线程标识符
- 程序计数器PC
- 其他寄存器
- 堆栈指针
- 线程运行状态
- 优先级



#### 线程的分类

##### 用户级线程（User-level Thread, ULT）

1. 用户级线程的管理由应用程序来完成。
2. 该线程切换不需要CPU改变状态。
3. 用户级线程对于操作系统来说是透明的，操作系统并不知道用户态下进程有多少线程，而只会认为线程等同于进程。
4. 优点：开销小、效率高。
5. 缺点：当一个用户级线程被阻塞的时候，整个进程都会被阻塞，并发度不高。



##### 内核级线程（Kernel-level Thread, KLT）

1. 内核级线程的管理需要由操作系统完成
2. 切换需要CPU改变状态
3. 内核级线程可以让内核知道线程的存在，这样就可以做到一个线程阻塞时调用进程中另一个线程
4. 优点：当一个线程被阻塞，同一个进程内的线程依然可以继续执行，并发能力强。多线程可以在多核处理机上并行执行
5. 缺点：内核的空间有限，每次线程切换需要调入内核态



##### 组合级线程

1. 多对一模型：多个用户级线程映射到一个内核级线程，且一个进程只被分配一个内核级线程
2. 一对一模型：一对一模型将每个用户级线程映射到一个内核级线程。
3. 多对多模型：内核线程的数量可能与特定应用程序或特定机器有关。 



## 处理调度与死锁

### 处理机调度的分级模型

多道批处理系统中：作业调度和进程调度

分时系统和实时系统中：进程调度、交换调度和线程调度。 

#### 高级调度（作业调度）

按一定的原则从外存的后备作业队列中挑选一个作业调入内存，并创建进程。每个作业只调入一次，调出一次。

作业：可以理解为用户向计算机提交的任务实体，一个作业由一个或多个进程组成。

作业控制实体（JCB）

作业分为经历**提交、收容、执行和完成**等4个状态

<img src="pics/image-20230404084438396.png" alt="image-20230404084438396" style="zoom:80%;" />

完成状态：此时作业运行完成，但是他占用的资源还未被回收

#### 低级调度

进程调度：从就绪队列中选择合适的进程为其分配处理机

#### 中级调度

内存调度：外存和内存中作业交换的调度

#### 调度目标

- 资源利用率：系统中的处理机和其他所有资源都尽可能的保持忙碌状态

- 公平性：各个进程都获得合理的CPU时间，避免进程“饿死”

- 平衡性：系统使用尽量平衡，避免一个资源（如CPU）忙个不停，一个资源（如 I/O）无所事事

- 策略强制执行：特殊情况的强制策略（安全策略）




### 进程调度

#### 进程调度的时机

- 主动放弃
  - 进程正常终止
  - 运行时异常终止
  - 主动阻塞
- 被动放弃
  - 分给进程的时间片用完
  - 更高优先级的进程需要先执行

#### 进程调度的方式

- 非剥夺调度方式（非抢占式）
- 剥夺调度方式（抢占式）



### 进程调度的性能指标

CPU利用率：CPU忙碌的时间占总时间的比例

系统吞吐率：单位时间内完成作业的数量

周转时间：作业被提交给系统开始，到作业完成为止的这段时间，$$T_i=T_{ei}-T_{si}$$

带权周转时间：作业周转时间与该作业执行时间之比



### 调度算法:star:

#### 先来先服务调度算法（FCFS）

- 按照作业/进程达到的顺序先后进行服务
- 一般是非抢占式的
- 对长作业有利，对短作业不利



#### 短作业(进程)优先调度算法(SJF\SPF)

- 思路：追求最少的平均等待时间、平均周转时间、平均带权周转时间
- 一般是非抢占式
- 对于长进程有可能会出现饥饿 



#### 高优先权优先调度算法 

- 作业调度——选择优先权最高的作业，将其调入内存运行

- 进程调度——将处理机分配给就绪队列中优先权最高的进程

- 设置为抢占式和非抢占式均可以




#### 高响应比优先调度算法（HRRN, Highest Response Ratio Next）

- 综合考虑作业/进程的等待时间和要求服务时间
- 响应比 =（已等待时间+要求服务时间）/ 要求服务时间
- 每次调度的时候选择响应比最大的作业/进程

- 即考虑了公平性，又考虑了平均周转时间
- 非抢占式

- 缺点：计算响应比会增加系统开销




#### 基于时间片的轮转调度算法 （RP）

- 公平地、轮流地为各个进程服务
- 把CPU的运行时间分成许多时间片，每次运行就绪队列队首的任务，运行完一个时间片后则将任务放到队尾
- 时间片切换会造成性能损失
- 抢占式



#### 多级反馈队列调度算法

- 优先度逐级降低，时间片逐级增加
- 算法规则：
  - 设置多级就绪队列，各级队列优先级从高到低，时间片从小到大
  - 先进入第一级，跑完时间片后未完成则退到第二集
  - 只有k级队列为空时，才会为k+1级队列的队头分配时间片



### 实时调度:star:

前面的多种调度并不能满足实时系统对调度的要求

硬实时调度算法：必须严格规定时间内完成

软实时调度算法：偶尔的超过时常是可以接受的

> 区别在于对截止时间要求！！！！！！！

实现实时调度应具备下述几个条件：

1. 提供必要的信息

   - 就绪时间
   - 开始完成截止时间
   - 处理时间
   - 资源要求
   - 优先级

2. 系统处理能力强

   满足这个公式，这个系统才是可调度的

   <img src="pics/image-20230410160639705.png" alt="" style="zoom:67%;" />

   采用单处理机系统，但需提高其处理能力

   采用多处理机系统

3. 采用抢占式调度机制

4. 具有快速切换机制

   - 对外部中断的快速响应能力
   - 快速的任务切换能力



#### 实时调度算法的分类

##### 非抢占式调度算法

算法简单，适合不复杂系统

1. 非抢占式轮转系统调度

   <img src="pics/image-20230410161600321.png" alt="image-20230410161600321" style="zoom:50%;" />

2. 非抢占式优先调度算法

   <img src="pics/image-20230410161624729.png" alt="image-20230410161624729" style="zoom:50%;" />

##### 抢占式调度算法

在要求较严格（响应时间为数十毫秒以下）的实时系统中采用

①**基于时钟中断的抢占式优先权调度算法**

- 在某实时任务到达后，如果任务的优先级高于当前任务的优先级，这时并不立即抢占当前任务的处理机，而是等到时钟中断到来时，调度程序才剥夺当前任务执行，将处理机分配给新到的高优先权任务
- 这种调度算法能获得较好的响应效果，其调度延时可降到几十毫秒到几毫秒，可用于大多数的实时系统

②**立即抢占的优先权调度算法**

- 一旦出现外部中断，只要当前任务未处于临界区，便可立即剥夺当前任务的执行，把处理机分配给请求中断的紧迫任务。
- 这种算法能获得非常快的响应，可把调度延迟时间降低到几毫秒至100微秒，甚至更低。



#### 常用的实时调度算法

##### 最早截止时间优先算法

谁的截至时间早先完成谁

##### 最低松弛度优先算法 LLF (Least Laxity First) 算法

根据任务紧急（或松弛）的程度来确定任务的优先级。任务紧急程度愈高，其优先级愈高。

EX：一个任务在200ms 之前必须完成，它本身需要运行100ms，则该任务的紧急程度（松弛程度）为100ms



### 死锁

定义：一组竞争系统资源或相互通信的进程间相互的“永久”阻塞

#### 死锁的必要条件

- 互斥条件：对分配到的资源进行排他性使用
- 请求和保持条件：进程提出了新的资源请求，但是**对自己已有资源保持不放**
- 不剥夺条件：其他进程不能剥夺未使用完的资源
- 环路等待条件：发生死锁时，存在进程-资源等待链



#### 处理死锁的方法

预防死锁：通过设置某些限制条件，破坏必要条件；可能会减弱系统速度

避免死锁：动态防止系统进入不安全状态

检测和解除死锁：及时检测死锁，常用的方法是撤消或挂起一些进程，以便回收一些资源，分配给已处于阻塞状态的进程，使之转为就绪状态，以继续运行。



#### 预防死锁

1. 破坏“互斥”条件
   - 可以允许若干个进程同时产生输出，将独占设备改造为共享使用的设备


2. 摒弃“请求并保持”条件 
   - 等待所有资源都就绪了再一次性获取


3. 摒弃“不剥夺”条件
   - 如果一个进程已经保持了某些资源，再请求得不到时，会放弃已有资源
   - 如果一个进程请求的资源被其他进程占用，强行抢占别人的资源，一般按照有限度来（复杂）

4. 摒弃“环路等待”条件 
   - 首先给系统中的资源编号，规定每个进程，必须按编号递增的顺序请求资源，同类资源一次申请完。




#### 避免死锁——银行家算法:star::star:

`安全状态`：系统存在一个进程序列 $<p_1,p_2,p_3,...,p_n>$，资源按照这个序列的顺序分配资源，可以依次满足每个进程对于资源的需求

`不安全状态`：不存在一个进程序列

**并非所有不安全状态都是死锁状态，但它迟早会进入死锁状态。**

**银行家算法:**

在资源动态分配过程中，若分配后系统状态仍是安全的，则同意分配，否则将拒绝分配，这样可防止系统进入不安全状态，从而避免死锁。 



#### 死锁检测

对系统是否已发送了死锁进行检测：

- 用某种数据结构来保存资源的请求和分配信息
- 提供一种算法，利用上述信息来检测系统是否已进入死锁状态



##### 资源分配图

- 两种节点
  - 方框代表资源，圆代表进程
- 方框指向进程，指的是资源被分配；

<img src="pics/image-20230606144817175.png" alt="image-20230606144817175" style="zoom:67%;" />



#### 死锁解除

- 剥夺资源法
  - 挂起死锁进程，把资源分配给其他死锁进程

- 撤销进程法
  - 强制撤销死锁进程
- 进程回退法
  - 让一个或者多个死锁进程回退到足以避免死锁的地步



## 存储器管理

### 层次结构

#### 主存储器与寄存器

##### 主存储器

内存或者主存，可以保存进程的程序和数据

CPU只能通过内存与外部存储交流

主存速度远低于CPU速度，所以需要在系统中引入寄存器和告诉缓存

##### 寄存器

速度快，价格昂贵，一般以字作为容量



#### 高速缓存（Cache）

容量比较小但速度比主存高得多， 接近于CPU的速度。

将主存中一些经常访问的信息存放在高速缓存中，减少访问主存的次数，可以大幅度提高程序执行的速度。

由于高速缓存的速度越快价格也越高，故有的计算机系统中设置了两级或多级高速缓存。一级高速缓存速度最高而容量最小，二级高速缓存容量稍大，速度也稍低



#### 磁盘缓存

磁盘将频繁使用的信息放在缓存中，减少开销

命中：CPU需要磁盘中信息时，在缓存中找到



#### 逻辑地址和物理地址

**目标程序**使用的地址单元称为**逻辑地址（相对地址或虚地址）**。一个用户作业的目标程序的逻辑地址集合称为该作业的**逻辑地址空间**。

主存中的实际存储单元编号称为**物理地址（绝对地址或内存地址）**。物理地址的总体构成**物理地址空间**。

**重定向：**必须把程序和数据的逻辑地址转换为物理地址。

分为**静态重定位和动态重定位。**



### 程序的装入和链接

#### 程序的装入

将程序（模块）装入内存时，需要实现从**逻辑地址到物理地址的转换**，可以有三种方式：

- 绝对装入方式
  - 编译时知道程序在内存中位置，产生绝对地址

  - 地址不需要修改

  - 适合单道程序

- 可重定位装入方式（静态重定位方式）
  - 在装入时对程序中逻辑地址的偏移值加入起始地址中

  - 在装入时一次完成

  - 只能连续装入

- 动态运行时装入方式



#### 程序的链接

源程序经编译后，可得到一组目标程序，再利用链接程序将这组目标模块链接，形成装入模块。

- 静态链接
- 装入时动态链接
- 运行时动态链接



### 存储器管理的功能

1. 内存空间的分配和回收
2. 内存的共享和保护
3. 地址映射，逻辑地址到物理地址
4. 在逻辑上实现内存扩充，虚拟存储技术
   - 覆盖技术
     - 同一个程序，需要程序员定义，对用户不透明
   - 交换技术
     - 不同程序的交换



### 连续分配管理方式

#### 单一连续分配 

内存分为**系统区**和**用户区**两部分，系统区仅提供给OS使用，通常是放在内存的低址部分；

用户区是指除系统区以外的全部内存空间，提供给用户使用。 

内存中**只能有一道用户程序**，只适用于单用户，单系统的操作系统中

优点：不会产生碎片

缺点：只能一个用户使用

#### 固定区域分配

将内存划分为若干个固定大小的区域（分区），每个分区中装入一道作业，允许几道作业并发运行。

- 分区内存相等：缺乏灵活性，适用于特殊情况（单个计算机控制多个相同对象的场合）


- 分区内存不等：普适性更强，适合多种作业环境


内存分配：

- 为了便于分配，通常将分区按大小排列，当用户程序装入时，从上到下依次搜素可用的分区




固定分区方式的**缺点**：

- 大程序可能无法装入；
- 主存空间利用率不高——作业往往不可能恰好填满分区，会产生内部碎片；
- 限制了多道运行的程序数。
- 作业动态扩充主存困难；
- 各分区作业要共享程序和数据也难实现；



#### 动态分区方式

##### 分配系统中数据结构

**空闲分区表**：

每个空闲分区占一个表目，表目包括：**分区号、分区始址、分区大小等**

| **分区号** | **分区始址** | **分区长度** |
| ---------- | ------------ | ------------ |
| **1**      | **100KB**    | **128KB**    |
| **2**      | **800KB**    | **200KB**    |
| **3**      | **1300KB**   | **700KB**    |

**空闲分区链**： 

<img src="pics/image-20230417092355661.png" alt="image-20230417092355661" style="zoom:67%;" />

##### 动态分区分配算法	

首次适应算法(First Fit)：空闲地址按地址顺序排列，每次从头搜索，直到找到一个合适大小的区域

循环首次适应算法(Next Fit)：每次从上一次的地址开始搜索

最佳适应算法(Best Fit)：按大小排序

最坏适应算法(Worst Fit)：将空闲分区按其容量从大到小顺序排列，分配时从表首开始顺序查找。



##### 动态分区的分配和回收流程

分配内存：

1. 先找到一块大小可以分配的分区大小
2. 检测剩余大小是否足够再作为一个分区
3. 够的话就分割
4. 不够就全给了



##### 基于索引搜索的动态分区分配算法 

**快速适应方法**（Quick fit）：将所有空闲分区根据容量大小分类，对于每一类具有相同容量的所有空闲分区，单独设立一个空闲分区链表。

在搜索可分配的空闲分区时分为两步：

1. 根据进程的长度，从索引表中寻找到能容纳它的最小空闲区链表；
2. 从链表中取下第一块进行分配，不进行空闲分区分割。

特点：

- 比顺序搜索查找速度快；
- 空闲分区回收存在较大系统开销，分区以进程为单位，存在一定空间浪费浪费。



**伙伴系统：**与快速适应方法不同的地方是，这个方式规定的空闲或者使用的内存块均为 $2^k$ 大小，所以在构成链表的时候更加节约空间

特点：

- 比顺序搜索查找速度快；
- 空闲分区可分割，空闲空间利用率比QF高；
- 回收时间开销比QF高。

#### 可重定位分区分配 

**动态重定位的引入** ：为了解决碎片问题

**物理地址 = 逻辑地址 + 基址寄存器中的地址值** 

当找不到满足的分区时，就进行紧凑操作



连续分配方式会形成“碎片”，“紧凑”须付出很大开销 --> 所以产生离散分配方式；

### 分页存储管理方式 :star:

#### 分页

- 将逻辑地址空间分成若干大小相等的片，称为 **页面或页(page)**。页号从0开始。


- 物理内存分成与页大小相同的若干存储块，称为 **块或页框(frame)**。页框号从0开始。

  - 页框=页帧=内存块=物理块=物理页面
  - 页框号=页帧号=内存块号=物理块号=物理页号

为进程分配内存时，以**块为单位将进程中的若干页分别装入到多个可以不相邻的物理页**中。最后一个页不满，称为页内碎片。 

**页的大小**：应是 $x^k$。通常为 512B～8KB 

**地址结构**：分页逻辑地址 = 页号P + 分页地址d

#### 页表

系统为每个进程建立一张**页表**，记录了相应页在内存中对应的物理块地址

1. 一个进程一张页表
2. 每个页面对应一个页表项
3. 每个页表项由页号+块号组成



#### 基本的地址转换机构

<img src="pics/image-20230423163942559.png" alt="image-20230423163942559" style="zoom:67%;" />

1. 从逻辑地址得到页号和页表偏移量
2. 比较页号和页表长度M，如果大于等于则越界
3. 若页号合法，则通过页表起始地址和页号找到对应页表项
4. 根据页表项找到物理地址
5. 访问对应内存单元

#### 具有快表的地址转换机构

##### 快表

块表：联想寄存器（TLB），是一种访问速度比内存快很多的高速缓存，用来存放最近访问的页表项的副本，可以加快地址变换的速度。

- 将页号送入**快速缓存**，块表没找到要去内存找，满了要淘汰


- 快表中没有找到，还需要访问内存中的页表，然后更新快表




##### 两级和多级页表



##### 反向页表

与索引的思想差不多，表项只与实际内存块大小有关



### 分段存储管理方式 :star:

- 分段将内存划分为不同大小的块，称为段（Segment），每个段代表逻辑上的一个部分，如代码段、数据段、堆栈段等。

- **逻辑地址和物理地址**：逻辑地址包括段号和段内偏移量，通过段表（Segment Table）将段号映射到物理地址。

> 共享：页只是信息存放的物理单位，没有实际意义，段是逻辑单位
>
> 保护：同样是对逻辑单位的包含，分段管理更容易实现



### 段页式存储管理方式

- 分页系统能有效地提高内存利用率；但是不按逻辑模块来实现信息的共享和保护


- 分段系统能很好地满足用户的需要；如果段长过大，难以分配很大的连续空间

段大小可以由用户决定；

段页式的地址结构是二维的

没有快表时，每访问一个内存，需要访问两次内存

#### 原理

将用户程序分成若干段，然后把段分成若干页

逻辑地址：段号，页号，页内偏移地址

段表：段号，页表长度、页表存放块号

### 虚拟存储器

> 虚拟存储器是一种存储管理技术，用以完成用小的内存实现大的虚空间中程序的运行，由操作系统决定，牺牲CPU工作时间以及内外存交换时间和外存空间

问题：内存位置不够

解决方法：逻辑上扩展内存——虚拟存储器

#### 局部性原理 

程序在执行时将呈现局部性规律，即在一较短的时间内，程序的执行仅局限于某个部分（如顺序执行，过程调用，循环，数组访问等）；相应地，它所访问的存储空间也局限于某个区域。

时间局部性——某指令一旦执行，则不久后该指令可能再次被执行（数据亦然）。循环

空间局部性——程序一旦访问了某个存储单元，不久后，附近的存储单元也将被访问。顺序执行

#### 虚拟存储器定义

**定义：**具有**请求调入**和**置换功能**，能从逻辑上扩充内存容量

**基本原理：**

- 部分装入
- 请求页面
- 页面置换

#### 虚拟存储器的特征

> - 多次性：一个作业被分成多次调入内存运行；
> - 对换性：作业在运行过程中进行换进、换出； 
> - 虚拟性：从逻辑上扩充内存，使用户看到的内存容量大于实际内存容量。这是虚拟存储器所表现的最重要的特征，也是实现虚拟存储器的最重要的目标
>



### 请求分页存储管理方式 

与基本分页存储管理的主要区别：

- 当访问的信息不在内存时，由操作系统复制将所需信息从外存调入内存
- 操作系统负责将内存中暂时不需要的信息换出到外存

#### 对换（Swapping）

内存资源有限，把内存中暂时不能运行的进程或进程所需要的程序和数据，调出到外存上，以便腾出足够的内存空间，再把已具有运行条件的进程或进程所需要的程序和数据，调入内存。

**整体对换：**以进程为单位

**部分对换：**对换以“页”“段”为单位

功能：

- 对换空间的管理
- 进程的换入
- 进程的换出

将外存分为：**文件区和对换区**

#### 硬件支持

缺页中断机构：

1. 当要访问的内存不在时，便产生一个缺页中断（内中断），然后由操作系统的缺页中断处理程序处理
2. 缺页进程阻塞，放入阻塞队列，等待调页完成
3. 装入内存 or 置换内存

#### 内存分配策略

- 最小物理块数确定：
  - 取决于指令、功能寻址方式
- 物理块的分配策略
  - 固定分区指的是分给进程的物理块数固定，可变就是不固定
  - 局部置换指的是置换私有页面，全局置换指的是只要缺页就获得新的物理块
  - 固定分区局部置换
  - 可变分区全局置换
  - 可变分区局部置换
  
- 物理块分配算法
  - 平均分配
  - 按比例分配算法
  - 考虑优先级分配算法


### 页面置换算法

#### 最佳置换算法(OPT, Optimal)

每次选择后续不再使用或者最长时间不使用的页面，实际中难以观测到序列

#### 先进先出页面置换算法(FIFO)

每次选择淘汰的页面是最早进入内存的页面

Belady异常：当为进程分配的物理块增大时，缺页次数不减反增

只有FIFO会出现以上异常

#### 最近最久未使用置换算法(LRU, least recently used)

实现方法：使用栈或者移位寄存器，记录上一次被访问后经历的时间

#### 最近最少使用置换算法(LFU)

为每个页面设置寄存器，访问了加一，每次选择最小的

#### 时钟置换算法(Clock)

简单的 CLOCK 算法：为页面设置访问一个访问位，被访问后他的访问位设为1，需要置换时，从指针开始扫描，将为0的换出，将1变为0；

每个页面都有一个计数器，同时有一个指针，当有页面失效时，会通过指针搜索计数器，如果为0则换页，否则计数器-1



改进型的时钟置换算法：增加一个是否被访问的访问位，因此形成坐标（访问位，修改位）

- 依次寻找访问(0,0) (0,1) (1,0) (1,1)

#### 页面缓冲算法PBA

OS总是分配给进程固定的内存空间，避免进程老是缺页

但是OS会觉得有些进程的缺页率已经够低了，就可以把一些不怎么影响缺页率的页拿出来，放到空闲页面链表，供需要的使用。

如果此时还没被修改，原进程又需要这个页，则会把该页取出来

**数据结构：**

1) 空闲页面链表
2) 修改页面链表

暂时缓冲页面，几个页面一起写回，减少开销



### 抖动和工作集

驻留集：请求分页存储管理中给进程分配的物理块的集合，一般小于进程的总大小

分配方法：

- 固定分配：在运行期间驻留集大小不变
- 可变分配：在运行期间，可以根据情况适当的增加或减少

置换方式：

- 局部置换：发生缺页时只能选择进程自己的物理块进行置换
- 全局置换：可以将操作系统保留的空闲块分配给缺页进程，可以分配别的进程的块

#### 抖动

刚调出的老页面又要被调用，时间被浪费在和外存的数据传输上

原因：

1. 进程数太多，使得每个进程分到内存块过少

2. 页面置换算法不合理

#### 工作集

- 定义：在某段时间间隔里，进程实际访问页面的集合

OS分配给每个进程的实际物理块的大小可以是固定的，也可以是不固定的，如果根据工作集的大小来分配实际物理块，会减少抖动的概率。

#### 预防抖动

- 采取局部置换策略
- 处理机调度中引入工作集算法
- 利用 L=S 准则（Denning,1980）调节缺页率
        L：缺页之间的平均服务时间
        S：平均缺页服务时间
- 暂停某些进程



## 文件管理

### 文件和文件系统

#### 分类方法

用途：

- 用户文件
- 库文件
- 系统文件

数据形式：

- 源文件
- 目标文件
- 可执行文件

存储控制属性分类：

- 读文件
- 写文件
- 执行文件



#### 文件系统模型

- 底层：文件 目录 磁盘存储空间


- 中间层：对对象进行操纵和管理的软件集合
  - 文件管理
  - 文件目录管理
  - 文件存储空间管理
  - 共享和保护

- 高层：操作系统提供给用户的接口——命令接口 程序接口


<img src="pics/image-20230626171324015.png" alt="image-20230626171324015" style="zoom:50%;" />



### 文件的逻辑结构

**逻辑结构：**从用户观点出发所观察到的文件组织形式，是用户可以直接处理的数据及其结构。

- 提高检索速度
- 便于修改
- 降低存储费用

**存储结构**：文件在外存上的存储组织形式。

- 文件是否有结构分类
  - 有结构文件
    - 又称“记录式文件”，每条记录由若干数据项组成
    - 又分为“定长记录”和“不定长记录”
  - 无结构文件
- 按文件的组织方式
  - 顺序文件、索引文件、索引顺序文件



#### 文件逻辑结构的类型

1. 有结构文件
   - 顺序文件
     - 文件中的记录一个接一个地顺序排列，定长 or 不定长。顺序存储 or 链式存储
     - 串结构：记录之间的顺序与关键字顺序无关
     - 顺序结构：记录之间的顺序按照关键字顺序排列

   - 索引文件
     - 建立一个索引表以加快文件检索速度，每条记录对应一个索引项
     - 缺点：有可能导致索引表比文件本事内容大很多

   - 索引顺序文件
     - 一组记录对应一个索引表项

   - hash表

2. 无结构文件



### 文件目录

要求：

- 按名存储
- 提高对目录的检索速度
- 文件共享
- 允许重名

#### 文件控制块和索引结点 

**文件控制块**(FCB)：为了能对文件进行正确的存取，必须为文件设置用于描述和控制文件的数据结构

一个文件对应一个FCB

1. 基本信息：
   - 文件名
   - 物理位置
   - 逻辑位置
   - 物理结构
2. 存取控制信息类
   - 文件主权限
   - 核准用户权限
   - 普通用户权限
3. 使用信息



**减少文件控制块得大小，可以显著减小查找文件所需次数**

UNIX采用文件名与文件描述信息分开的方法，即文件描述信息单独形成一个称为索引节点的数据结构，称为索引结点（i节点）。

文件目录：文件控制块的集合组成文件目录



#### 目录结构

- 单级目录结构
- 两级目录结构
- 多级目录结构
- 无环图目录结构



### 外存分配方式

外存分配方式有：连续分配、链接分配、索引分配

#### 连续分配

- 为每一个文件分配一组相邻的盘块
- 顺序文件结构，物理文件又称顺序文件
- 文件目录项：文件名、第一个盘块号、文件长度
- 会形成磁盘碎片



#### 链接分配

为文件分配多个不连续的盘符，通过在每个盘块上的链接指针，将同属于一个文件的多个离散的盘块链接成一个链表

> 注意链接分配只能够顺序访问！

##### 隐式链接

每个FCB中，包含第一个盘块和最后一个盘块号

在每一个盘块中，都有指向下一个盘块的指针

缺点：只适合顺序访问，一个出问题后面就寄了



##### 显式链接

指针显式存放在外存的一张链接表中，整个磁盘就一张表，称为FAT表

每个表项中存放链接指针，即下一个盘块号。

文件的第一个块号，存放在文件目录项（FCB）中



#### 索引方式

将每个文件的盘块号集中放在一起

为每个文件分配一个索引块（表），把分配给该文件的盘块号都记录在索引块中。

在建立文件时，其目录项中包含指向索引块的指针。

**优点：**

支持直接访问，不会产生外部碎片，文件较大时，优于链接分配



### 文件存储空间的管理

操作系统需要记住存储空间的使用情况，所以需要**相应的存储结构和提供存储空间分配和回收的手段**

#### 空闲表法和空闲链表法



#### 位示图

从位示意图中很容易找到一个或一组相邻近的空闲盘块



#### 成组空间法



### 文件共享与保护

#### 基于索引结点的共享方式 

硬链接，计数+1



#### 利用符号链实现文件共享

软链接，计数一直是1

### 题目

1、存放在某个磁盘上的文件系统，采用混合索引分配方式，其FCB中共有13个地址项，第0~9个地址项为直接地址，第10个地址项为一次间接地址，第11个地址项为二次间接地址，第12个地址项为三次间接地址。如果每个盘块的大小为512字节，若盘块号需要用3个字节来描述，而每个盘块最多存放170个盘块地址： 

（1）该文件系统允许文件的最大长度是多少？

（2）将文件的字节偏移量5000、15000转换为物理块号和块内偏移量。

（3）假设文件的FCB已在内存，为了访问文件中某个位置的内容，最少需要访问几次磁盘，最多需要访问几次磁盘？

（4）对某个长度为18000000字节的文件，它需要占用多少个盘块（包括间接地址块）？

**【解答】（列出了详细的分析过程，实际回答可以简单写）**

1、$(10+170+170*170+170*170*170)*512=4942080*512字节=2471040 KB$

2、每一个盘块的大小是512字节，文件的逻辑空间每块大小也是512字节

（1）5000/512得到商为9，余数为392，所以字节偏移量5000对应的逻辑块号为9，块内偏移量为392。由于9<10，故可直接从该文件的FCB的9号地址项处得到物理盘块号，块内偏移量为392。

（2）15000/512得到商为29，余数为152，即字节偏移量15000对应的逻辑块号为29，块内偏移量为152。由于10<29<10+170，而29-10=19，故可从FCB的10号地址项，即一次间址项中得到一次间址的地址；并从一次间址块的19号（即该块的第57~59这3个字节）中获得对应的物理盘块号，块内偏移量为152。

3、由于文件的FCB已在内存，为了访问文件中某个位置的内容，最少需要1次访问磁盘（即可通过直接地址直接读文件盘块），最多需要4次访问磁盘（第一次是读三次间址块，第二次是读二次间址块，第三次是读一次间址块，第四次是读文件盘块）

4、根据题意，18000000/512＝35156.25，因此该文件总共需要35157个盘块存储。由于10＋170＋170×170<35157<10＋170＋170×170＋170*170*170，故该文件不仅需要使用10个直接地址项，还需要使用一次、二次及三次间接地址项。又因为35157－（10＋170＋170×170）＝6077，6077/（170×170）得到商为0，余数为6077，得知该文件在三次间接地址时还需要1个二次间接地址块；而余数6077/170得到商为35余数为127，可知该文件在三次间接地址时还需要36个一次间接地址块。因此该文件需要：

直接地址 10个数据盘块

一次地址 1个一次地址块，170个数据块

二次地址 1个二次地址块+170个一次地址块+170*170个数据块

三次地址 1个三次地址块+1个二次地址块+36个一次地址块+（35*170+127）（或直接6077）



## 设备管理

设备管理的目标：

- 向用户提供使用外部设备的接口，按照用户的要求和设备的类型，控制设备工作，完成用户的输入输出请求
  - 方便是指用户能独立于具体设备的复杂物理特性而方便地使用设备；
  - 统一是指对不同设备尽量能统一操作方式；
  - 方便和统一要求对用户屏蔽实现具体设备I/O操作的细节，呈现给用户的是一种性能理想化的、操作简便的逻辑设备。
  - 系统的这种性能亦称为设备的独立性（设备无关性）。

- 利用中断技术、通道技术和缓冲技术，提高**CPU与设备**、**设备与设备间**的并行工作能力，充分利用设备资源，提高外部设备的使用效率
- 设备管理就是要保证在多道程序环境下，当多个进程竞争使用设备时，按照一定的策略分配和管理设备，以使系统能有条不紊地工作



### I/O系统

- 直接用于IO和存储的设备
- 相应的设备控制器和高速总线
- IO通道

#### I/O设备

<img src="pics/image-20230625091509610.png" alt="image-20230625091509610" style="zoom: 50%;" />

I/O设备的电子部件称作**设备控制器**

I/O设备通常与设备控制器相连，包含的信号有：数字信号、控制信号、状态信号。

设备控制器：控制一个或几个I/O设备，实现I/O设备和计算机之间的数据交换

组成：

- 处理机与设备控制器的接口
- 设备控制器与设备的接口
- I/O逻辑



#### I/O通道

I/O通道——是一种特殊的处理机，它具有执行I/O指令的能力，并且通过执行通道程序来控制I/O操作。 



### I/O控制方式

衡量I/O控制方式的好坏有以下三个原则：

1. 数据传送速度足够快，能满足用户的需求但又不丢失数据；
2. 系统开销小，所需的处理控制程序少；
3. 能充分发挥硬件资源的能力，使 I/O 设备尽可能忙，而 CPU 等待时间尽可能少。

#### 程序查询I/O方式

直接访问由用户进程直接控制主存或 CPU 和外围设备之间的信息传送

- 忙/等方式
  - 查询方式
  - CPU极大浪费




#### 中断驱动I/O控制方式

使得CPU和I/O设备并行工作

CPU请求I/O设备后去做自己的事情



#### DMA控制方式

由于中断驱动方式仍以字节为单位进行I/O的，用于控制块设备时是极其低效的（中断频繁），故引入了DMA，以数据块为I/O单位，比中断驱动方式又成百倍地提高效率。 

进一步提高了CPU与I/O设备的并行操作程度。

组成：

<img src="pics/image-20230625091739398.png" alt="image-20230625091739398" style="zoom:50%;" />



#### I/O通道控制方式

读/写多个不同的数据块

通道程序是由一系列通道命令构成的

<img src="pics/image-20230625092015806.png" alt="image-20230625092015806" style="zoom:50%;" />



### 缓冲管理:star:

#### 引入

- 为了缓和CPU和I/O速度不匹配
- 减少CPU中断次数
- 解决数据粒度不匹配
- 提高并行性

#### 单缓冲和双缓冲

<img src="pics/image-20230607150255541.png" alt="image-20230607150255541" style="zoom: 50%;" />

系统处理一块数据的时间可表示为**Max(T,C) + M**

##### 双缓冲

<img src="pics/image-20230607150551387.png" alt="image-20230607150551387" style="zoom:50%;" />

若C<T 处理一块数据的平均时间为Max(T,C+M)

若C>T 处理一块数据的平均时间大约为C+M



##### 循环缓冲

<img src="pics/image-20230625092548117.png" alt="image-20230625092548117" style="zoom:33%;" />



##### 缓冲池

<img src="pics/image-20230625092717313.png" alt="image-20230625092717313" style="zoom:33%;" />

工作方式：

<img src="pics/image-20230625092744584.png" alt="image-20230625092744584" style="zoom:25%;" />



### 设备分配

**必须由系统统一分配**

#### 设备分配中的数据结构

<img src="pics/image-20230625092913540.png" alt="image-20230625092913540" style="zoom:33%;" />

设备控制表DCT

<img src="pics/image-20230607151223795.png" alt="image-20230607151223795" style="zoom:40%;" />

 控制器控制表COCT

 通道控制表CHCT

 系统设备表SDT

<img src="pics/image-20230607151319617.png" alt="image-20230607151319617" style="zoom: 33%;" />



#### SPOOLing技术

虚拟设备技术，利用高速共享设备将低速的独享设备模拟为高速的共享设备，逻辑上，系统为每一个用户都分配了一台独立的高速独享设备。

<img src="pics/image-20230625093055970.png" alt="image-20230625093055970" style="zoom:33%;" />

##### 组成

磁盘输入井和磁盘输出井：

- 磁盘输入井和磁盘输出井是磁盘中两块较大的存储区域；输入井用来模拟脱机输入时候的磁盘，暂时存储I/O输入设备的输入；输出井模拟脱机输出时候的磁盘，用来存储用户程序的输出


输入缓冲区和输出缓冲区：

- 在内存中开辟的两个区域，输入缓冲区用来暂存I/O设备的输入，再传送到输入井

- 输出缓冲区用来暂存从输出井送来的数据，再传送给输出设备

输入进程和输出进程：

- 输入进程：用来模拟脱机输入时的外围控制机，在输入设备空闲时，将用户要求的数据从输入机通过输入缓冲区传送到输入井，当CPU需要数据时，再从输入井中读出数据

- 输出进程：用来模拟脱机输出时的外围控制机，在输出设备空闲时，将用户程序的数据从输出井中读到输出缓冲区中，并传送到输出设备中去




##### 意义

`提高了I/O速度 `：对数据所进行的I/O操作，从对低速I/O设备进行的I/O操作，演变为对输入井或输出井中数据的存取。

`将独占设备改造成共享设备`：在Spooling系统中，实际上并没有为任何进程分配设备，只是在输入井或输出井中为进程分配一个存储区和建立一张I/O请求表

`实现了虚拟设备功能`：将独占设备变换为若干台对应的逻辑设备的功能。  



### I/O软件系统层次模型

目标：

1. 隐藏物理细节
2. 与设备无关
3. 提高处理机和I/O设备的利用率
4. 对I/O设备控制
5. 错误处理
6. 保证设备的正确共享

<img src="pics/image-20230625093400425.png" alt="image-20230625093400425" style="zoom:40%;" />



#### 中断处理程序

- 中断
  - 中断是指CPU对I/O设备发来的中断信号的一种响应。
  -  CPU暂停正在执行的程序，保留CPU环境后，自动  转去执行该I/O设备的中断处理程序。
    执行完后，再回到断点，继续执行原来的程序。
  - 这种中断是由外部设备引起的，一般称为外中断。
- 陷入（trap）
  - 由CPU内部事件引起的中断，如除零，越界访问等。
  - 与中断一样，若系统发现了有陷入事件，CPU也将暂停正在执行的程度，转去执行该陷入事件的处理序。
  - 中断事件来源于内部，通常称为内中断

**中断向量表**

为每种设备配以相应的中断处理程序，并把该程序的入口地址放在中断向量表的一个表项中



##### 中断处理步骤

1. 检测是否有未响应的中断信号
   1. 设备完成输入或输出后，发送请求
   2. 程序每执行完当前指令，处理机都要检测是否有信号，以便及时响应
2. 保护被中断进程的CPU环境
   1. 硬件自动将处理机状态和下一条指令地址保存在中断保留区
   2. 把被中断进程的 CPU 现场信息，即将包括所有 CPU 寄存器的（如通用寄存器、段寄存器等）内容都压入中断栈中。
3. 转入设备中断处理程序
   1. 找到引起本次中断的I/O设备，并发送确认
   2. 收到确认信号后，取消中断请求信号，将设备中断处理程序入口地址装到程序计数器中 
4. 中断处理
5. 恢复被中断进程CPU的现场并退出中断
   1. 当中断处理完成以后，需要恢复 CPU 的现场，退出中断。但是，此刻是否返回到被中断的进程，取决于两个因素：
   2. ①本中断是否采用了屏蔽（禁止）中断方式，若是，就会返回被中断的进程。
   3. ②采用的是中断嵌套方式，如果没有优先级更高的中断请求 I / O ，在中断完成后，仍会返回被中断的进程；反之，系统将处理优先级更高的中断请求。



#### 设备驱动程序

是I/O进程与设备控制器之间的通信程序

主要任务：

1. 接收上层软件发来的抽象I/O要求，转换为具体要求后发给设备控制器
2. 将设备控制器的信号传递给上层软件



功能：

- 接收由独立性软件发来的命令和参数，并将命令中的抽象要求转换为具体要求。例如，将磁盘块号转换为磁盘的盘面、磁道号和扇区号。
- 检查用户I/O请求的合法性、了解I/O设备状态、传递有关参数、设置设备工作方式 
- 发出I/O命令。如果设备空闲，便立即启动I/O设备去完成指定的I/O操作； 如果设备处于忙碌状态，则将请求者的请求块挂在设备队列上等待。
- 及时响应由控制器或通道来的中断请求，并根据其中断类型调用相应的中断处理程序。 
- 对于设置有通道的系统，驱动程序还应能自动地构成通道程序。



### 设备独立性软件

> 应用程序独立于具体使用的物理设备。

引入了逻辑设备和物理设备

从逻辑名到物理设备名映射的实现：

1. 逻辑设备表



### 磁盘存储器管理

#### 磁盘访问时间

1）寻道时间`Ts`：是指把磁臂（磁头）移动到指定磁道上所经历的时间。

2）旋转延迟时间$Tτ$：是指定扇区移动到磁头下面所经历的时间。 

3）传输时间$Tt$：是指把数据从磁盘上读出或向磁盘写入数据所经历的时间。
$$
T_a=T_s+T_τ+T_t = (m \times n+s)+\frac 1 {2r}+\frac b{rN}
$$
n：移动磁道数    s：启动磁道臂时间

r：每秒的转数 

N：一条磁道的字节数

b：传输的字节数



#### 磁盘调度算法

目的是为了使平均寻道时间最少

1. 先来先服务FCFS
2. 最短寻道时间优先
   - 会有饿死
3. 扫描算法SCAN
   - 先按顺序扫描
   - 再反向扫描
4. 循环扫描CSCAN
   - 先按顺序扫描
   - 再直接跑到最外侧



### RAID分级

- RAID0
  - 数据分散存储在所有磁盘中
  - 并发IO
  - 不需要进行数据校验
  - n个磁盘组成的RAID0是单个磁盘的n倍性能
- RAID1
  - 分别写入工作磁盘和镜像，利用率为50%
  - 写入有影响，读取无影响
  - 数据保护
- RAID2
  - 纠错海明码磁盘阵列，其设计思想是利用海明码实现数据校验冗余。
- RAID3
  - RAID3是采用一个专用的磁盘作为校验盘，其余磁盘作为数据盘，数据按位可字节的方式交叉存储到各个数据盘中。
  - 并行从多个磁盘条带读取数据，性能非常高，同时还提供了数据容错能力。
  - RAID3 只需要一个校验盘，阵列的存储空间利用率高，再加上并行访问的特征，能够为高带宽的大量读写提供高性能，适用大容量数据的顺序访问应用，如影像处理、流媒体服务等
- RAID5
  - 将校验数据分散到所有的磁盘中
